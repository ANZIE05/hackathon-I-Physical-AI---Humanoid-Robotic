"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_textbook=globalThis.webpackChunkphysical_ai_humanoid_robotics_textbook||[]).push([[8091],{3961:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>r,default:()=>m,frontMatter:()=>s,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"module-2/digital-twin-practical-labs","title":"Digital Twin Practical Labs","description":"Overview","source":"@site/docs/module-2/digital-twin-practical-labs.md","sourceDirName":"module-2","slug":"/module-2/digital-twin-practical-labs","permalink":"/docs/module-2/digital-twin-practical-labs","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-2/digital-twin-practical-labs.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"sidebar_position":6},"sidebar":"tutorialSidebar","previous":{"title":"Unity Visualization","permalink":"/docs/module-2/unity-visualization"},"next":{"title":"Digital Twin Review Questions","permalink":"/docs/module-2/digital-twin-review-questions"}}');var o=i(4848),t=i(8453);const s={sidebar_position:6},r="Digital Twin Practical Labs",l={},c=[{value:"Overview",id:"overview",level:2},{value:"Lab 1: Basic Robot Simulation in Gazebo",id:"lab-1-basic-robot-simulation-in-gazebo",level:2},{value:"Objective",id:"objective",level:3},{value:"Prerequisites",id:"prerequisites",level:3},{value:"Lab Setup",id:"lab-setup",level:3},{value:"Implementation Steps",id:"implementation-steps",level:3},{value:"Step 1: Create Robot URDF Model",id:"step-1-create-robot-urdf-model",level:4},{value:"Step 2: Create Gazebo World",id:"step-2-create-gazebo-world",level:4},{value:"Step 3: Create Robot Control Node",id:"step-3-create-robot-control-node",level:4},{value:"Step 4: Create Launch File",id:"step-4-create-launch-file",level:4},{value:"Step 5: Update Package Configuration",id:"step-5-update-package-configuration",level:4},{value:"Step 6: Build and Test",id:"step-6-build-and-test",level:4},{value:"Lab Exercises",id:"lab-exercises",level:3},{value:"Expected Results",id:"expected-results",level:3},{value:"Lab 2: Advanced Sensor Simulation",id:"lab-2-advanced-sensor-simulation",level:2},{value:"Objective",id:"objective-1",level:3},{value:"Implementation Steps",id:"implementation-steps-1",level:3},{value:"Step 1: Enhanced Robot Model with Multiple Sensors",id:"step-1-enhanced-robot-model-with-multiple-sensors",level:4},{value:"Step 2: Sensor Fusion Node",id:"step-2-sensor-fusion-node",level:4},{value:"Step 3: Enhanced Launch File",id:"step-3-enhanced-launch-file",level:4},{value:"Lab Exercises",id:"lab-exercises-1",level:3},{value:"Expected Results",id:"expected-results-1",level:3},{value:"Lab 3: Unity Visualization Integration",id:"lab-3-unity-visualization-integration",level:2},{value:"Objective",id:"objective-2",level:3},{value:"Implementation Steps",id:"implementation-steps-2",level:3},{value:"Step 1: Unity Setup for Robotics",id:"step-1-unity-setup-for-robotics",level:4},{value:"Step 2: Environment Visualization",id:"step-2-environment-visualization",level:4},{value:"Lab Exercises",id:"lab-exercises-2",level:3},{value:"Expected Results",id:"expected-results-2",level:3},{value:"Troubleshooting Common Issues",id:"troubleshooting-common-issues",level:2},{value:"Gazebo Simulation Issues",id:"gazebo-simulation-issues",level:3},{value:"Unity Integration Issues",id:"unity-integration-issues",level:3},{value:"Sensor Fusion Issues",id:"sensor-fusion-issues",level:3},{value:"Lab Report Template",id:"lab-report-template",level:2},{value:"Lab Documentation Requirements",id:"lab-documentation-requirements",level:3},{value:"Evaluation Criteria",id:"evaluation-criteria",level:3},{value:"Review Questions",id:"review-questions",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"digital-twin-practical-labs",children:"Digital Twin Practical Labs"})}),"\n",(0,o.jsx)(e.h2,{id:"overview",children:"Overview"}),"\n",(0,o.jsx)(e.p,{children:"This section provides hands-on practical labs that reinforce the concepts of digital twin simulation, Gazebo fundamentals, physics simulation, sensor simulation, and Unity visualization. Each lab builds upon the previous knowledge and provides real-world application of simulation principles in Physical AI and Humanoid Robotics contexts."}),"\n",(0,o.jsx)(e.h2,{id:"lab-1-basic-robot-simulation-in-gazebo",children:"Lab 1: Basic Robot Simulation in Gazebo"}),"\n",(0,o.jsx)(e.h3,{id:"objective",children:"Objective"}),"\n",(0,o.jsx)(e.p,{children:"Create a simple differential drive robot model in Gazebo with basic sensors and ROS 2 integration to understand the fundamentals of robotic simulation."}),"\n",(0,o.jsx)(e.h3,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"ROS 2 Humble Hawksbill installed"}),"\n",(0,o.jsx)(e.li,{children:"Gazebo Garden installed"}),"\n",(0,o.jsx)(e.li,{children:"Basic understanding of URDF/SDF"}),"\n",(0,o.jsx)(e.li,{children:"Understanding of ROS 2 communication patterns"}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"lab-setup",children:"Lab Setup"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-bash",children:"# Create workspace\nmkdir -p ~/simulation_labs/ws_basic_robot/src\ncd ~/simulation_labs/ws_basic_robot\n\n# Create simulation package\nros2 pkg create --build-type ament_python basic_robot_simulation --dependencies rclpy std_msgs sensor_msgs geometry_msgs nav_msgs tf2_ros gazebo_ros_pkgs\n"})}),"\n",(0,o.jsx)(e.h3,{id:"implementation-steps",children:"Implementation Steps"}),"\n",(0,o.jsx)(e.h4,{id:"step-1-create-robot-urdf-model",children:"Step 1: Create Robot URDF Model"}),"\n",(0,o.jsxs)(e.p,{children:["Create ",(0,o.jsx)(e.code,{children:"basic_robot_simulation/urdf/differential_robot.urdf"}),":"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-xml",children:'<?xml version="1.0"?>\n<robot name="differential_robot" xmlns:xacro="http://www.ros.org/wiki/xacro">\n  \x3c!-- Properties --\x3e\n  <xacro:property name="M_PI" value="3.1415926535897931" />\n  <xacro:property name="wheel_radius" value="0.1" />\n  <xacro:property name="wheel_width" value="0.05" />\n  <xacro:property name="base_length" value="0.5" />\n  <xacro:property name="base_width" value="0.3" />\n  <xacro:property name="base_height" value="0.15" />\n  <xacro:property name="wheel_pos_x" value="0.2" />\n  <xacro:property name="wheel_pos_y" value="0.15" />\n\n  \x3c!-- Base Link --\x3e\n  <link name="base_link">\n    <visual>\n      <geometry>\n        <box size="${base_length} ${base_width} ${base_height}"/>\n      </geometry>\n      <material name="blue">\n        <color rgba="0 0 0.8 1"/>\n      </material>\n    </visual>\n    <collision>\n      <geometry>\n        <box size="${base_length} ${base_width} ${base_height}"/>\n      </geometry>\n    </collision>\n    <inertial>\n      <mass value="5"/>\n      <inertia ixx="0.1" ixy="0" ixz="0" iyy="0.1" iyz="0" izz="0.1"/>\n    </inertial>\n  </link>\n\n  \x3c!-- Left Wheel --\x3e\n  <joint name="left_wheel_joint" type="continuous">\n    <parent link="base_link"/>\n    <child link="left_wheel"/>\n    <origin xyz="${wheel_pos_x} ${wheel_pos_y} 0" rpy="${-M_PI/2} 0 0"/>\n    <axis xyz="0 0 1"/>\n  </joint>\n\n  <link name="left_wheel">\n    <visual>\n      <geometry>\n        <cylinder radius="${wheel_radius}" length="${wheel_width}"/>\n      </geometry>\n      <material name="black">\n        <color rgba="0 0 0 1"/>\n      </material>\n    </visual>\n    <collision>\n      <geometry>\n        <cylinder radius="${wheel_radius}" length="${wheel_width}"/>\n      </geometry>\n    </collision>\n    <inertial>\n      <mass value="0.5"/>\n      <inertia ixx="0.001" ixy="0" ixz="0" iyy="0.001" iyz="0" izz="0.002"/>\n    </inertial>\n  </link>\n\n  \x3c!-- Right Wheel --\x3e\n  <joint name="right_wheel_joint" type="continuous">\n    <parent link="base_link"/>\n    <child link="right_wheel"/>\n    <origin xyz="${wheel_pos_x} ${-wheel_pos_y} 0" rpy="${-M_PI/2} 0 0"/>\n    <axis xyz="0 0 1"/>\n  </joint>\n\n  <link name="right_wheel">\n    <visual>\n      <geometry>\n        <cylinder radius="${wheel_radius}" length="${wheel_width}"/>\n      </geometry>\n      <material name="black">\n        <color rgba="0 0 0 1"/>\n      </material>\n    </visual>\n    <collision>\n      <geometry>\n        <cylinder radius="${wheel_radius}" length="${wheel_width}"/>\n      </geometry>\n    </collision>\n    <inertial>\n      <mass value="0.5"/>\n      <inertia ixx="0.001" ixy="0" ixz="0" iyy="0.001" iyz="0" izz="0.002"/>\n    </inertial>\n  </link>\n\n  \x3c!-- Camera --\x3e\n  <joint name="camera_joint" type="fixed">\n    <parent link="base_link"/>\n    <child link="camera_link"/>\n    <origin xyz="${base_length/2 - 0.05} 0 ${base_height/2}" rpy="0 0 0"/>\n  </joint>\n\n  <link name="camera_link">\n    <visual>\n      <geometry>\n        <box size="0.05 0.05 0.05"/>\n      </geometry>\n      <material name="red">\n        <color rgba="0.8 0 0 1"/>\n      </material>\n    </visual>\n    <collision>\n      <geometry>\n        <box size="0.05 0.05 0.05"/>\n      </geometry>\n    </collision>\n    <inertial>\n      <mass value="0.1"/>\n      <inertia ixx="0.0001" ixy="0" ixz="0" iyy="0.0001" iyz="0" izz="0.0001"/>\n    </inertial>\n  </link>\n\n</robot>\n'})}),"\n",(0,o.jsx)(e.h4,{id:"step-2-create-gazebo-world",children:"Step 2: Create Gazebo World"}),"\n",(0,o.jsxs)(e.p,{children:["Create ",(0,o.jsx)(e.code,{children:"basic_robot_simulation/worlds/simple_room.sdf"}),":"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-xml",children:'<?xml version="1.0" ?>\n<sdf version="1.7">\n  <world name="simple_room">\n    \x3c!-- Physics --\x3e\n    <physics type="ode">\n      <max_step_size>0.001</max_step_size>\n      <real_time_factor>1</real_time_factor>\n      <real_time_update_rate>1000</real_time_update_rate>\n      <ode>\n        <solver>\n          <type>quick</type>\n          <iters>10</iters>\n          <sor>1.3</sor>\n        </solver>\n        <constraints>\n          <cfm>0.0</cfm>\n          <erp>0.2</erp>\n        </constraints>\n      </ode>\n    </physics>\n\n    \x3c!-- Lighting --\x3e\n    <light name="sun" type="directional">\n      <cast_shadows>true</cast_shadows>\n      <pose>0 0 10 0 0 0</pose>\n      <diffuse>0.8 0.8 0.8 1</diffuse>\n      <specular>0.2 0.2 0.2 1</specular>\n      <attenuation>\n        <range>1000</range>\n        <constant>0.9</constant>\n        <linear>0.01</linear>\n        <quadratic>0.001</quadratic>\n      </attenuation>\n      <direction>-0.2 0.3 -0.9</direction>\n    </light>\n\n    \x3c!-- Ground plane --\x3e\n    <include>\n      <uri>model://ground_plane</uri>\n    </include>\n\n    \x3c!-- Room walls --\x3e\n    <model name="wall_1">\n      <pose>-3 0 1 0 0 0</pose>\n      <link name="link">\n        <collision name="collision">\n          <geometry>\n            <box><size>0.1 6 2</size></box>\n          </geometry>\n        </collision>\n        <visual name="visual">\n          <geometry>\n            <box><size>0.1 6 2</size></box>\n          </geometry>\n          <material>\n            <ambient>0.5 0.5 0.5 1</ambient>\n            <diffuse>0.5 0.5 0.5 1</diffuse>\n          </material>\n        </visual>\n        <inertial>\n          <mass>100</mass>\n          <inertia>\n            <ixx>10</ixx>\n            <ixy>0</ixy>\n            <ixz>0</ixz>\n            <iyy>10</iyy>\n            <iyz>0</iyz>\n            <izz>10</izz>\n          </inertia>\n        </inertial>\n      </link>\n    </model>\n\n    <model name="wall_2">\n      <pose>3 0 1 0 0 0</pose>\n      <link name="link">\n        <collision name="collision">\n          <geometry>\n            <box><size>0.1 6 2</size></box>\n          </geometry>\n        </collision>\n        <visual name="visual">\n          <geometry>\n            <box><size>0.1 6 2</size></box>\n          </geometry>\n          <material>\n            <ambient>0.5 0.5 0.5 1</ambient>\n            <diffuse>0.5 0.5 0.5 1</diffuse>\n          </material>\n        </visual>\n        <inertial>\n          <mass>100</mass>\n          <inertia>\n            <ixx>10</ixx>\n            <ixy>0</ixy>\n            <ixz>0</ixz>\n            <iyy>10</iyy>\n            <iyz>0</iyz>\n            <izz>10</izz>\n          </inertia>\n        </inertial>\n      </link>\n    </model>\n\n    <model name="wall_3">\n      <pose>0 -3 1 0 0 1.5707</pose>\n      <link name="link">\n        <collision name="collision">\n          <geometry>\n            <box><size>0.1 6 2</size></box>\n          </geometry>\n        </collision>\n        <visual name="visual">\n          <geometry>\n            <box><size>0.1 6 2</size></box>\n          </geometry>\n          <material>\n            <ambient>0.5 0.5 0.5 1</ambient>\n            <diffuse>0.5 0.5 0.5 1</diffuse>\n          </material>\n        </visual>\n        <inertial>\n          <mass>100</mass>\n          <inertia>\n            <ixx>10</ixx>\n            <ixy>0</ixy>\n            <ixz>0</ixz>\n            <iyy>10</iyy>\n            <iyz>0</iyz>\n            <izz>10</izz>\n          </inertia>\n        </inertial>\n      </link>\n    </model>\n\n    <model name="wall_4">\n      <pose>0 3 1 0 0 1.5707</pose>\n      <link name="link">\n        <collision name="collision">\n          <geometry>\n            <box><size>0.1 6 2</size></box>\n          </geometry>\n        </collision>\n        <visual name="visual">\n          <geometry>\n            <box><size>0.1 6 2</size></box>\n          </geometry>\n          <material>\n            <ambient>0.5 0.5 0.5 1</ambient>\n            <diffuse>0.5 0.5 0.5 1</diffuse>\n          </material>\n        </visual>\n        <inertial>\n          <mass>100</mass>\n          <inertia>\n            <ixx>10</ixx>\n            <ixy>0</ixy>\n            <ixz>0</ixz>\n            <iyy>10</iyy>\n            <iyz>0</iyz>\n            <izz>10</izz>\n          </inertia>\n        </inertial>\n      </link>\n    </model>\n\n    \x3c!-- Obstacles --\x3e\n    <model name="obstacle_1">\n      <pose>1 1 0.2 0 0 0</pose>\n      <link name="link">\n        <collision name="collision">\n          <geometry>\n            <cylinder><radius>0.3</radius><length>0.4</length></cylinder>\n          </geometry>\n        </collision>\n        <visual name="visual">\n          <geometry>\n            <cylinder><radius>0.3</radius><length>0.4</length></cylinder>\n          </geometry>\n          <material>\n            <ambient>0.8 0.6 0.2 1</ambient>\n            <diffuse>0.8 0.6 0.2 1</diffuse>\n          </material>\n        </visual>\n        <inertial>\n          <mass>10</mass>\n          <inertia>\n            <ixx>0.5</ixx>\n            <ixy>0</ixy>\n            <ixz>0</ixz>\n            <iyy>0.5</iyy>\n            <iyz>0</iyz>\n            <izz>0.8</izz>\n          </inertia>\n        </inertial>\n      </link>\n    </model>\n\n    \x3c!-- Robot spawn point --\x3e\n    <include>\n      <uri>model://differential_robot</uri>\n      <pose>0 0 0.2 0 0 0</pose>\n    </include>\n  </world>\n</sdf>\n'})}),"\n",(0,o.jsx)(e.h4,{id:"step-3-create-robot-control-node",children:"Step 3: Create Robot Control Node"}),"\n",(0,o.jsxs)(e.p,{children:["Create ",(0,o.jsx)(e.code,{children:"basic_robot_simulation/basic_robot_simulation/robot_controller.py"}),":"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import Twist, Vector3\nfrom sensor_msgs.msg import LaserScan, Image\nfrom nav_msgs.msg import Odometry\nfrom tf2_ros import TransformBroadcaster\nfrom geometry_msgs.msg import TransformStamped\nfrom cv_bridge import CvBridge\nimport math\nimport numpy as np\n\nclass RobotController(Node):\n    def __init__(self):\n        super().__init__('robot_controller')\n\n        # Publishers\n        self.cmd_vel_publisher = self.create_publisher(Twist, 'cmd_vel', 10)\n        self.status_publisher = self.create_publisher(\n            rclpy.qos.QoSProfile(depth=10), 'robot_status', 10)\n\n        # Subscribers\n        self.scan_subscription = self.create_subscription(\n            LaserScan, 'scan', self.scan_callback, 10)\n        self.odom_subscription = self.create_subscription(\n            Odometry, 'odom', self.odom_callback, 10)\n        self.image_subscription = self.create_subscription(\n            Image, 'camera/image_raw', self.image_callback, 10)\n\n        # Timer for control loop\n        self.control_timer = self.create_timer(0.1, self.control_loop)\n\n        # Robot state\n        self.latest_scan = None\n        self.robot_pose = {'x': 0.0, 'y': 0.0, 'theta': 0.0}\n        self.linear_velocity = 0.0\n        self.angular_velocity = 0.0\n        self.cv_bridge = CvBridge()\n\n        # Control parameters\n        self.obstacle_threshold = 0.5  # meters\n        self.target_distance = 2.0     # meters\n        self.current_mode = 'exploring'  # exploring, avoiding, following\n\n        self.get_logger().info('Robot Controller Node Started')\n\n    def scan_callback(self, msg):\n        \"\"\"Process laser scan data\"\"\"\n        self.latest_scan = msg\n\n        # Check for obstacles in front of robot\n        if len(msg.ranges) > 0:\n            # Get front-facing ranges (\xb130 degrees)\n            front_start = len(msg.ranges) // 2 - 15\n            front_end = len(msg.ranges) // 2 + 15\n\n            if front_start >= 0 and front_end < len(msg.ranges):\n                front_ranges = msg.ranges[front_start:front_end]\n                valid_ranges = [r for r in front_ranges if 0 < r < float('inf')]\n\n                if valid_ranges:\n                    min_range = min(valid_ranges)\n                    if min_range < self.obstacle_threshold:\n                        self.current_mode = 'avoiding'\n                    else:\n                        self.current_mode = 'exploring'\n\n    def odom_callback(self, msg):\n        \"\"\"Update robot pose from odometry\"\"\"\n        self.robot_pose['x'] = msg.pose.pose.position.x\n        self.robot_pose['y'] = msg.pose.pose.position.y\n\n        # Convert quaternion to euler\n        orientation = msg.pose.pose.orientation\n        siny_cosp = 2 * (orientation.w * orientation.z + orientation.x * orientation.y)\n        cosy_cosp = 1 - 2 * (orientation.y * orientation.y + orientation.z * orientation.z)\n        theta = math.atan2(siny_cosp, cosy_cosp)\n        self.robot_pose['theta'] = theta\n\n    def image_callback(self, msg):\n        \"\"\"Process camera image data\"\"\"\n        try:\n            cv_image = self.cv_bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')\n            # In a real application, you would process the image here\n            # For this lab, we just log that we received an image\n            self.get_logger().debug(f'Received image: {cv_image.shape}')\n        except Exception as e:\n            self.get_logger().error(f'Error processing image: {e}')\n\n    def control_loop(self):\n        \"\"\"Main control logic\"\"\"\n        cmd = Twist()\n\n        if self.current_mode == 'avoiding':\n            # Emergency obstacle avoidance\n            cmd.linear.x = 0.0\n            cmd.angular.z = 0.5  # Turn right\n        elif self.current_mode == 'exploring':\n            # Simple exploration pattern\n            cmd.linear.x = 0.3  # Move forward slowly\n            cmd.angular.z = 0.0\n\n        # Publish command\n        self.cmd_vel_publisher.publish(cmd)\n\n        # Publish status\n        status_msg = rclpy.qos.QoSProfile(depth=10)\n        status_msg.data = f'Mode: {self.current_mode}, Pos: ({self.robot_pose[\"x\"]:.2f}, {self.robot_pose[\"y\"]:.2f})'\n        self.status_publisher.publish(status_msg)\n\n        self.get_logger().info(f'Control: {self.current_mode}, Vel: ({cmd.linear.x:.2f}, {cmd.angular.z:.2f})',\n                              throttle_duration_sec=2)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    robot_controller = RobotController()\n\n    try:\n        rclpy.spin(robot_controller)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        robot_controller.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,o.jsx)(e.h4,{id:"step-4-create-launch-file",children:"Step 4: Create Launch File"}),"\n",(0,o.jsxs)(e.p,{children:["Create ",(0,o.jsx)(e.code,{children:"basic_robot_simulation/launch/basic_simulation.launch.py"}),":"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"from launch import LaunchDescription\nfrom launch.actions import IncludeLaunchDescription, DeclareLaunchArgument\nfrom launch.launch_description_sources import PythonLaunchDescriptionSource\nfrom launch.substitutions import PathJoinSubstitution, LaunchConfiguration\nfrom launch_ros.actions import Node\nfrom launch_ros.substitutions import FindPackageShare\n\ndef generate_launch_description():\n    # Declare launch arguments\n    world_arg = DeclareLaunchArgument(\n        'world',\n        default_value='simple_room.sdf',\n        description='Choose one of the world files from `/basic_robot_simulation/worlds`'\n    )\n\n    # Launch Gazebo\n    gazebo = IncludeLaunchDescription(\n        PythonLaunchDescriptionSource([\n            PathJoinSubstitution([\n                FindPackageShare('gazebo_ros'),\n                'launch',\n                'gazebo.launch.py'\n            ])\n        ]),\n        launch_arguments={\n            'world': PathJoinSubstitution([\n                FindPackageShare('basic_robot_simulation'),\n                'worlds',\n                LaunchConfiguration('world')\n            ]),\n            'verbose': 'false'\n        }.items()\n    )\n\n    # Robot state publisher\n    robot_state_publisher = Node(\n        package='robot_state_publisher',\n        executable='robot_state_publisher',\n        parameters=[{\n            'robot_description': open(\n                PathJoinSubstitution([\n                    FindPackageShare('basic_robot_simulation'),\n                    'urdf',\n                    'differential_robot.urdf'\n                ])\n            ).read()\n        }]\n    )\n\n    # Joint state publisher\n    joint_state_publisher = Node(\n        package='joint_state_publisher',\n        executable='joint_state_publisher',\n        parameters=[{'use_sim_time': True}]\n    )\n\n    # Gazebo ROS diff drive plugin configuration\n    diff_drive_spawner = Node(\n        package='controller_manager',\n        executable='spawner',\n        arguments=['diff_cont'],\n        parameters=[{'use_sim_time': True}]\n    )\n\n    # Robot controller node\n    robot_controller = Node(\n        package='basic_robot_simulation',\n        executable='robot_controller',\n        parameters=[{'use_sim_time': True}],\n        output='screen'\n    )\n\n    return LaunchDescription([\n        world_arg,\n        gazebo,\n        robot_state_publisher,\n        joint_state_publisher,\n        robot_controller\n    ])\n"})}),"\n",(0,o.jsx)(e.h4,{id:"step-5-update-package-configuration",children:"Step 5: Update Package Configuration"}),"\n",(0,o.jsxs)(e.p,{children:["Update ",(0,o.jsx)(e.code,{children:"basic_robot_simulation/package.xml"}),":"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-xml",children:'<?xml version="1.0"?>\n<?xml-model href="http://download.ros.org/schema/package_format3.xsd" schematypens="http://www.w3.org/2001/XMLSchema"?>\n<package format="3">\n  <name>basic_robot_simulation</name>\n  <version>0.0.0</version>\n  <description>Basic robot simulation package for lab exercises</description>\n  <maintainer email="student@university.edu">Student</maintainer>\n  <license>Apache-2.0</license>\n\n  <depend>rclpy</depend>\n  <depend>std_msgs</depend>\n  <depend>sensor_msgs</depend>\n  <depend>geometry_msgs</depend>\n  <depend>nav_msgs</depend>\n  <depend>tf2_ros</depend>\n  <depend>cv_bridge</depend>\n  <depend>gazebo_ros_pkgs</depend>\n\n  <test_depend>ament_copyright</test_depend>\n  <test_depend>ament_flake8</test_depend>\n  <test_depend>ament_pep257</test_depend>\n  <test_depend>python3-pytest</test_depend>\n\n  <export>\n    <build_type>ament_python</build_type>\n  </export>\n</package>\n'})}),"\n",(0,o.jsxs)(e.p,{children:["Update ",(0,o.jsx)(e.code,{children:"basic_robot_simulation/setup.py"}),":"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"from setuptools import find_packages, setup\n\npackage_name = 'basic_robot_simulation'\n\nsetup(\n    name=package_name,\n    version='0.0.0',\n    packages=find_packages(exclude=['test']),\n    data_files=[\n        ('share/ament_index/resource_index/packages',\n            ['resource/' + package_name]),\n        ('share/' + package_name, ['package.xml']),\n        ('share/' + package_name + '/urdf', ['urdf/differential_robot.urdf']),\n        ('share/' + package_name + '/worlds', ['worlds/simple_room.sdf']),\n        ('share/' + package_name + '/launch', ['launch/basic_simulation.launch.py']),\n    ],\n    install_requires=['setuptools'],\n    zip_safe=True,\n    maintainer='Student',\n    maintainer_email='student@university.edu',\n    description='Basic robot simulation package for lab exercises',\n    license='Apache-2.0',\n    tests_require=['pytest'],\n    entry_points={\n        'console_scripts': [\n            'robot_controller = basic_robot_simulation.robot_controller:main',\n        ],\n    },\n)\n"})}),"\n",(0,o.jsx)(e.h4,{id:"step-6-build-and-test",children:"Step 6: Build and Test"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-bash",children:"# Build the package\ncd ~/simulation_labs/ws_basic_robot\ncolcon build --packages-select basic_robot_simulation\n\n# Source the workspace\nsource install/setup.bash\n\n# Launch the simulation\nros2 launch basic_robot_simulation basic_simulation.launch.py\n\n# In another terminal, send commands to test\nros2 topic pub /cmd_vel geometry_msgs/Twist '{linear: {x: 0.5}, angular: {z: 0.2}}'\n"})}),"\n",(0,o.jsx)(e.h3,{id:"lab-exercises",children:"Lab Exercises"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsx)(e.li,{children:"Modify the robot's behavior to follow walls instead of random exploration"}),"\n",(0,o.jsx)(e.li,{children:"Add more complex obstacles to the environment"}),"\n",(0,o.jsx)(e.li,{children:"Implement a simple navigation algorithm that moves toward a target"}),"\n",(0,o.jsx)(e.li,{children:"Add more sensors to the robot (IMU, additional cameras)"}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"expected-results",children:"Expected Results"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Robot model successfully loads in Gazebo"}),"\n",(0,o.jsx)(e.li,{children:"Robot responds to velocity commands"}),"\n",(0,o.jsx)(e.li,{children:"Sensor data is published and received correctly"}),"\n",(0,o.jsx)(e.li,{children:"Basic control logic functions as expected"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"lab-2-advanced-sensor-simulation",children:"Lab 2: Advanced Sensor Simulation"}),"\n",(0,o.jsx)(e.h3,{id:"objective-1",children:"Objective"}),"\n",(0,o.jsx)(e.p,{children:"Create a comprehensive sensor simulation system with multiple sensor types (LiDAR, camera, IMU) and implement sensor fusion for enhanced perception."}),"\n",(0,o.jsx)(e.h3,{id:"implementation-steps-1",children:"Implementation Steps"}),"\n",(0,o.jsx)(e.h4,{id:"step-1-enhanced-robot-model-with-multiple-sensors",children:"Step 1: Enhanced Robot Model with Multiple Sensors"}),"\n",(0,o.jsxs)(e.p,{children:["Create ",(0,o.jsx)(e.code,{children:"basic_robot_simulation/urdf/sensor_robot.urdf"}),":"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-xml",children:'<?xml version="1.0"?>\n<robot name="sensor_robot" xmlns:xacro="http://www.ros.org/wiki/xacro">\n  \x3c!-- Properties --\x3e\n  <xacro:property name="M_PI" value="3.1415926535897931" />\n  <xacro:property name="wheel_radius" value="0.1" />\n  <xacro:property name="wheel_width" value="0.05" />\n  <xacro:property name="base_length" value="0.5" />\n  <xacro:property name="base_width" value="0.3" />\n  <xacro:property name="base_height" value="0.15" />\n  <xacro:property name="wheel_pos_x" value="0.2" />\n  <xacro:property name="wheel_pos_y" value="0.15" />\n\n  \x3c!-- Base Link --\x3e\n  <link name="base_link">\n    <visual>\n      <geometry>\n        <box size="${base_length} ${base_width} ${base_height}"/>\n      </geometry>\n      <material name="blue">\n        <color rgba="0 0 0.8 1"/>\n      </material>\n    </visual>\n    <collision>\n      <geometry>\n        <box size="${base_length} ${base_width} ${base_height}"/>\n      </geometry>\n    </collision>\n    <inertial>\n      <mass value="5"/>\n      <inertia ixx="0.1" ixy="0" ixz="0" iyy="0.1" iyz="0" izz="0.1"/>\n    </inertial>\n  </link>\n\n  \x3c!-- Left Wheel --\x3e\n  <joint name="left_wheel_joint" type="continuous">\n    <parent link="base_link"/>\n    <child link="left_wheel"/>\n    <origin xyz="${wheel_pos_x} ${wheel_pos_y} 0" rpy="${-M_PI/2} 0 0"/>\n    <axis xyz="0 0 1"/>\n  </joint>\n\n  <link name="left_wheel">\n    <visual>\n      <geometry>\n        <cylinder radius="${wheel_radius}" length="${wheel_width}"/>\n      </geometry>\n      <material name="black">\n        <color rgba="0 0 0 1"/>\n      </material>\n    </visual>\n    <collision>\n      <geometry>\n        <cylinder radius="${wheel_radius}" length="${wheel_width}"/>\n      </geometry>\n    </collision>\n    <inertial>\n      <mass value="0.5"/>\n      <inertia ixx="0.001" ixy="0" ixz="0" iyy="0.001" iyz="0" izz="0.002"/>\n    </inertial>\n  </link>\n\n  \x3c!-- Right Wheel --\x3e\n  <joint name="right_wheel_joint" type="continuous">\n    <parent link="base_link"/>\n    <child link="right_wheel"/>\n    <origin xyz="${wheel_pos_x} ${-wheel_pos_y} 0" rpy="${-M_PI/2} 0 0"/>\n    <axis xyz="0 0 1"/>\n  </joint>\n\n  <link name="right_wheel">\n    <visual>\n      <geometry>\n        <cylinder radius="${wheel_radius}" length="${wheel_width}"/>\n      </geometry>\n      <material name="black">\n        <color rgba="0 0 0 1"/>\n      </material>\n    </visual>\n    <collision>\n      <geometry>\n        <cylinder radius="${wheel_radius}" length="${wheel_width}"/>\n      </geometry>\n    </collision>\n    <inertial>\n      <mass value="0.5"/>\n      <inertia ixx="0.001" ixy="0" ixz="0" iyy="0.001" iyz="0" izz="0.002"/>\n    </inertial>\n  </link>\n\n  \x3c!-- Camera --\x3e\n  <joint name="camera_joint" type="fixed">\n    <parent link="base_link"/>\n    <child link="camera_link"/>\n    <origin xyz="${base_length/2 - 0.05} 0 ${base_height/2}" rpy="0 0 0"/>\n  </joint>\n\n  <link name="camera_link">\n    <visual>\n      <geometry>\n        <box size="0.05 0.05 0.05"/>\n      </geometry>\n      <material name="red">\n        <color rgba="0.8 0 0 1"/>\n      </material>\n    </visual>\n    <collision>\n      <geometry>\n        <box size="0.05 0.05 0.05"/>\n      </geometry>\n    </collision>\n    <inertial>\n      <mass value="0.1"/>\n      <inertia ixx="0.0001" ixy="0" ixz="0" iyy="0.0001" iyz="0" izz="0.0001"/>\n    </inertial>\n  </link>\n\n  \x3c!-- LiDAR --\x3e\n  <joint name="lidar_joint" type="fixed">\n    <parent link="base_link"/>\n    <child link="lidar_link"/>\n    <origin xyz="0 0 ${base_height + 0.05}" rpy="0 0 0"/>\n  </joint>\n\n  <link name="lidar_link">\n    <visual>\n      <geometry>\n        <cylinder radius="0.05" length="0.05"/>\n      </geometry>\n      <material name="green">\n        <color rgba="0 0.8 0 1"/>\n      </material>\n    </visual>\n    <collision>\n      <geometry>\n        <cylinder radius="0.05" length="0.05"/>\n      </geometry>\n    </collision>\n    <inertial>\n      <mass value="0.1"/>\n      <inertia ixx="0.0001" ixy="0" ixz="0" iyy="0.0001" iyz="0" izz="0.0002"/>\n    </inertial>\n  </link>\n\n  \x3c!-- IMU --\x3e\n  <joint name="imu_joint" type="fixed">\n    <parent link="base_link"/>\n    <child link="imu_link"/>\n    <origin xyz="0 0 0" rpy="0 0 0"/>\n  </joint>\n\n  <link name="imu_link">\n    <inertial>\n      <mass value="0.01"/>\n      <inertia ixx="0.00001" ixy="0" ixz="0" iyy="0.00001" iyz="0" izz="0.00001"/>\n    </inertial>\n  </link>\n\n  \x3c!-- Gazebo plugins for sensors --\x3e\n  <gazebo reference="camera_link">\n    <sensor name="camera" type="camera">\n      <always_on>1</always_on>\n      <update_rate>30</update_rate>\n      <camera name="head_camera">\n        <horizontal_fov>1.047</horizontal_fov>\n        <image>\n          <width>640</width>\n          <height>480</height>\n          <format>R8G8B8</format>\n        </image>\n        <clip>\n          <near>0.1</near>\n          <far>30</far>\n        </clip>\n      </camera>\n      <plugin name="camera_controller" filename="libgazebo_ros_camera.so">\n        <frame_name>camera_link</frame_name>\n        <topic_name>camera/image_raw</topic_name>\n        <hack_baseline>0.07</hack_baseline>\n      </plugin>\n    </sensor>\n  </gazebo>\n\n  <gazebo reference="lidar_link">\n    <sensor name="3d_lidar" type="ray">\n      <always_on>1</always_on>\n      <update_rate>10</update_rate>\n      <ray>\n        <scan>\n          <horizontal>\n            <samples>360</samples>\n            <resolution>1</resolution>\n            <min_angle>-3.14159</min_angle>\n            <max_angle>3.14159</max_angle>\n          </horizontal>\n        </scan>\n        <range>\n          <min>0.1</min>\n          <max>10</max>\n          <resolution>0.01</resolution>\n        </range>\n      </ray>\n      <plugin name="lidar_controller" filename="libgazebo_ros_laser.so">\n        <topic_name>scan</topic_name>\n        <frame_name>lidar_link</frame_name>\n      </plugin>\n    </sensor>\n  </gazebo>\n\n  <gazebo reference="imu_link">\n    <sensor name="imu_sensor" type="imu">\n      <always_on>1</always_on>\n      <update_rate>100</update_rate>\n      <plugin name="imu_controller" filename="libgazebo_ros_imu.so">\n        <topic_name>imu/data</topic_name>\n        <frame_name>imu_link</frame_name>\n      </plugin>\n    </sensor>\n  </gazebo>\n\n  \x3c!-- Differential drive plugin --\x3e\n  <gazebo>\n    <plugin name="diff_drive" filename="libgazebo_ros_diff_drive.so">\n      <left_joint>left_wheel_joint</left_joint>\n      <right_joint>right_wheel_joint</right_joint>\n      <wheel_separation>0.3</wheel_separation>\n      <wheel_diameter>0.2</wheel_diameter>\n      <max_wheel_torque>20</max_wheel_torque>\n      <max_wheel_acceleration>1.0</max_wheel_acceleration>\n      <command_topic>cmd_vel</command_topic>\n      <odometry_topic>odom</odometry_topic>\n      <odometry_frame>odom</odometry_frame>\n      <robot_base_frame>base_link</robot_base_frame>\n      <publish_odom>true</publish_odom>\n      <publish_odom_tf>true</publish_odom_tf>\n      <publish_wheel_tf>true</publish_wheel_tf>\n    </plugin>\n  </gazebo>\n\n</robot>\n'})}),"\n",(0,o.jsx)(e.h4,{id:"step-2-sensor-fusion-node",children:"Step 2: Sensor Fusion Node"}),"\n",(0,o.jsxs)(e.p,{children:["Create ",(0,o.jsx)(e.code,{children:"basic_robot_simulation/basic_robot_simulation/sensor_fusion.py"}),":"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import LaserScan, Image, Imu\nfrom geometry_msgs.msg import Pose, Twist\nfrom nav_msgs.msg import Odometry\nfrom std_msgs.msg import Float32MultiArray\nfrom cv_bridge import CvBridge\nimport numpy as np\nimport math\n\nclass SensorFusionNode(Node):\n    def __init__(self):\n        super().__init__(\'sensor_fusion_node\')\n\n        # Publishers\n        self.fused_data_publisher = self.create_publisher(\n            Float32MultiArray, \'fused_sensor_data\', 10)\n        self.environment_map_publisher = self.create_publisher(\n            Float32MultiArray, \'environment_map\', 10)\n\n        # Subscribers\n        self.scan_subscription = self.create_subscription(\n            LaserScan, \'scan\', self.scan_callback, 10)\n        self.imu_subscription = self.create_subscription(\n            Imu, \'imu/data\', self.imu_callback, 10)\n        self.odom_subscription = self.create_subscription(\n            Odometry, \'odom\', self.odom_callback, 10)\n\n        # Timer for fusion processing\n        self.fusion_timer = self.create_timer(0.1, self.fusion_loop)\n\n        # Sensor data storage\n        self.latest_scan = None\n        self.latest_imu = None\n        self.latest_odom = None\n        self.cv_bridge = CvBridge()\n\n        # Environment mapping\n        self.map_resolution = 0.1  # meters per cell\n        self.map_size = 20  # meters (10m in each direction)\n        self.map_cells = int(self.map_size / self.map_resolution)\n        self.environment_map = np.zeros((self.map_cells, self.map_cells))\n\n        self.get_logger().info(\'Sensor Fusion Node Started\')\n\n    def scan_callback(self, msg):\n        """Process LiDAR scan data"""\n        self.latest_scan = msg\n\n        # Update environment map based on scan\n        if self.latest_odom:\n            self.update_map_from_scan(msg)\n\n    def imu_callback(self, msg):\n        """Process IMU data"""\n        self.latest_imu = msg\n\n    def odom_callback(self, msg):\n        """Process odometry data"""\n        self.latest_odom = msg\n\n    def update_map_from_scan(self, scan_msg):\n        """Update occupancy grid map from LiDAR scan"""\n        if not self.latest_odom:\n            return\n\n        robot_x = self.latest_odom.pose.pose.position.x\n        robot_y = self.latest_odom.pose.pose.position.y\n\n        # Convert quaternion to yaw\n        quat = self.latest_odom.pose.pose.orientation\n        siny_cosp = 2 * (quat.w * quat.z + quat.x * quat.y)\n        cosy_cosp = 1 - 2 * (quat.y * quat.y + quat.z * quat.z)\n        robot_yaw = math.atan2(siny_cosp, cosy_cosp)\n\n        # Process each ray in the scan\n        for i, range_val in enumerate(scan_msg.ranges):\n            if 0 < range_val < scan_msg.range_max:\n                # Calculate angle of this ray\n                angle = scan_msg.angle_min + i * scan_msg.angle_increment + robot_yaw\n\n                # Calculate world coordinates of detected point\n                world_x = robot_x + range_val * math.cos(angle)\n                world_y = robot_y + range_val * math.sin(angle)\n\n                # Convert to map coordinates\n                map_x = int((world_x + self.map_size/2) / self.map_resolution)\n                map_y = int((world_y + self.map_size/2) / self.map_resolution)\n\n                # Update map if coordinates are valid\n                if 0 <= map_x < self.map_cells and 0 <= map_y < self.map_cells:\n                    self.environment_map[map_y, map_x] = 1.0  # Mark as occupied\n\n    def fusion_loop(self):\n        """Main sensor fusion processing"""\n        if not all([self.latest_scan, self.latest_imu, self.latest_odom]):\n            return\n\n        # Create fused data array\n        fused_data = Float32MultiArray()\n\n        # Pack sensor data into array:\n        # [scan_min_range, scan_avg_range, imu_angular_velocity_z, robot_linear_x, robot_angular_z]\n        scan_ranges = [r for r in self.latest_scan.ranges if 0 < r < float(\'inf\')]\n        if scan_ranges:\n            scan_min = min(scan_ranges)\n            scan_avg = sum(scan_ranges) / len(scan_ranges)\n        else:\n            scan_min = 0.0\n            scan_avg = 0.0\n\n        imu_angular_z = self.latest_imu.angular_velocity.z\n        robot_linear_x = self.latest_odom.twist.twist.linear.x\n        robot_angular_z = self.latest_odom.twist.twist.angular.z\n\n        fused_data.data = [scan_min, scan_avg, imu_angular_z, robot_linear_x, robot_angular_z]\n\n        # Publish fused data\n        self.fused_data_publisher.publish(fused_data)\n\n        # Publish environment map\n        map_msg = Float32MultiArray()\n        map_msg.data = self.environment_map.flatten().tolist()\n        self.environment_map_publisher.publish(map_msg)\n\n        # Log fusion results\n        self.get_logger().info(f\'Fusion: Min Range={scan_min:.2f}, \'\n                              f\'IMU Angular Z={imu_angular_z:.2f}, \'\n                              f\'Robot Vel=({robot_linear_x:.2f}, {robot_angular_z:.2f})\',\n                              throttle_duration_sec=2)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    sensor_fusion_node = SensorFusionNode()\n\n    try:\n        rclpy.spin(sensor_fusion_node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        sensor_fusion_node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,o.jsx)(e.h4,{id:"step-3-enhanced-launch-file",children:"Step 3: Enhanced Launch File"}),"\n",(0,o.jsx)(e.p,{children:"Update the launch file to include sensor fusion:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"# Enhanced launch file with sensor fusion\nfrom launch import LaunchDescription\nfrom launch.actions import IncludeLaunchDescription, DeclareLaunchArgument\nfrom launch.launch_description_sources import PythonLaunchDescriptionSource\nfrom launch.substitutions import PathJoinSubstitution, LaunchConfiguration\nfrom launch_ros.actions import Node\nfrom launch_ros.substitutions import FindPackageShare\n\ndef generate_launch_description():\n    # Declare launch arguments\n    world_arg = DeclareLaunchArgument(\n        'world',\n        default_value='simple_room.sdf',\n        description='Choose one of the world files from `/basic_robot_simulation/worlds`'\n    )\n\n    # Launch Gazebo\n    gazebo = IncludeLaunchDescription(\n        PythonLaunchDescriptionSource([\n            PathJoinSubstitution([\n                FindPackageShare('gazebo_ros'),\n                'launch',\n                'gazebo.launch.py'\n            ])\n        ]),\n        launch_arguments={\n            'world': PathJoinSubstitution([\n                FindPackageShare('basic_robot_simulation'),\n                'worlds',\n                LaunchConfiguration('world')\n            ]),\n            'verbose': 'false'\n        }.items()\n    )\n\n    # Robot state publisher with enhanced model\n    robot_state_publisher = Node(\n        package='robot_state_publisher',\n        executable='robot_state_publisher',\n        parameters=[{\n            'robot_description': open(\n                PathJoinSubstitution([\n                    FindPackageShare('basic_robot_simulation'),\n                    'urdf',\n                    'sensor_robot.urdf'\n                ])\n            ).read()\n        }]\n    )\n\n    # Joint state publisher\n    joint_state_publisher = Node(\n        package='joint_state_publisher',\n        executable='joint_state_publisher',\n        parameters=[{'use_sim_time': True}]\n    )\n\n    # Robot controller node\n    robot_controller = Node(\n        package='basic_robot_simulation',\n        executable='robot_controller',\n        parameters=[{'use_sim_time': True}],\n        output='screen'\n    )\n\n    # Sensor fusion node\n    sensor_fusion = Node(\n        package='basic_robot_simulation',\n        executable='sensor_fusion',\n        parameters=[{'use_sim_time': True}],\n        output='screen'\n    )\n\n    return LaunchDescription([\n        world_arg,\n        gazebo,\n        robot_state_publisher,\n        joint_state_publisher,\n        robot_controller,\n        sensor_fusion\n    ])\n"})}),"\n",(0,o.jsx)(e.h3,{id:"lab-exercises-1",children:"Lab Exercises"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsx)(e.li,{children:"Implement a more sophisticated sensor fusion algorithm that combines multiple sensor inputs"}),"\n",(0,o.jsx)(e.li,{children:"Create an occupancy grid map from LiDAR data"}),"\n",(0,o.jsx)(e.li,{children:"Implement obstacle detection and avoidance using fused sensor data"}),"\n",(0,o.jsx)(e.li,{children:"Add visualizations for the fused sensor data"}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"expected-results-1",children:"Expected Results"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Multiple sensors working simultaneously"}),"\n",(0,o.jsx)(e.li,{children:"Sensor fusion node processing and combining data"}),"\n",(0,o.jsx)(e.li,{children:"Environment mapping from sensor data"}),"\n",(0,o.jsx)(e.li,{children:"Enhanced robot behavior based on fused information"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"lab-3-unity-visualization-integration",children:"Lab 3: Unity Visualization Integration"}),"\n",(0,o.jsx)(e.h3,{id:"objective-2",children:"Objective"}),"\n",(0,o.jsx)(e.p,{children:"Create a Unity visualization system that connects to the ROS 2 simulation and provides enhanced 3D visualization of the robot and environment."}),"\n",(0,o.jsx)(e.h3,{id:"implementation-steps-2",children:"Implementation Steps"}),"\n",(0,o.jsx)(e.h4,{id:"step-1-unity-setup-for-robotics",children:"Step 1: Unity Setup for Robotics"}),"\n",(0,o.jsx)(e.p,{children:"Create a Unity scene with the robot model and environment visualization:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// UnityRobotVisualizer.cs - Main visualization script\nusing UnityEngine;\nusing RosMessageTypes.Sensor;\nusing RosMessageTypes.Geometry;\nusing RosMessageTypes.Nav;\n\npublic class UnityRobotVisualizer : MonoBehaviour\n{\n    [Header("Robot Configuration")]\n    public GameObject robotModel;\n    public Transform robotTransform;\n\n    [Header("Sensor Visualization")]\n    public GameObject lidarPointCloud;\n    public GameObject cameraFeedDisplay;\n    public GameObject occupancyGrid;\n\n    [Header("ROS Connection")]\n    public string rosBridgeUrl = "ws://localhost:9090";\n    public string robotPoseTopic = "/odom";\n    public string lidarTopic = "/scan";\n    public string cameraTopic = "/camera/image_raw";\n\n    private RosConnection rosConnection;\n    private UnitySensorSimulation sensorSim;\n\n    void Start()\n    {\n        ConnectToROS();\n        SetupSubscribers();\n        InitializeVisualization();\n    }\n\n    void ConnectToROS()\n    {\n        rosConnection = GetComponent<RosConnection>();\n        rosConnection.rosBridgeServerUrl = rosBridgeUrl;\n    }\n\n    void SetupSubscribers()\n    {\n        rosConnection.Subscribe<OdometryMsg>(robotPoseTopic, UpdateRobotPose);\n        rosConnection.Subscribe<LaserScanMsg>(lidarTopic, ProcessLidarData);\n        rosConnection.Subscribe<ImageMsg>(cameraTopic, ProcessCameraData);\n    }\n\n    void InitializeVisualization()\n    {\n        if (robotModel == null)\n        {\n            robotModel = GameObject.CreatePrimitive(PrimitiveType.Capsule);\n            robotModel.name = "RobotModel";\n        }\n\n        robotTransform = robotModel.transform;\n    }\n\n    void UpdateRobotPose(OdometryMsg odom)\n    {\n        // Update robot position and orientation\n        Vector3 position = new Vector3(\n            (float)odom.pose.pose.position.x,\n            (float)odom.pose.pose.position.z, // Map Z to Unity Y for up direction\n            (float)odom.pose.pose.position.y  // Map Y to Unity Z\n        );\n\n        Quaternion rotation = new Quaternion(\n            (float)odom.pose.pose.orientation.x,\n            (float)odom.pose.pose.orientation.z,\n            (float)odom.pose.pose.orientation.y,\n            (float)odom.pose.pose.orientation.w\n        );\n\n        robotTransform.position = position;\n        robotTransform.rotation = rotation;\n    }\n\n    void ProcessLidarData(LaserScanMsg scan)\n    {\n        // Convert LiDAR data to Unity visualization\n        if (lidarPointCloud != null)\n        {\n            UpdateLidarVisualization(scan);\n        }\n    }\n\n    void ProcessCameraData(ImageMsg image)\n    {\n        // Process camera image for display\n        if (cameraFeedDisplay != null)\n        {\n            UpdateCameraVisualization(image);\n        }\n    }\n\n    void UpdateLidarVisualization(LaserScanMsg scan)\n    {\n        // This would typically update a point cloud visualization\n        // For this example, we\'ll just log the data\n        Debug.Log($"Received LiDAR scan with {scan.ranges.Length} points");\n    }\n\n    void UpdateCameraVisualization(ImageMsg image)\n    {\n        // This would update a texture with camera data\n        Debug.Log($"Received camera image: {image.width}x{image.height}");\n    }\n\n    void Update()\n    {\n        // Update visualization elements\n        UpdateEnvironment();\n    }\n\n    void UpdateEnvironment()\n    {\n        // Update environment visualization based on current state\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h4,{id:"step-2-environment-visualization",children:"Step 2: Environment Visualization"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// EnvironmentVisualizer.cs - Visualize the simulated environment\nusing UnityEngine;\n\npublic class EnvironmentVisualizer : MonoBehaviour\n{\n    [Header("Environment Configuration")]\n    public float mapSize = 20f;\n    public int resolution = 100;\n    public Material occupiedMaterial;\n    public Material freeSpaceMaterial;\n    public Material unknownMaterial;\n\n    private GameObject[,] gridCells;\n    private float cellSize;\n\n    void Start()\n    {\n        InitializeGrid();\n        GenerateEnvironment();\n    }\n\n    void InitializeGrid()\n    {\n        cellSize = mapSize / resolution;\n        gridCells = new GameObject[resolution, resolution];\n\n        // Create grid visualization\n        for (int x = 0; x < resolution; x++)\n        {\n            for (int z = 0; z < resolution; z++)\n            {\n                Vector3 position = new Vector3(\n                    (x - resolution / 2) * cellSize,\n                    0,\n                    (z - resolution / 2) * cellSize\n                );\n\n                GameObject cell = GameObject.CreatePrimitive(PrimitiveType.Quad);\n                cell.transform.position = position;\n                cell.transform.localScale = new Vector3(cellSize * 0.9f, 0.1f, cellSize * 0.9f);\n                cell.transform.rotation = Quaternion.Euler(90, 0, 0); // Face upward\n\n                cell.GetComponent<Renderer>().material = unknownMaterial;\n                cell.name = $"GridCell_{x}_{z}";\n\n                gridCells[x, z] = cell;\n            }\n        }\n    }\n\n    public void UpdateGridCell(int x, int z, float occupancy)\n    {\n        if (x >= 0 && x < resolution && z >= 0 && z < resolution)\n        {\n            GameObject cell = gridCells[x, z];\n            if (cell != null)\n            {\n                if (occupancy > 0.7f) // Occupied\n                {\n                    cell.GetComponent<Renderer>().material = occupiedMaterial;\n                }\n                else if (occupancy < 0.3f) // Free space\n                {\n                    cell.GetComponent<Renderer>().material = freeSpaceMaterial;\n                }\n                else // Unknown\n                {\n                    cell.GetComponent<Renderer>().material = unknownMaterial;\n                }\n            }\n        }\n    }\n\n    void GenerateEnvironment()\n    {\n        // Generate static environment elements\n        CreateWalls();\n        CreateObstacles();\n    }\n\n    void CreateWalls()\n    {\n        // Create boundary walls\n        float wallHeight = 2f;\n        float wallThickness = 0.1f;\n        float halfSize = mapSize / 2;\n\n        // Create 4 walls around the boundary\n        CreateWall(new Vector3(0, wallHeight/2, halfSize), new Vector3(mapSize, wallThickness, wallHeight), Color.gray);\n        CreateWall(new Vector3(0, wallHeight/2, -halfSize), new Vector3(mapSize, wallThickness, wallHeight), Color.gray);\n        CreateWall(new Vector3(halfSize, wallHeight/2, 0), new Vector3(wallThickness, wallThickness, mapSize), Color.gray);\n        CreateWall(new Vector3(-halfSize, wallHeight/2, 0), new Vector3(wallThickness, wallThickness, mapSize), Color.gray);\n    }\n\n    void CreateObstacles()\n    {\n        // Create some static obstacles in the environment\n        CreateObstacle(new Vector3(2, 0.5f, 2), new Vector3(0.5f, 1f, 0.5f), Color.red);\n        CreateObstacle(new Vector3(-2, 0.5f, -2), new Vector3(1f, 1f, 0.3f), Color.blue);\n    }\n\n    GameObject CreateWall(Vector3 position, Vector3 size, Color color)\n    {\n        GameObject wall = GameObject.CreatePrimitive(PrimitiveType.Cube);\n        wall.transform.position = position;\n        wall.transform.localScale = size;\n\n        Renderer renderer = wall.GetComponent<Renderer>();\n        Material material = new Material(Shader.Find("Standard"));\n        material.color = color;\n        renderer.material = material;\n\n        wall.AddComponent<Rigidbody>();\n        wall.GetComponent<Rigidbody>().isKinematic = true;\n\n        return wall;\n    }\n\n    GameObject CreateObstacle(Vector3 position, Vector3 size, Color color)\n    {\n        GameObject obstacle = GameObject.CreatePrimitive(PrimitiveType.Cube);\n        obstacle.transform.position = position;\n        obstacle.transform.localScale = size;\n\n        Renderer renderer = obstacle.GetComponent<Renderer>();\n        Material material = new Material(Shader.Find("Standard"));\n        material.color = color;\n        renderer.material = material;\n\n        obstacle.AddComponent<Rigidbody>();\n        obstacle.GetComponent<Rigidbody>().isKinematic = true;\n\n        return obstacle;\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h3,{id:"lab-exercises-2",children:"Lab Exercises"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsx)(e.li,{children:"Implement real-time visualization of LiDAR point clouds in Unity"}),"\n",(0,o.jsx)(e.li,{children:"Create a 3D occupancy grid visualization that updates from ROS 2 data"}),"\n",(0,o.jsx)(e.li,{children:"Implement camera feed display in the Unity scene"}),"\n",(0,o.jsx)(e.li,{children:"Add interactive controls to the Unity visualization"}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"expected-results-2",children:"Expected Results"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Unity visualization connected to ROS 2 simulation"}),"\n",(0,o.jsx)(e.li,{children:"Real-time robot position and orientation display"}),"\n",(0,o.jsx)(e.li,{children:"Environment visualization with obstacles"}),"\n",(0,o.jsx)(e.li,{children:"Sensor data visualization (LiDAR, camera)"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"troubleshooting-common-issues",children:"Troubleshooting Common Issues"}),"\n",(0,o.jsx)(e.h3,{id:"gazebo-simulation-issues",children:"Gazebo Simulation Issues"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Model Not Loading"}),": Check URDF/SDF syntax, file paths, and dependencies"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Physics Instability"}),": Adjust time steps, solver parameters, and mass properties"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Sensor Data Issues"}),": Verify plugin configuration and topic names"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Performance Problems"}),": Optimize collision meshes and reduce update rates"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"unity-integration-issues",children:"Unity Integration Issues"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Connection Problems"}),": Check ROS bridge connection and topic names"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Coordinate System Mismatch"}),": Verify coordinate system conversions"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Performance Issues"}),": Optimize Unity rendering and reduce update frequency"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Data Synchronization"}),": Ensure proper timing between systems"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"sensor-fusion-issues",children:"Sensor Fusion Issues"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Data Alignment"}),": Ensure all sensors are properly calibrated and synchronized"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Noise Filtering"}),": Implement appropriate filtering for sensor data"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Algorithm Performance"}),": Optimize fusion algorithms for real-time operation"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"lab-report-template",children:"Lab Report Template"}),"\n",(0,o.jsx)(e.h3,{id:"lab-documentation-requirements",children:"Lab Documentation Requirements"}),"\n",(0,o.jsx)(e.p,{children:"Each lab should include:"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Objective"}),": Clear statement of what was implemented"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Implementation"}),": Code snippets and explanations"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Results"}),": What worked, what didn't, and why"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Analysis"}),": Discussion of challenges and solutions"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Extensions"}),": Ideas for improvement or additional features"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"evaluation-criteria",children:"Evaluation Criteria"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Functionality"}),": Does the implementation work as expected?"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Code Quality"}),": Is the code well-structured and documented?"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Understanding"}),": Does the student demonstrate understanding of concepts?"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Creativity"}),": Are there innovative solutions or extensions?"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Problem-Solving"}),": How effectively were challenges addressed?"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"review-questions",children:"Review Questions"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsx)(e.li,{children:"How do you configure multiple sensors on a robot model in Gazebo?"}),"\n",(0,o.jsx)(e.li,{children:"What are the key considerations for sensor fusion in robotics applications?"}),"\n",(0,o.jsx)(e.li,{children:"How do you optimize Gazebo simulation performance for real-time applications?"}),"\n",(0,o.jsx)(e.li,{children:"What are the challenges of integrating Unity with ROS 2 for visualization?"}),"\n",(0,o.jsx)(e.li,{children:"How do you validate the accuracy of simulated sensors against real sensors?"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,o.jsx)(e.p,{children:"After completing these practical labs, students should be able to:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Design and implement comprehensive simulation environments"}),"\n",(0,o.jsx)(e.li,{children:"Integrate multiple sensor systems for enhanced perception"}),"\n",(0,o.jsx)(e.li,{children:"Create advanced visualization systems for robotics"}),"\n",(0,o.jsx)(e.li,{children:"Apply learned concepts to real-world robotics challenges"}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:"These hands-on labs provide essential practical experience that bridges the gap between theoretical knowledge and real-world robotics simulation and visualization systems."})]})}function m(n={}){const{wrapper:e}={...(0,t.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>s,x:()=>r});var a=i(6540);const o={},t=a.createContext(o);function s(n){const e=a.useContext(t);return a.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:s(n.components),a.createElement(t.Provider,{value:e},n.children)}}}]);