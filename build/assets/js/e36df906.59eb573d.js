"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_textbook=globalThis.webpackChunkphysical_ai_humanoid_robotics_textbook||[]).push([[4136],{4561:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>a,default:()=>u,frontMatter:()=>r,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"module-2/unity-visualization","title":"Unity Visualization","description":"Overview","source":"@site/docs/module-2/unity-visualization.md","sourceDirName":"module-2","slug":"/module-2/unity-visualization","permalink":"/docs/module-2/unity-visualization","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-2/unity-visualization.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5},"sidebar":"tutorialSidebar","previous":{"title":"Gazebo Workflows","permalink":"/docs/module-2/gazebo-workflows"},"next":{"title":"Digital Twin Practical Labs","permalink":"/docs/module-2/digital-twin-practical-labs"}}');var o=i(4848),s=i(8453);const r={sidebar_position:5},a="Unity Visualization",l={},c=[{value:"Overview",id:"overview",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Key Concepts",id:"key-concepts",level:2},{value:"Unity in Robotics Context",id:"unity-in-robotics-context",level:3},{value:"Unity vs. Gazebo",id:"unity-vs-gazebo",level:3},{value:"Rendering Pipelines",id:"rendering-pipelines",level:3},{value:"Unity Setup for Robotics",id:"unity-setup-for-robotics",level:2},{value:"Installation and Configuration",id:"installation-and-configuration",level:3},{value:"Unity Project Structure for Robotics",id:"unity-project-structure-for-robotics",level:3},{value:"Robot Model Integration",id:"robot-model-integration",level:2},{value:"Importing Robot Models",id:"importing-robot-models",level:3},{value:"Robot Kinematics Setup",id:"robot-kinematics-setup",level:3},{value:"Environment Design",id:"environment-design",level:2},{value:"Creating Realistic Environments",id:"creating-realistic-environments",level:3},{value:"Dynamic Environment Elements",id:"dynamic-environment-elements",level:3},{value:"ROS 2 Integration",id:"ros-2-integration",level:2},{value:"Unity ROS Integration Package",id:"unity-ros-integration-package",level:3},{value:"Sensor Simulation in Unity",id:"sensor-simulation-in-unity",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"Rendering Optimization Techniques",id:"rendering-optimization-techniques",level:3},{value:"User Interface and Interaction",id:"user-interface-and-interaction",level:2},{value:"Robotics UI System",id:"robotics-ui-system",level:3},{value:"Advanced Visualization Techniques",id:"advanced-visualization-techniques",level:2},{value:"Point Cloud Visualization",id:"point-cloud-visualization",level:3},{value:"Deployment and Distribution",id:"deployment-and-distribution",level:2},{value:"Building for Different Platforms",id:"building-for-different-platforms",level:3},{value:"Best Practices and Guidelines",id:"best-practices-and-guidelines",level:2},{value:"Performance Guidelines",id:"performance-guidelines",level:3},{value:"Quality Assurance",id:"quality-assurance",level:3},{value:"Development Workflow",id:"development-workflow",level:3},{value:"Troubleshooting Common Issues",id:"troubleshooting-common-issues",level:2},{value:"Performance Problems",id:"performance-problems",level:3},{value:"Rendering Issues",id:"rendering-issues",level:3},{value:"Integration Issues",id:"integration-issues",level:3},{value:"Practical Lab: Unity Robotics Visualization",id:"practical-lab-unity-robotics-visualization",level:2},{value:"Lab Objective",id:"lab-objective",level:3},{value:"Implementation Steps",id:"implementation-steps",level:3},{value:"Expected Outcome",id:"expected-outcome",level:3},{value:"Review Questions",id:"review-questions",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"unity-visualization",children:"Unity Visualization"})}),"\n",(0,o.jsx)(e.h2,{id:"overview",children:"Overview"}),"\n",(0,o.jsx)(e.p,{children:"Unity visualization provides advanced 3D rendering capabilities for robotics applications, offering photorealistic environments and high-performance graphics. This section covers the integration of Unity with robotics workflows, creating immersive visualization experiences for Physical AI and Humanoid Robotics applications."}),"\n",(0,o.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,o.jsx)(e.p,{children:"By the end of this section, students will be able to:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Set up Unity for robotics visualization applications"}),"\n",(0,o.jsx)(e.li,{children:"Create and import robot models with proper kinematics"}),"\n",(0,o.jsx)(e.li,{children:"Implement realistic environments and lighting"}),"\n",(0,o.jsx)(e.li,{children:"Integrate Unity with ROS 2 communication systems"}),"\n",(0,o.jsx)(e.li,{children:"Optimize Unity scenes for real-time robotics applications"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"key-concepts",children:"Key Concepts"}),"\n",(0,o.jsx)(e.h3,{id:"unity-in-robotics-context",children:"Unity in Robotics Context"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Photorealistic Rendering"}),": High-quality graphics for realistic perception simulation"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Real-time Performance"}),": Optimized rendering for interactive robotics applications"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Physics Simulation"}),": Built-in physics engine for basic simulation needs"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Cross-platform Deployment"}),": Support for various hardware and operating systems"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Asset Integration"}),": Easy import of 3D models, animations, and materials"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"unity-vs-gazebo",children:"Unity vs. Gazebo"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Unity"}),": Better for visualization, rendering, and user interaction"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Gazebo"}),": Better for physics simulation and sensor modeling"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Hybrid Approach"}),": Use Unity for visualization, Gazebo for physics"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Data Exchange"}),": Realistic sensor data from Gazebo, rendered in Unity"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"rendering-pipelines",children:"Rendering Pipelines"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Built-in Render Pipeline"}),": Standard Unity rendering (good for basic needs)"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Universal Render Pipeline (URP)"}),": Optimized for performance across platforms"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"High Definition Render Pipeline (HDRP)"}),": High-quality rendering for advanced visuals"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Custom Pipelines"}),": Tailored rendering for specific robotics needs"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"unity-setup-for-robotics",children:"Unity Setup for Robotics"}),"\n",(0,o.jsx)(e.h3,{id:"installation-and-configuration",children:"Installation and Configuration"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-bash",children:"# Download Unity Hub\n# Install Unity 2022.3 LTS or later (recommended for stability)\n\n# Required packages for robotics:\n# - Physics (for basic collision detection)\n# - XR (for VR/AR applications)\n# - 2D (for UI and overlays)\n# - TextMeshPro (for UI text)\n# - ProBuilder (for rapid prototyping)\n"})}),"\n",(0,o.jsx)(e.h3,{id:"unity-project-structure-for-robotics",children:"Unity Project Structure for Robotics"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{children:"RoboticsVisualization/\n\u251c\u2500\u2500 Assets/\n\u2502   \u251c\u2500\u2500 Models/                 # Robot and environment models\n\u2502   \u2502   \u251c\u2500\u2500 Robots/\n\u2502   \u2502   \u251c\u2500\u2500 Environments/\n\u2502   \u2502   \u2514\u2500\u2500 Props/\n\u2502   \u251c\u2500\u2500 Scripts/                # C# scripts for robotics integration\n\u2502   \u2502   \u251c\u2500\u2500 ROSIntegration/\n\u2502   \u2502   \u251c\u2500\u2500 RobotControllers/\n\u2502   \u2502   \u251c\u2500\u2500 SensorSimulators/\n\u2502   \u2502   \u2514\u2500\u2500 UI/\n\u2502   \u251c\u2500\u2500 Materials/              # Surface materials and shaders\n\u2502   \u251c\u2500\u2500 Textures/               # Image textures\n\u2502   \u251c\u2500\u2500 Scenes/                 # Unity scene files\n\u2502   \u251c\u2500\u2500 Prefabs/                # Reusable game objects\n\u2502   \u251c\u2500\u2500 Animations/             # Robot animations and movements\n\u2502   \u2514\u2500\u2500 Plugins/                # External libraries and tools\n\u251c\u2500\u2500 ProjectSettings/\n\u2514\u2500\u2500 Packages/\n"})}),"\n",(0,o.jsx)(e.h2,{id:"robot-model-integration",children:"Robot Model Integration"}),"\n",(0,o.jsx)(e.h3,{id:"importing-robot-models",children:"Importing Robot Models"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// Example script for importing and configuring robot models\nusing UnityEngine;\n\npublic class RobotModelImporter : MonoBehaviour\n{\n    [Header("Robot Configuration")]\n    public string robotName;\n    public float robotScale = 1.0f;\n    public bool usePhysicalColliders = true;\n\n    [Header("Joint Configuration")]\n    public Transform[] jointTransforms;\n    public ConfigurableJoint[] configurableJoints;\n\n    void Start()\n    {\n        SetupRobotModel();\n        ConfigureJoints();\n        SetupColliders();\n    }\n\n    void SetupRobotModel()\n    {\n        // Apply scale and positioning\n        transform.localScale = Vector3.one * robotScale;\n\n        // Center the model at origin\n        CenterModel();\n    }\n\n    void ConfigureJoints()\n    {\n        // Configure each joint with appropriate limits and constraints\n        foreach (var joint in configurableJoints)\n        {\n            // Set joint configuration based on robot specifications\n            joint.xMotion = ConfigurableJointMotion.Locked;\n            joint.yMotion = ConfigurableJointMotion.Locked;\n            joint.zMotion = ConfigurableJointMotion.Locked;\n\n            // Configure angular limits based on real robot\n            joint.angularXMotion = ConfigurableJointMotion.Limited;\n            joint.angularYMotion = ConfigurableJointMotion.Limited;\n            joint.angularZMotion = ConfigurableJointMotion.Limited;\n        }\n    }\n\n    void SetupColliders()\n    {\n        if (usePhysicalColliders)\n        {\n            // Add colliders to each link\n            AddCollidersToLinks();\n        }\n    }\n\n    void CenterModel()\n    {\n        // Calculate center of mass and reposition\n        // Implementation depends on specific robot model\n    }\n\n    void AddCollidersToLinks()\n    {\n        // Add appropriate colliders to each robot link\n        // Use simplified geometry for performance\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h3,{id:"robot-kinematics-setup",children:"Robot Kinematics Setup"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:"// Forward kinematics implementation\nusing UnityEngine;\n\npublic class RobotForwardKinematics : MonoBehaviour\n{\n    public Transform[] jointChain;\n    public Transform endEffector;\n\n    [System.Serializable]\n    public class JointConfiguration\n    {\n        public float angle;\n        public float minAngle = -180f;\n        public float maxAngle = 180f;\n        public float offset = 0f;\n    }\n\n    public JointConfiguration[] jointConfigurations;\n\n    void UpdateRobotPosition()\n    {\n        for (int i = 0; i < jointChain.Length; i++)\n        {\n            if (i < jointConfigurations.Length)\n            {\n                float finalAngle = jointConfigurations[i].angle + jointConfigurations[i].offset;\n                jointChain[i].localEulerAngles = new Vector3(0, finalAngle, 0);\n            }\n        }\n    }\n\n    public Vector3 CalculateEndEffectorPosition()\n    {\n        if (endEffector != null)\n        {\n            return endEffector.position;\n        }\n        return Vector3.zero;\n    }\n\n    public void SetJointAngles(float[] angles)\n    {\n        if (angles.Length == jointConfigurations.Length)\n        {\n            for (int i = 0; i < angles.Length; i++)\n            {\n                jointConfigurations[i].angle = Mathf.Clamp(angles[i],\n                    jointConfigurations[i].minAngle,\n                    jointConfigurations[i].maxAngle);\n            }\n            UpdateRobotPosition();\n        }\n    }\n}\n"})}),"\n",(0,o.jsx)(e.h2,{id:"environment-design",children:"Environment Design"}),"\n",(0,o.jsx)(e.h3,{id:"creating-realistic-environments",children:"Creating Realistic Environments"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// Environment setup script\nusing UnityEngine;\nusing UnityEngine.Rendering;\n\npublic class EnvironmentSetup : MonoBehaviour\n{\n    [Header("Lighting Configuration")]\n    public Light mainLight;\n    public float ambientIntensity = 1.0f;\n    public Color ambientColor = Color.white;\n\n    [Header("Environment Settings")]\n    public Material[] environmentMaterials;\n    public GameObject[] staticObstacles;\n    public bool enableReflections = true;\n\n    void Start()\n    {\n        ConfigureLighting();\n        SetupEnvironment();\n        OptimizeForPerformance();\n    }\n\n    void ConfigureLighting()\n    {\n        // Set up main directional light\n        if (mainLight != null)\n        {\n            mainLight.type = LightType.Directional;\n            mainLight.intensity = ambientIntensity;\n            RenderSettings.ambientLight = ambientColor;\n        }\n\n        // Configure reflection probes for realistic lighting\n        if (enableReflections)\n        {\n            SetupReflectionProbes();\n        }\n    }\n\n    void SetupEnvironment()\n    {\n        // Add static obstacles to environment\n        foreach (var obstacle in staticObstacles)\n        {\n            obstacle.AddComponent<Rigidbody>();\n            obstacle.GetComponent<Rigidbody>().isKinematic = true;\n        }\n\n        // Apply materials to environment\n        ApplyEnvironmentMaterials();\n    }\n\n    void SetupReflectionProbes()\n    {\n        // Add reflection probes for realistic lighting\n        // Position probes strategically throughout the environment\n    }\n\n    void ApplyEnvironmentMaterials()\n    {\n        // Apply appropriate materials to environment objects\n        // Use physically-based materials for realism\n    }\n\n    void OptimizeForPerformance()\n    {\n        // Enable occlusion culling\n        // Optimize draw calls\n        // Use level of detail (LOD) systems\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h3,{id:"dynamic-environment-elements",children:"Dynamic Environment Elements"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// Script for dynamic environment objects\nusing UnityEngine;\n\npublic class DynamicEnvironment : MonoBehaviour\n{\n    [Header("Moving Objects")]\n    public GameObject[] movingObjects;\n    public float movementSpeed = 1.0f;\n    public Vector3 movementRange = new Vector3(5, 0, 5);\n\n    [Header("Interactive Elements")]\n    public GameObject[] interactiveObjects;\n    public bool enablePhysics = true;\n\n    private Vector3[] initialPositions;\n\n    void Start()\n    {\n        StoreInitialPositions();\n        SetupDynamicElements();\n    }\n\n    void StoreInitialPositions()\n    {\n        initialPositions = new Vector3[movingObjects.Length];\n        for (int i = 0; i < movingObjects.Length; i++)\n        {\n            initialPositions[i] = movingObjects[i].transform.position;\n        }\n    }\n\n    void SetupDynamicElements()\n    {\n        foreach (var obj in movingObjects)\n        {\n            if (enablePhysics)\n            {\n                obj.AddComponent<Rigidbody>();\n                obj.GetComponent<Rigidbody>().useGravity = false;\n            }\n        }\n    }\n\n    void Update()\n    {\n        MoveDynamicObjects();\n    }\n\n    void MoveDynamicObjects()\n    {\n        for (int i = 0; i < movingObjects.Length; i++)\n        {\n            // Move objects in a periodic pattern\n            Vector3 offset = new Vector3(\n                Mathf.Sin(Time.time * movementSpeed + i) * movementRange.x,\n                0,\n                Mathf.Cos(Time.time * movementSpeed + i) * movementRange.z\n            );\n\n            movingObjects[i].transform.position = initialPositions[i] + offset;\n        }\n    }\n\n    public void AddDynamicObject(GameObject obj)\n    {\n        // Add a new dynamic object to the environment\n        System.Array.Resize(ref movingObjects, movingObjects.Length + 1);\n        movingObjects[movingObjects.Length - 1] = obj;\n        System.Array.Resize(ref initialPositions, initialPositions.Length + 1);\n        initialPositions[initialPositions.Length - 1] = obj.transform.position;\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h2,{id:"ros-2-integration",children:"ROS 2 Integration"}),"\n",(0,o.jsx)(e.h3,{id:"unity-ros-integration-package",children:"Unity ROS Integration Package"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// Example ROS communication script\nusing System.Collections;\nusing System.Collections.Generic;\nusing UnityEngine;\nusing RosMessageTypes.Sensor;\nusing RosMessageTypes.Geometry;\n\npublic class UnityROSInterface : MonoBehaviour\n{\n    [Header("ROS Connection")]\n    public string rosBridgeUrl = "ws://localhost:9090";\n\n    [Header("Robot Topics")]\n    public string jointStatesTopic = "/joint_states";\n    public string cmdVelTopic = "/cmd_vel";\n    public string laserScanTopic = "/scan";\n\n    // ROS connection and publishers/subscribers\n    private RosConnection rosConnection;\n\n    void Start()\n    {\n        ConnectToROS();\n        SetupSubscribers();\n        SetupPublishers();\n    }\n\n    void ConnectToROS()\n    {\n        // Initialize ROS connection\n        rosConnection = GetComponent<RosConnection>();\n        rosConnection.rosBridgeServerUrl = rosBridgeUrl;\n    }\n\n    void SetupSubscribers()\n    {\n        // Subscribe to joint states\n        rosConnection.Subscribe<JointStateMsg>(jointStatesTopic, UpdateRobotJoints);\n\n        // Subscribe to velocity commands\n        rosConnection.Subscribe<TwistMsg>(cmdVelTopic, ProcessVelocityCommand);\n    }\n\n    void SetupPublishers()\n    {\n        // Publishers will be created as needed\n    }\n\n    void UpdateRobotJoints(JointStateMsg jointState)\n    {\n        // Update robot model based on joint states\n        // This would typically call the kinematics script\n        RobotForwardKinematics kinematics = GetComponent<RobotForwardKinematics>();\n        if (kinematics != null && jointState.position.Length == kinematics.jointConfigurations.Length)\n        {\n            float[] angles = new float[jointState.position.Length];\n            for (int i = 0; i < jointState.position.Length; i++)\n            {\n                angles[i] = (float)jointState.position[i];\n            }\n            kinematics.SetJointAngles(angles);\n        }\n    }\n\n    void ProcessVelocityCommand(TwistMsg twist)\n    {\n        // Process velocity commands\n        // Update robot movement in Unity\n        UpdateRobotMovement(twist);\n    }\n\n    void UpdateRobotMovement(TwistMsg twist)\n    {\n        // Apply velocity to robot in Unity\n        Rigidbody rb = GetComponent<Rigidbody>();\n        if (rb != null)\n        {\n            rb.velocity = new Vector3((float)twist.linear.x, 0, (float)twist.linear.y);\n            rb.angularVelocity = new Vector3(0, (float)twist.angular.z, 0);\n        }\n    }\n\n    // Method to publish sensor data back to ROS\n    public void PublishLaserScan(float[] ranges, float angleMin, float angleMax, float angleIncrement)\n    {\n        LaserScanMsg scanMsg = new LaserScanMsg();\n        scanMsg.ranges = System.Array.ConvertAll(ranges, x => (float)x);\n        scanMsg.angle_min = angleMin;\n        scanMsg.angle_max = angleMax;\n        scanMsg.angle_increment = angleIncrement;\n        scanMsg.time_increment = 0.01f; // Example value\n        scanMsg.scan_time = 0.1f; // Example value\n        scanMsg.range_min = 0.1f;\n        scanMsg.range_max = 10.0f;\n\n        rosConnection.Publish(laserScanTopic, scanMsg);\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h3,{id:"sensor-simulation-in-unity",children:"Sensor Simulation in Unity"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// Unity-based sensor simulation\nusing UnityEngine;\n\npublic class UnitySensorSimulation : MonoBehaviour\n{\n    [Header("Camera Sensor")]\n    public Camera sensorCamera;\n    public int imageWidth = 640;\n    public int imageHeight = 480;\n    public float fieldOfView = 60f;\n\n    [Header("LiDAR Sensor")]\n    public float lidarRange = 10f;\n    public int lidarResolution = 360;\n    public float lidarAngleMin = -Mathf.PI;\n    public float lidarAngleMax = Mathf.PI;\n\n    [Header("Sensor Output")]\n    public bool publishToROS = true;\n    public string sensorTopic = "/sensor_data";\n\n    private RenderTexture sensorTexture;\n    private UnityROSInterface rosInterface;\n\n    void Start()\n    {\n        SetupSensors();\n        rosInterface = FindObjectOfType<UnityROSInterface>();\n    }\n\n    void SetupSensors()\n    {\n        // Configure camera sensor\n        if (sensorCamera != null)\n        {\n            sensorCamera.fieldOfView = fieldOfView;\n            sensorTexture = new RenderTexture(imageWidth, imageHeight, 24);\n            sensorCamera.targetTexture = sensorTexture;\n        }\n    }\n\n    void Update()\n    {\n        SimulateSensors();\n    }\n\n    void SimulateSensors()\n    {\n        // Simulate camera data\n        SimulateCamera();\n\n        // Simulate LiDAR data\n        SimulateLiDAR();\n    }\n\n    void SimulateCamera()\n    {\n        if (sensorCamera != null)\n        {\n            // Render to texture\n            sensorCamera.Render();\n\n            // Convert to format suitable for ROS\n            if (publishToROS)\n            {\n                Texture2D image = RenderTextureToTexture2D(sensorTexture);\n                // Publish image to ROS (implementation depends on ROS package used)\n            }\n        }\n    }\n\n    void SimulateLiDAR()\n    {\n        float[] ranges = new float[lidarResolution];\n\n        for (int i = 0; i < lidarResolution; i++)\n        {\n            float angle = lidarAngleMin + (lidarAngleMax - lidarAngleMin) * i / lidarResolution;\n\n            // Raycast to simulate LiDAR measurement\n            Vector3 direction = new Vector3(Mathf.Cos(angle), 0, Mathf.Sin(angle));\n            RaycastHit hit;\n\n            if (Physics.Raycast(transform.position, transform.TransformDirection(direction), out hit, lidarRange))\n            {\n                ranges[i] = hit.distance;\n            }\n            else\n            {\n                ranges[i] = lidarRange; // No obstacle detected\n            }\n        }\n\n        // Publish LiDAR data to ROS if needed\n        if (publishToROS && rosInterface != null)\n        {\n            rosInterface.PublishLaserScan(\n                ranges,\n                lidarAngleMin,\n                lidarAngleMax,\n                (lidarAngleMax - lidarAngleMin) / lidarResolution\n            );\n        }\n    }\n\n    Texture2D RenderTextureToTexture2D(RenderTexture rt)\n    {\n        Texture2D tex = new Texture2D(rt.width, rt.height, TextureFormat.RGB24, false);\n        RenderTexture.active = rt;\n        tex.ReadPixels(new Rect(0, 0, rt.width, rt.height), 0, 0);\n        tex.Apply();\n        RenderTexture.active = null;\n        return tex;\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,o.jsx)(e.h3,{id:"rendering-optimization-techniques",children:"Rendering Optimization Techniques"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// Performance optimization script\nusing UnityEngine;\nusing System.Collections.Generic;\n\npublic class PerformanceOptimizer : MonoBehaviour\n{\n    [Header("LOD Configuration")]\n    public float lodDistance = 10f;\n    public int lodCount = 3;\n\n    [Header("Occlusion Culling")]\n    public bool enableOcclusionCulling = true;\n\n    [Header("Dynamic Batching")]\n    public bool enableDynamicBatching = true;\n\n    [Header("Object Pooling")]\n    public int poolSize = 100;\n\n    private List<GameObject> objectPool;\n    private Camera mainCamera;\n\n    void Start()\n    {\n        mainCamera = Camera.main;\n        SetupOptimizations();\n        InitializeObjectPool();\n    }\n\n    void SetupOptimizations()\n    {\n        // Configure LOD system\n        SetupLODGroups();\n\n        // Enable occlusion culling\n        if (enableOcclusionCulling)\n        {\n            EnableOcclusionCulling();\n        }\n\n        // Configure batching settings\n        ConfigureBatching();\n    }\n\n    void SetupLODGroups()\n    {\n        // Create LOD groups for complex objects\n        LODGroup[] lodGroups = FindObjectsOfType<LODGroup>();\n        foreach (var lodGroup in lodGroups)\n        {\n            LOD[] lods = new LOD[lodCount];\n            float[] screenSizes = new float[lodCount];\n\n            for (int i = 0; i < lodCount; i++)\n            {\n                screenSizes[i] = 1.0f / (i + 1);\n            }\n\n            // Configure LODs based on distance\n            for (int i = 0; i < lodCount; i++)\n            {\n                float distance = lodDistance * (i + 1);\n                lods[i] = new LOD(screenSizes[i], GetRenderersForLOD(i));\n            }\n\n            lodGroup.SetLODs(lods);\n        }\n    }\n\n    Renderer[] GetRenderersForLOD(int lodLevel)\n    {\n        // Return appropriate renderers for each LOD level\n        // Implementation depends on specific model structure\n        return new Renderer[0];\n    }\n\n    void EnableOcclusionCulling()\n    {\n        // Configure occlusion culling settings\n        // This is typically done in Unity Editor, but can be configured here\n    }\n\n    void ConfigureBatching()\n    {\n        // Configure dynamic batching\n        // Dynamic batching is enabled by default in Unity\n    }\n\n    void InitializeObjectPool()\n    {\n        objectPool = new List<GameObject>();\n        // Pre-instantiate objects for pooling\n        for (int i = 0; i < poolSize; i++)\n        {\n            GameObject obj = new GameObject();\n            obj.SetActive(false);\n            objectPool.Add(obj);\n        }\n    }\n\n    public GameObject GetPooledObject()\n    {\n        foreach (var obj in objectPool)\n        {\n            if (!obj.activeInHierarchy)\n            {\n                obj.SetActive(true);\n                return obj;\n            }\n        }\n\n        // If pool is empty, create new object\n        GameObject newObj = new GameObject();\n        objectPool.Add(newObj);\n        return newObj;\n    }\n\n    void Update()\n    {\n        OptimizeRendering();\n    }\n\n    void OptimizeRendering()\n    {\n        // Implement frame rate optimization\n        // Reduce quality when performance drops\n        if (Time.unscaledDeltaTime > 1.0f / 30.0f) // Target 30 FPS minimum\n        {\n            ReduceRenderingQuality();\n        }\n        else\n        {\n            RestoreRenderingQuality();\n        }\n    }\n\n    void ReduceRenderingQuality()\n    {\n        // Reduce shadow quality, disable effects, etc.\n        QualitySettings.shadowResolution = ShadowResolution.Low;\n        // Disable expensive effects\n    }\n\n    void RestoreRenderingQuality()\n    {\n        // Restore quality settings\n        QualitySettings.shadowResolution = ShadowResolution.Medium;\n        // Re-enable effects\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h2,{id:"user-interface-and-interaction",children:"User Interface and Interaction"}),"\n",(0,o.jsx)(e.h3,{id:"robotics-ui-system",children:"Robotics UI System"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// UI for robotics visualization\nusing UnityEngine;\nusing UnityEngine.UI;\nusing TMPro;\n\npublic class RoboticsUI : MonoBehaviour\n{\n    [Header("Robot Status Panel")]\n    public TextMeshProUGUI robotStatusText;\n    public TextMeshProUGUI jointAngleText;\n    public TextMeshProUGUI positionText;\n\n    [Header("Sensor Data Panel")]\n    public TextMeshProUGUI sensorStatusText;\n    public TextMeshProUGUI cameraResolutionText;\n    public TextMeshProUGUI lidarRangeText;\n\n    [Header("Control Panel")]\n    public Slider linearVelocitySlider;\n    public Slider angularVelocitySlider;\n    public Button resetButton;\n    public Button pauseButton;\n\n    [Header("Visualization Controls")]\n    public Toggle wireframeToggle;\n    public Toggle collisionToggle;\n    public Slider transparencySlider;\n\n    private UnityROSInterface rosInterface;\n    private RobotForwardKinematics robotKinematics;\n\n    void Start()\n    {\n        SetupUI();\n        SetupEventHandlers();\n    }\n\n    void SetupUI()\n    {\n        rosInterface = FindObjectOfType<UnityROSInterface>();\n        robotKinematics = FindObjectOfType<RobotForwardKinematics>();\n\n        // Initialize UI elements\n        if (linearVelocitySlider != null)\n            linearVelocitySlider.minValue = -1.0f;\n            linearVelocitySlider.maxValue = 1.0f;\n\n        if (angularVelocitySlider != null)\n            angularVelocitySlider.minValue = -1.0f;\n            angularVelocitySlider.maxValue = 1.0f;\n    }\n\n    void SetupEventHandlers()\n    {\n        if (resetButton != null)\n            resetButton.onClick.AddListener(ResetRobot);\n\n        if (pauseButton != null)\n            pauseButton.onClick.AddListener(TogglePause);\n\n        if (linearVelocitySlider != null)\n            linearVelocitySlider.onValueChanged.AddListener(OnLinearVelocityChanged);\n\n        if (angularVelocitySlider != null)\n            angularVelocitySlider.onValueChanged.AddListener(OnAngularVelocityChanged);\n\n        if (wireframeToggle != null)\n            wireframeToggle.onValueChanged.AddListener(OnWireframeToggled);\n\n        if (collisionToggle != null)\n            collisionToggle.onValueChanged.AddListener(OnCollisionToggled);\n    }\n\n    void Update()\n    {\n        UpdateRobotStatus();\n        UpdateSensorStatus();\n    }\n\n    void UpdateRobotStatus()\n    {\n        if (robotStatusText != null)\n        {\n            robotStatusText.text = "Robot Status: Active";\n        }\n\n        if (jointAngleText != null && robotKinematics != null)\n        {\n            string jointText = "Joint Angles:\\n";\n            for (int i = 0; i < robotKinematics.jointConfigurations.Length; i++)\n            {\n                jointText += $"Joint {i}: {robotKinematics.jointConfigurations[i].angle:F2}\xb0\\n";\n            }\n            jointAngleText.text = jointText;\n        }\n\n        if (positionText != null)\n        {\n            Vector3 pos = transform.position;\n            positionText.text = $"Position: ({pos.x:F2}, {pos.y:F2}, {pos.z:F2})";\n        }\n    }\n\n    void UpdateSensorStatus()\n    {\n        if (sensorStatusText != null)\n        {\n            sensorStatusText.text = "Sensors: Active";\n        }\n\n        if (cameraResolutionText != null)\n        {\n            cameraResolutionText.text = "Camera: 640x480";\n        }\n\n        if (lidarRangeText != null)\n        {\n            lidarRangeText.text = "LiDAR Range: 10m";\n        }\n    }\n\n    void ResetRobot()\n    {\n        // Reset robot to initial position\n        transform.position = Vector3.zero;\n        transform.rotation = Quaternion.identity;\n\n        // Reset joint angles\n        if (robotKinematics != null)\n        {\n            for (int i = 0; i < robotKinematics.jointConfigurations.Length; i++)\n            {\n                robotKinematics.jointConfigurations[i].angle = 0f;\n            }\n            robotKinematics.UpdateRobotPosition();\n        }\n    }\n\n    void TogglePause()\n    {\n        Time.timeScale = Time.timeScale == 0 ? 1 : 0;\n        pauseButton.GetComponentInChildren<TextMeshProUGUI>().text =\n            Time.timeScale == 0 ? "Resume" : "Pause";\n    }\n\n    void OnLinearVelocityChanged(float value)\n    {\n        // Send velocity command to ROS\n        if (rosInterface != null)\n        {\n            // Implementation depends on ROS interface\n        }\n    }\n\n    void OnAngularVelocityChanged(float value)\n    {\n        // Send angular velocity command to ROS\n        if (rosInterface != null)\n        {\n            // Implementation depends on ROS interface\n        }\n    }\n\n    void OnWireframeToggled(bool isOn)\n    {\n        // Toggle wireframe rendering\n        Shader.SetGlobalFloat("_WireframeMode", isOn ? 1.0f : 0.0f);\n    }\n\n    void OnCollisionToggled(bool isOn)\n    {\n        // Toggle collision visualization\n        foreach (Collider col in FindObjectsOfType<Collider>())\n        {\n            col.enabled = isOn;\n        }\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h2,{id:"advanced-visualization-techniques",children:"Advanced Visualization Techniques"}),"\n",(0,o.jsx)(e.h3,{id:"point-cloud-visualization",children:"Point Cloud Visualization"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// Point cloud visualization for LiDAR data\nusing UnityEngine;\n\n[RequireComponent(typeof(MeshFilter), typeof(MeshRenderer))]\npublic class PointCloudVisualizer : MonoBehaviour\n{\n    [Header("Point Cloud Settings")]\n    public float pointSize = 0.05f;\n    public Color pointColor = Color.green;\n    public int maxPoints = 10000;\n\n    private Mesh mesh;\n    private Vector3[] vertices;\n    private Color[] colors;\n    private int[] triangles;\n    private int pointCount = 0;\n\n    void Start()\n    {\n        InitializePointCloud();\n    }\n\n    void InitializePointCloud()\n    {\n        mesh = new Mesh();\n        GetComponent<MeshFilter>().mesh = mesh;\n\n        vertices = new Vector3[maxPoints];\n        colors = new Color[maxPoints];\n        triangles = new int[maxPoints * 3]; // Each point is a triangle\n\n        // Initialize with default values\n        for (int i = 0; i < maxPoints; i++)\n        {\n            vertices[i] = Vector3.zero;\n            colors[i] = pointColor;\n        }\n\n        // Create triangle indices for point visualization\n        for (int i = 0; i < maxPoints; i++)\n        {\n            triangles[i * 3] = i;\n            triangles[i * 3 + 1] = i;\n            triangles[i * 3 + 2] = i;\n        }\n    }\n\n    public void UpdatePointCloud(Vector3[] newPoints)\n    {\n        pointCount = Mathf.Min(newPoints.Length, maxPoints);\n\n        // Update vertices and colors\n        for (int i = 0; i < pointCount; i++)\n        {\n            vertices[i] = newPoints[i];\n            colors[i] = GetColorForDistance(newPoints[i]);\n        }\n\n        // Update mesh\n        mesh.Clear();\n        mesh.vertices = vertices;\n        mesh.colors = colors;\n        mesh.triangles = GetTriangleIndices(pointCount);\n        mesh.RecalculateBounds();\n    }\n\n    Color GetColorForDistance(Vector3 point)\n    {\n        // Color points based on distance from origin\n        float distance = point.magnitude;\n        float normalizedDistance = Mathf.Clamp01(distance / 10f); // Normalize to 0-10m range\n        return Color.Lerp(Color.red, Color.green, normalizedDistance);\n    }\n\n    int[] GetTriangleIndices(int count)\n    {\n        int[] indices = new int[count * 3];\n        for (int i = 0; i < count; i++)\n        {\n            indices[i * 3] = i;\n            indices[i * 3 + 1] = i;\n            indices[i * 3 + 2] = i;\n        }\n        return indices;\n    }\n\n    void OnValidate()\n    {\n        pointSize = Mathf.Max(0.001f, pointSize);\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h2,{id:"deployment-and-distribution",children:"Deployment and Distribution"}),"\n",(0,o.jsx)(e.h3,{id:"building-for-different-platforms",children:"Building for Different Platforms"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'// Build configuration script\nusing UnityEngine;\n\npublic class BuildConfiguration : MonoBehaviour\n{\n    [Header("Build Settings")]\n    public BuildTarget targetPlatform = BuildTarget.StandaloneWindows64;\n    public bool enableHeadless = false;\n    public int targetFrameRate = 60;\n\n    [Header("Optimization Settings")]\n    public bool enableOcclusionCulling = true;\n    public bool enableBatching = true;\n    public int lodBias = 1;\n\n    void Start()\n    {\n        ConfigureBuildSettings();\n    }\n\n    void ConfigureBuildSettings()\n    {\n        // Set target frame rate\n        Application.targetFrameRate = targetFrameRate;\n\n        // Configure quality settings\n        QualitySettings.maxQueuedFrames = 2;\n        QualitySettings.vSyncCount = 0; // Disable VSync for consistent frame rates\n\n        // Configure LOD bias\n        QualitySettings.lodBias = lodBias;\n\n        // Configure occlusion culling\n        if (enableOcclusionCulling)\n        {\n            // This is typically configured in the editor\n            // Runtime configuration depends on specific needs\n        }\n    }\n\n    public void ConfigureForHeadless()\n    {\n        if (enableHeadless)\n        {\n            // Configure for headless operation\n            Screen.SetResolution(1, 1, false); // Minimal resolution\n            QualitySettings.SetQualityLevel(0); // Lowest quality\n        }\n    }\n\n    public void ConfigureForVR()\n    {\n        // Configure for VR operation\n        // Enable VR settings\n        // Configure for VR-specific rendering\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h2,{id:"best-practices-and-guidelines",children:"Best Practices and Guidelines"}),"\n",(0,o.jsx)(e.h3,{id:"performance-guidelines",children:"Performance Guidelines"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"LOD Systems"}),": Implement Level of Detail for complex models"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Occlusion Culling"}),": Use occlusion culling for large environments"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Object Pooling"}),": Reuse objects instead of creating/destroying"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Texture Compression"}),": Use appropriate texture compression"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Shader Optimization"}),": Use efficient shaders for robotics visualization"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"quality-assurance",children:"Quality Assurance"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Real-time Performance"}),": Maintain 30+ FPS for smooth interaction"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Visual Accuracy"}),": Ensure visual representation matches real robot"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Synchronization"}),": Keep visualization synchronized with real data"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"User Experience"}),": Provide intuitive controls and feedback"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Scalability"}),": Design for different hardware capabilities"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"development-workflow",children:"Development Workflow"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Version Control"}),": Use Git for Unity project management"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Asset Management"}),": Organize assets in logical folder structure"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Testing"}),": Implement automated testing for visualization components"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Documentation"}),": Maintain clear documentation for all systems"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Deployment"}),": Create streamlined deployment processes"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"troubleshooting-common-issues",children:"Troubleshooting Common Issues"}),"\n",(0,o.jsx)(e.h3,{id:"performance-problems",children:"Performance Problems"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Low Frame Rate"}),": Optimize draw calls, reduce overdraw, use LOD"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"High Memory Usage"}),": Implement object pooling, compress textures"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Input Lag"}),": Optimize update loops, reduce processing in Update()"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"rendering-issues",children:"Rendering Issues"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Z-Fighting"}),": Adjust near/far clip planes, use appropriate scaling"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Lighting Artifacts"}),": Configure lighting settings properly"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Texture Problems"}),": Verify texture import settings"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"integration-issues",children:"Integration Issues"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"ROS Connection"}),": Check network connectivity and topic names"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Data Synchronization"}),": Ensure proper timing and data flow"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Coordinate Systems"}),": Verify coordinate system compatibility"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"practical-lab-unity-robotics-visualization",children:"Practical Lab: Unity Robotics Visualization"}),"\n",(0,o.jsx)(e.h3,{id:"lab-objective",children:"Lab Objective"}),"\n",(0,o.jsx)(e.p,{children:"Create a complete Unity visualization environment for a mobile robot with camera and LiDAR sensors."}),"\n",(0,o.jsx)(e.h3,{id:"implementation-steps",children:"Implementation Steps"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsx)(e.li,{children:"Import robot model and configure kinematics"}),"\n",(0,o.jsx)(e.li,{children:"Create realistic environment with obstacles"}),"\n",(0,o.jsx)(e.li,{children:"Implement ROS 2 integration for real-time data"}),"\n",(0,o.jsx)(e.li,{children:"Add sensor simulation and visualization"}),"\n",(0,o.jsx)(e.li,{children:"Create user interface for monitoring and control"}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"expected-outcome",children:"Expected Outcome"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Functional Unity visualization environment"}),"\n",(0,o.jsx)(e.li,{children:"Real-time robot and sensor data display"}),"\n",(0,o.jsx)(e.li,{children:"Proper ROS 2 integration"}),"\n",(0,o.jsx)(e.li,{children:"Demonstrated understanding of Unity robotics concepts"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"review-questions",children:"Review Questions"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsx)(e.li,{children:"What are the key differences between Unity and Gazebo for robotics visualization?"}),"\n",(0,o.jsx)(e.li,{children:"How do you integrate Unity with ROS 2 communication systems?"}),"\n",(0,o.jsx)(e.li,{children:"What are the best practices for optimizing Unity performance in robotics applications?"}),"\n",(0,o.jsx)(e.li,{children:"How do you implement sensor simulation in Unity for robotics applications?"}),"\n",(0,o.jsx)(e.li,{children:"What are the considerations for deploying Unity visualization systems?"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,o.jsx)(e.p,{children:"After mastering Unity visualization, students should proceed to:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Advanced simulation techniques"}),"\n",(0,o.jsx)(e.li,{children:"NVIDIA Isaac integration"}),"\n",(0,o.jsx)(e.li,{children:"Computer vision in Unity"}),"\n",(0,o.jsx)(e.li,{children:"Virtual reality applications for robotics"}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:"This comprehensive guide to Unity visualization provides the foundation for creating sophisticated, high-quality visualization systems for Physical AI and Humanoid Robotics applications."})]})}function u(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>r,x:()=>a});var t=i(6540);const o={},s=t.createContext(o);function r(n){const e=t.useContext(s);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function a(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:r(n.components),t.createElement(s.Provider,{value:e},n.children)}}}]);