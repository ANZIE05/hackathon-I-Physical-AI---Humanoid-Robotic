"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_textbook=globalThis.webpackChunkphysical_ai_humanoid_robotics_textbook||[]).push([[8739],{7077:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>d,frontMatter:()=>s,metadata:()=>a,toc:()=>m});const a=JSON.parse('{"id":"module-3/isaac-sim-fundamentals","title":"Isaac Sim Fundamentals","description":"Overview","source":"@site/docs/module-3/isaac-sim-fundamentals.md","sourceDirName":"module-3","slug":"/module-3/isaac-sim-fundamentals","permalink":"/docs/module-3/isaac-sim-fundamentals","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-3/isaac-sim-fundamentals.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1}}');var r=i(4848),t=i(8453);const s={sidebar_position:1},o="Isaac Sim Fundamentals",l={},m=[{value:"Overview",id:"overview",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Key Concepts",id:"key-concepts",level:2},{value:"NVIDIA Omniverse Foundation",id:"nvidia-omniverse-foundation",level:3},{value:"Isaac Sim Architecture",id:"isaac-sim-architecture",level:3},{value:"Photorealistic Rendering",id:"photorealistic-rendering",level:3},{value:"Synthetic Data Generation",id:"synthetic-data-generation",level:3},{value:"Isaac Sim Setup and Configuration",id:"isaac-sim-setup-and-configuration",level:2},{value:"System Requirements",id:"system-requirements",level:3},{value:"Installation Process",id:"installation-process",level:3},{value:"Basic Configuration",id:"basic-configuration",level:3},{value:"Isaac Sim Environment Creation",id:"isaac-sim-environment-creation",level:2},{value:"Basic Scene Setup",id:"basic-scene-setup",level:3},{value:"Advanced Environment Design",id:"advanced-environment-design",level:3},{value:"Robot Integration",id:"robot-integration",level:2},{value:"Importing Robot Models",id:"importing-robot-models",level:3},{value:"Physics Configuration",id:"physics-configuration",level:3},{value:"Synthetic Data Generation",id:"synthetic-data-generation-1",level:2},{value:"Dataset Creation Pipeline",id:"dataset-creation-pipeline",level:3},{value:"Domain Randomization",id:"domain-randomization",level:3},{value:"ROS 2 Integration",id:"ros-2-integration",level:2},{value:"Isaac ROS Bridge Setup",id:"isaac-ros-bridge-setup",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"Isaac Sim Performance Considerations",id:"isaac-sim-performance-considerations",level:3},{value:"Troubleshooting and Best Practices",id:"troubleshooting-and-best-practices",level:2},{value:"Common Issues and Solutions",id:"common-issues-and-solutions",level:3},{value:"Practical Lab: Complete Isaac Sim Environment",id:"practical-lab-complete-isaac-sim-environment",level:2},{value:"Lab Objective",id:"lab-objective",level:3},{value:"Implementation Steps",id:"implementation-steps",level:3},{value:"Step 1: Set up Isaac Sim Environment",id:"step-1-set-up-isaac-sim-environment",level:4},{value:"Lab Exercise: Isaac Sim Integration",id:"lab-exercise-isaac-sim-integration",level:3},{value:"Expected Results",id:"expected-results",level:3},{value:"Review Questions",id:"review-questions",level:2},{value:"Next Steps",id:"next-steps",level:2}];function c(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"isaac-sim-fundamentals",children:"Isaac Sim Fundamentals"})}),"\n",(0,r.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,r.jsx)(n.p,{children:"NVIDIA Isaac Sim is a powerful simulation environment built on NVIDIA Omniverse for developing, testing, and validating AI-powered robotics applications. It provides photorealistic rendering, synthetic data generation, and seamless integration with ROS 2, making it an essential tool for Physical AI and Humanoid Robotics development."}),"\n",(0,r.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,r.jsx)(n.p,{children:"By the end of this section, students will be able to:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Understand the architecture and capabilities of Isaac Sim"}),"\n",(0,r.jsx)(n.li,{children:"Create photorealistic simulation environments for robotics"}),"\n",(0,r.jsx)(n.li,{children:"Generate synthetic data for AI training and validation"}),"\n",(0,r.jsx)(n.li,{children:"Integrate Isaac Sim with ROS 2 systems and workflows"}),"\n",(0,r.jsx)(n.li,{children:"Apply advanced rendering techniques for realistic perception simulation"}),"\n",(0,r.jsx)(n.li,{children:"Utilize Isaac Sim's synthetic data generation capabilities for AI development"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"key-concepts",children:"Key Concepts"}),"\n",(0,r.jsx)(n.h3,{id:"nvidia-omniverse-foundation",children:"NVIDIA Omniverse Foundation"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"RTX Technology"}),": Physically accurate rendering using NVIDIA RTX GPUs"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"USD (Universal Scene Description)"}),": Scalable scene representation format"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Real-time Collaboration"}),": Multi-user collaboration capabilities"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Extensibility"}),": Modular architecture with custom extensions"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"isaac-sim-architecture",children:"Isaac Sim Architecture"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simulation Engine"}),": Physics simulation based on PhysX"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Rendering Engine"}),": RTX-accelerated rendering for photorealistic scenes"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Synthetic Data Generation"}),": Tools for creating labeled training data"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"ROS 2 Integration"}),": Bridges for ROS 2 communication and control"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"photorealistic-rendering",children:"Photorealistic Rendering"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Path Tracing"}),": Physically accurate light simulation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Global Illumination"}),": Realistic lighting and shadows"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Material Simulation"}),": Physically-based materials and surfaces"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Sensor Simulation"}),": Accurate simulation of cameras and other sensors"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"synthetic-data-generation",children:"Synthetic Data Generation"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Domain Randomization"}),": Variation of environmental parameters"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Automatic Labeling"}),": Perfect ground truth for training data"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Data Diversity"}),": Generation of rare or dangerous scenarios"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Annotation Tools"}),": Integrated tools for data labeling and processing"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"isaac-sim-setup-and-configuration",children:"Isaac Sim Setup and Configuration"}),"\n",(0,r.jsx)(n.h3,{id:"system-requirements",children:"System Requirements"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# System requirements\n- NVIDIA GPU: RTX 2060 or higher\n- VRAM: 8GB+ recommended\n- CPU: Multi-core processor (8+ cores)\n- RAM: 16GB+ (32GB recommended)\n- Storage: 10GB+ for Isaac Sim installation\n\n# Recommended for optimal performance\n- NVIDIA GPU: RTX 3080/4080 or higher\n- VRAM: 12GB+ (24GB+ for large scenes)\n- RAM: 32GB+\n- Storage: SSD with 20GB+ free space\n"})}),"\n",(0,r.jsx)(n.h3,{id:"installation-process",children:"Installation Process"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Download Isaac Sim from NVIDIA Developer portal\n# Extract and install\ntar -xf isaac_sim-2023.1.0.tar.gz\ncd isaac_sim-2023.1.0\n\n# Install dependencies\nsudo apt update\nsudo apt install nvidia-isaac-ros-dev\nsudo apt install nvidia-isaac-ros-gazebo-interfaces\nsudo apt install nvidia-isaac-ros-pointcloud-utils\n\n# Verify installation\ndpkg -l | grep isaac-sim\n"})}),"\n",(0,r.jsx)(n.h3,{id:"basic-configuration",children:"Basic Configuration"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:'# Isaac Sim configuration file\nisaac_sim_common:\n  ros__parameters:\n    # Performance settings\n    enable_profiler: false\n    profiler_filename: "/tmp/isaac_sim_profile.json"\n\n    # Memory management\n    use_pinned_memory: true\n    max_memory_allocation_mb: 4096\n\n    # Communication settings\n    qos_history: 1  # KEEP_LAST\n    qos_depth: 10\n    qos_reliability: 1  # RELIABLE\n    qos_durability: 2  # TRANSIENT_LOCAL\n'})}),"\n",(0,r.jsx)(n.h2,{id:"isaac-sim-environment-creation",children:"Isaac Sim Environment Creation"}),"\n",(0,r.jsx)(n.h3,{id:"basic-scene-setup",children:"Basic Scene Setup"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Basic scene setup script\nimport omni\nfrom omni.isaac.core import World\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\nfrom omni.isaac.core.utils.prims import create_primitive\nfrom omni.isaac.core.utils.carb import set_carb_setting\n\n# Configure simulation settings\nset_carb_setting("/physics/solverType", "TGS")\nset_carb_setting("/physics/iterations", 16)\nset_carb_setting("/physics/worker_thread_count", 8)\n\n# Create world instance\nworld = World(stage_units_in_meters=1.0)\n\n# Add ground plane\nground_plane = create_primitive(\n    prim_path="/World/ground_plane",\n    primitive_type="Plane",\n    scale=[10, 10, 1],\n    color=[0.2, 0.2, 0.2]\n)\n\n# Add lighting\ndistant_light = world.scene.add_default_ground_plane(color=[0.1, 0.1, 0.1])\n'})}),"\n",(0,r.jsx)(n.h3,{id:"advanced-environment-design",children:"Advanced Environment Design"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Advanced environment with lighting and materials\nimport omni\nfrom pxr import UsdLux, Gf, Sdf\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\nfrom omni.isaac.core.utils.prims import get_prim_at_path\n\ndef create_advanced_environment(world):\n    """Create an advanced environment with realistic lighting and materials"""\n\n    # Add dome light for global illumination\n    dome_light_path = "/World/DomeLight"\n    dome_light = world.scene.add(\n        prim_path=dome_light_path,\n        name="dome_light",\n        light_type="DomeLight",\n        color=[0.2, 0.2, 0.2],\n        intensity=300\n    )\n\n    # Add directional light for shadows\n    directional_light_path = "/World/DirectionalLight"\n    directional_light = world.scene.add(\n        prim_path=directional_light_path,\n        name="directional_light",\n        light_type="DistantLight",\n        color=[0.9, 0.9, 0.9],\n        intensity=1000\n    )\n\n    # Create textured floor\n    floor_path = "/World/floor"\n    floor = create_primitive(\n        prim_path=floor_path,\n        primitive_type="Plane",\n        scale=[10, 10, 1],\n        color=[0.5, 0.5, 0.5]\n    )\n\n    # Add realistic materials\n    add_realistic_materials(floor_path)\n\n    return dome_light, directional_light, floor\n\ndef add_realistic_materials(prim_path):\n    """Add realistic materials to the environment"""\n    from omni.isaac.core.materials import OmniPBR\n\n    # Create realistic floor material\n    floor_material = OmniPBR(\n        prim_path=f"{prim_path}/Material",\n        color=(0.7, 0.7, 0.7),\n        roughness=0.2,\n        metallic=0.0,\n        specular_level=0.5\n    )\n\n    return floor_material\n'})}),"\n",(0,r.jsx)(n.h2,{id:"robot-integration",children:"Robot Integration"}),"\n",(0,r.jsx)(n.h3,{id:"importing-robot-models",children:"Importing Robot Models"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Robot import and configuration\nfrom omni.isaac.core.utils.nucleus import get_assets_root_path\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\nfrom omni.isaac.core.robots import Robot\nimport carb\n\ndef import_robot_model(world, robot_usd_path, position=[0, 0, 0.5], orientation=[0, 0, 0, 1]):\n    """Import and configure a robot model in Isaac Sim"""\n\n    # Add robot to stage\n    robot_prim_path = "/World/Robot"\n    add_reference_to_stage(\n        usd_path=robot_usd_path,\n        prim_path=robot_prim_path\n    )\n\n    # Create robot object\n    robot = Robot(\n        prim_path=robot_prim_path,\n        name="my_robot",\n        position=position,\n        orientation=orientation\n    )\n\n    # Add robot to world\n    world.scene.add(robot)\n\n    return robot\n\ndef setup_robot_with_sensors(robot, world):\n    """Add sensors to the robot"""\n    from omni.isaac.sensor import Camera\n\n    # Add RGB camera\n    camera = Camera(\n        prim_path="/World/Robot/chassis/camera",\n        frequency=30,\n        resolution=(640, 480)\n    )\n    world.scene.add(camera)\n\n    # Add LiDAR sensor\n    # Additional sensor setup would go here\n\n    return camera\n'})}),"\n",(0,r.jsx)(n.h3,{id:"physics-configuration",children:"Physics Configuration"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Physics configuration for realistic robot simulation\nfrom omni.isaac.core.utils.physics import set_articulation_properties\nfrom omni.isaac.core.utils.prims import get_prim_at_path\n\ndef configure_robot_physics(robot):\n    """Configure physics properties for realistic robot simulation"""\n\n    # Get robot articulation\n    articulation = get_prim_at_path(robot.prim_path)\n\n    # Set physics properties\n    set_articulation_properties(\n        articulation=articulation,\n        joint_friction=[0.1] * len(robot.joint_names),  # Joint friction\n        joint_damping=[0.01] * len(robot.joint_names),  # Joint damping\n        joint_stiffness=[0.0] * len(robot.joint_names)  # Joint stiffness\n    )\n\n    # Configure collision properties\n    configure_collision_properties(robot)\n\ndef configure_collision_properties(robot):\n    """Configure collision properties for the robot"""\n    # Add collision filtering and material properties\n    # This would include setting up proper collision groups\n    # and material properties for realistic interactions\n    pass\n'})}),"\n",(0,r.jsx)(n.h2,{id:"synthetic-data-generation-1",children:"Synthetic Data Generation"}),"\n",(0,r.jsx)(n.h3,{id:"dataset-creation-pipeline",children:"Dataset Creation Pipeline"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Synthetic dataset creation\nimport numpy as np\nfrom omni.synthetic_utils import SyntheticDataHelper\nfrom PIL import Image\nimport os\n\nclass SyntheticDatasetGenerator:\n    def __init__(self, output_dir="synthetic_data", num_samples=1000):\n        self.output_dir = output_dir\n        self.num_samples = num_samples\n        self.data_helper = SyntheticDataHelper()\n\n        # Create output directory\n        os.makedirs(output_dir, exist_ok=True)\n        os.makedirs(f"{output_dir}/images", exist_ok=True)\n        os.makedirs(f"{output_dir}/labels", exist_ok=True)\n        os.makedirs(f"{output_dir}/depth", exist_ok=True)\n\n    def generate_dataset(self, world, robot, environment_params):\n        """Generate synthetic dataset with domain randomization"""\n\n        for i in range(self.num_samples):\n            # Randomize environment\n            self.randomize_environment(environment_params)\n\n            # Randomize lighting\n            self.randomize_lighting()\n\n            # Randomize camera position/orientation\n            self.randomize_camera(robot)\n\n            # Capture data\n            rgb_image = self.capture_rgb_image()\n            depth_image = self.capture_depth_image()\n            segmentation = self.capture_segmentation()\n\n            # Save data with perfect labels\n            self.save_sample(i, rgb_image, depth_image, segmentation)\n\n            print(f"Generated sample {i+1}/{self.num_samples}")\n\n    def randomize_environment(self, params):\n        """Randomize environment parameters"""\n        # Randomize object positions, colors, materials\n        # Randomize floor texture and appearance\n        # Randomize obstacles and scene elements\n        pass\n\n    def randomize_lighting(self):\n        """Randomize lighting conditions"""\n        # Randomize light intensity, color, position\n        # Randomize time of day effects\n        # Randomize weather conditions\n        pass\n\n    def randomize_camera(self, robot):\n        """Randomize camera position relative to robot"""\n        # Randomize camera position and orientation\n        # Randomize camera intrinsics\n        pass\n\n    def capture_rgb_image(self):\n        """Capture RGB image from camera"""\n        # Implementation depends on Isaac Sim API\n        return np.random.rand(480, 640, 3)  # Placeholder\n\n    def capture_depth_image(self):\n        """Capture depth image"""\n        # Implementation depends on Isaac Sim API\n        return np.random.rand(480, 640)  # Placeholder\n\n    def capture_segmentation(self):\n        """Capture semantic segmentation"""\n        # Implementation depends on Isaac Sim API\n        return np.random.randint(0, 10, (480, 640))  # Placeholder\n\n    def save_sample(self, idx, rgb, depth, seg):\n        """Save synthetic data sample"""\n        # Save RGB image\n        rgb_img = Image.fromarray((rgb * 255).astype(np.uint8))\n        rgb_img.save(f"{self.output_dir}/images/{idx:06d}.png")\n\n        # Save depth image\n        depth_img = Image.fromarray((depth * 255).astype(np.uint16))\n        depth_img.save(f"{self.output_dir}/depth/{idx:06d}.png")\n\n        # Save segmentation labels\n        seg_img = Image.fromarray(seg.astype(np.uint8))\n        seg_img.save(f"{self.output_dir}/labels/{idx:06d}.png")\n'})}),"\n",(0,r.jsx)(n.h3,{id:"domain-randomization",children:"Domain Randomization"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Domain randomization implementation\nimport random\nimport colorsys\n\nclass DomainRandomizer:\n    def __init__(self):\n        self.lighting_params = {\n            'intensity_range': (100, 1500),\n            'color_temperature_range': (3000, 8000),\n            'shadow_softness_range': (0.1, 0.9)\n        }\n\n        self.material_params = {\n            'roughness_range': (0.0, 1.0),\n            'metallic_range': (0.0, 1.0),\n            'specular_range': (0.0, 1.0)\n        }\n\n    def randomize_lighting(self, light_prim):\n        \"\"\"Randomize lighting properties\"\"\"\n        # Randomize intensity\n        intensity = random.uniform(*self.lighting_params['intensity_range'])\n        light_prim.GetAttribute('intensity').Set(intensity)\n\n        # Randomize color temperature\n        temp = random.uniform(*self.lighting_params['color_temperature_range'])\n        color = self.color_temp_to_rgb(temp)\n        light_prim.GetAttribute('color').Set(Gf.Vec3f(*color))\n\n        # Randomize other properties\n        softness = random.uniform(*self.lighting_params['shadow_softness_range'])\n        # Apply shadow softness based on implementation\n\n    def randomize_materials(self, material_prim):\n        \"\"\"Randomize material properties\"\"\"\n        # Randomize roughness\n        roughness = random.uniform(*self.material_params['roughness_range'])\n        material_prim.GetAttribute('roughness').Set(roughness)\n\n        # Randomize metallic\n        metallic = random.uniform(*self.material_params['metallic_range'])\n        material_prim.GetAttribute('metallic').Set(metallic)\n\n        # Randomize specular\n        specular = random.uniform(*self.material_params['specular_range'])\n        material_prim.GetAttribute('specular_level').Set(specular)\n\n    def color_temp_to_rgb(self, temp):\n        \"\"\"Convert color temperature to RGB values\"\"\"\n        temp = temp / 100\n        if temp <= 66:\n            red = 255\n            green = temp\n            green = 99.4708025861 * math.log(green) - 161.1195681661\n        else:\n            red = temp - 60\n            red = 329.698727446 * (red ** -0.1332047592)\n            green = temp - 60\n            green = 288.1221695283 * (green ** -0.0755148492)\n\n        blue = 255 if temp >= 66 else temp - 10\n        blue = 138.5177312231 * math.log(blue) - 305.0447927307 if temp < 19 else 0\n\n        return [max(0, min(255, x))/255.0 for x in [red, green, blue]]\n"})}),"\n",(0,r.jsx)(n.h2,{id:"ros-2-integration",children:"ROS 2 Integration"}),"\n",(0,r.jsx)(n.h3,{id:"isaac-ros-bridge-setup",children:"Isaac ROS Bridge Setup"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Isaac ROS bridge configuration\nfrom omni.isaac.ros2_bridge import ROS2Bridge\nimport rclpy\nfrom sensor_msgs.msg import Image, CameraInfo\nfrom geometry_msgs.msg import Twist\nfrom nav_msgs.msg import Odometry\n\nclass IsaacROSIntegration:\n    def __init__(self):\n        # Initialize ROS 2 bridge\n        self.ros2_bridge = ROS2Bridge()\n        self.node = rclpy.create_node(\'isaac_sim_ros_bridge\')\n\n        # Publishers\n        self.rgb_pub = self.create_publisher(Image, \'/camera/rgb/image_raw\', 10)\n        self.depth_pub = self.create_publisher(Image, \'/camera/depth/image_raw\', 10)\n        self.odom_pub = self.create_publisher(Odometry, \'/odom\', 10)\n        self.camera_info_pub = self.create_publisher(CameraInfo, \'/camera/rgb/camera_info\', 10)\n\n        # Subscribers\n        self.cmd_vel_sub = self.create_subscription(\n            Twist, \'/cmd_vel\', self.cmd_vel_callback, 10)\n\n        # Timer for publishing sensor data\n        self.pub_timer = self.create_timer(0.1, self.publish_sensor_data)\n\n    def cmd_vel_callback(self, msg):\n        """Handle velocity commands from ROS"""\n        # Process velocity command and apply to robot\n        linear_x = msg.linear.x\n        angular_z = msg.angular.z\n\n        # Apply command to simulated robot\n        self.apply_robot_command(linear_x, angular_z)\n\n    def publish_sensor_data(self):\n        """Publish sensor data to ROS topics"""\n        # Get current sensor data from Isaac Sim\n        rgb_image = self.get_current_rgb_image()\n        depth_image = self.get_current_depth_image()\n        odom_data = self.get_current_odometry()\n\n        # Publish to ROS topics\n        if rgb_image is not None:\n            self.rgb_pub.publish(rgb_image)\n            self.publish_camera_info()\n\n        if depth_image is not None:\n            self.depth_pub.publish(depth_image)\n\n        if odom_data is not None:\n            self.odom_pub.publish(odom_data)\n\n    def get_current_rgb_image(self):\n        """Get current RGB image from Isaac Sim camera"""\n        # Implementation to get image from Isaac Sim camera\n        return None  # Placeholder\n\n    def get_current_depth_image(self):\n        """Get current depth image from Isaac Sim"""\n        # Implementation to get depth from Isaac Sim sensor\n        return None  # Placeholder\n\n    def get_current_odometry(self):\n        """Get current odometry from Isaac Sim"""\n        # Implementation to get robot pose and velocity\n        return None  # Placeholder\n\n    def apply_robot_command(self, linear_x, angular_z):\n        """Apply velocity command to simulated robot"""\n        # Implementation to control simulated robot\n        pass\n\n    def publish_camera_info(self):\n        """Publish camera information"""\n        camera_info = CameraInfo()\n        camera_info.header.frame_id = "camera_rgb_optical_frame"\n        camera_info.width = 640\n        camera_info.height = 480\n        camera_info.distortion_model = "plumb_bob"\n        camera_info.d = [0.0, 0.0, 0.0, 0.0, 0.0]  # Distortion coefficients\n        camera_info.k = [525.0, 0.0, 319.5, 0.0, 525.0, 239.5, 0.0, 0.0, 1.0]  # Camera matrix\n        camera_info.r = [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]  # Rectification matrix\n        camera_info.p = [525.0, 0.0, 319.5, 0.0, 0.0, 525.0, 239.5, 0.0, 0.0, 0.0, 1.0, 0.0]  # Projection matrix\n\n        self.camera_info_pub.publish(camera_info)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,r.jsx)(n.h3,{id:"isaac-sim-performance-considerations",children:"Isaac Sim Performance Considerations"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Performance optimization for Isaac Sim\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image, PointCloud2, LaserScan\nfrom std_msgs.msg import UInt32\nimport time\nfrom collections import deque\nimport threading\nimport psutil\nimport GPUtil\n\nclass IsaacSimPerformanceOptimizer(Node):\n    def __init__(self):\n        super().__init__('isaac_sim_performance_optimizer')\n\n        # Publishers for performance metrics\n        self.fps_pub = self.create_publisher(UInt32, 'performance/fps', 10)\n        self.cpu_pub = self.create_publisher(UInt32, 'performance/cpu_percent', 10)\n        self.gpu_pub = self.create_publisher(UInt32, 'performance/gpu_percent', 10)\n\n        # Performance monitoring\n        self.frame_times = deque(maxlen=30)  # Last 30 frame times\n        self.processing_times = deque(maxlen=30)\n        self.memory_usage = deque(maxlen=30)\n        self.cpu_usage = deque(maxlen=30)\n\n        # Performance targets\n        self.target_fps = 30\n        self.max_processing_time = 0.033  # 33ms for 30 FPS\n        self.max_memory_percent = 80.0\n\n        # Adaptive processing parameters\n        self.adaptive_params = {\n            'image_decimation': 1,  # Process every Nth frame\n            'pointcloud_decimation': 4,  # Process every 4th point\n            'feature_count': 1000,  # Number of features to track\n            'bundle_adjustment_freq': 10  # BA every N keyframes\n        }\n\n        # Threading for performance monitoring\n        self.monitoring_thread = threading.Thread(target=self.monitor_performance)\n        self.monitoring_thread.daemon = True\n        self.monitoring_thread.start()\n\n        # Performance timer\n        self.perf_timer = self.create_timer(1.0, self.publish_performance_metrics)\n\n        self.get_logger().info('Isaac Sim Performance Optimizer Initialized')\n\n    def monitor_performance(self):\n        \"\"\"Monitor system performance in separate thread\"\"\"\n        while rclpy.ok():\n            # CPU usage\n            cpu_percent = psutil.cpu_percent(interval=0.1)\n            self.cpu_usage.append(cpu_percent)\n\n            # Memory usage\n            memory_percent = psutil.virtual_memory().percent\n            self.memory_usage.append(memory_percent)\n\n            # GPU usage if available\n            gpus = GPUtil.getGPUs()\n            if gpus:\n                gpu_percent = gpus[0].load * 100\n                self.gpu_usage.append(gpu_percent)\n            else:\n                self.gpu_usage.append(0)\n\n            time.sleep(0.1)\n\n    def adaptive_processing(self, image_data, sensor_type='image'):\n        \"\"\"Adapt processing based on performance\"\"\"\n        start_time = time.time()\n\n        if sensor_type == 'image':\n            # Adjust processing based on performance\n            if self.current_fps < self.target_fps * 0.8:\n                # Reduce processing load\n                self.adaptive_params['feature_count'] = max(500,\n                    int(self.adaptive_params['feature_count'] * 0.9))\n                self.adaptive_params['image_decimation'] = min(5,\n                    self.adaptive_params['image_decimation'] + 1)\n            elif self.current_fps > self.target_fps * 1.1:\n                # Can afford more processing\n                self.adaptive_params['feature_count'] = min(2000,\n                    int(self.adaptive_params['feature_count'] * 1.1))\n                self.adaptive_params['image_decimation'] = max(1,\n                    self.adaptive_params['image_decimation'] - 1)\n\n            # Apply decimation\n            if self.adaptive_params['image_decimation'] > 1:\n                # Process every Nth frame\n                if self.frame_count % self.adaptive_params['image_decimation'] != 0:\n                    return None  # Skip processing\n\n            # Process image with adjusted parameters\n            processed_result = self.process_image_adaptive(image_data)\n\n        elif sensor_type == 'lidar':\n            # Similar adaptation for LiDAR processing\n            if self.adaptive_params['pointcloud_decimation'] > 1:\n                # Apply decimation to LiDAR data\n                processed_result = self.decimate_pointcloud(image_data)\n\n        processing_time = time.time() - start_time\n        self.processing_times.append(processing_time)\n\n        return processed_result\n\n    def process_image_adaptive(self, image_data):\n        \"\"\"Process image with adaptive parameters\"\"\"\n        # Extract features with adaptive count\n        feature_detector = cv2.ORB_create(\n            nfeatures=self.adaptive_params['feature_count'],\n            scaleFactor=1.2,\n            nlevels=8,\n            edgeThreshold=31,\n            patchSize=31,\n            fastThreshold=20\n        )\n\n        keypoints, descriptors = feature_detector.detectAndCompute(image_data, None)\n        return keypoints, descriptors\n\n    def decimate_pointcloud(self, pointcloud_data):\n        \"\"\"Decimate point cloud for performance\"\"\"\n        # Reduce point cloud density\n        decimation_factor = self.adaptive_params['pointcloud_decimation']\n        return pointcloud_data[::decimation_factor]\n\n    def get_current_performance(self):\n        \"\"\"Get current performance metrics\"\"\"\n        if len(self.frame_times) > 1:\n            avg_frame_time = sum(self.frame_times) / len(self.frame_times)\n            current_fps = 1.0 / avg_frame_time if avg_frame_time > 0 else 0\n        else:\n            current_fps = 0\n\n        avg_processing_time = sum(self.processing_times) / len(self.processing_times) if self.processing_times else 0\n        avg_cpu_usage = sum(self.cpu_usage) / len(self.cpu_usage) if self.cpu_usage else 0\n        avg_memory_usage = sum(self.memory_usage) / len(self.memory_usage) if self.memory_usage else 0\n\n        return {\n            'fps': current_fps,\n            'avg_processing_time': avg_processing_time,\n            'cpu_usage': avg_cpu_usage,\n            'memory_usage': avg_memory_usage,\n            'adaptive_params': self.adaptive_params.copy()\n        }\n\n    def publish_performance_metrics(self):\n        \"\"\"Publish performance metrics\"\"\"\n        perf_metrics = self.get_current_performance()\n\n        # Publish FPS\n        fps_msg = UInt32()\n        fps_msg.data = int(perf_metrics['fps'])\n        self.fps_pub.publish(fps_msg)\n\n        # Publish CPU usage\n        cpu_msg = UInt32()\n        cpu_msg.data = int(perf_metrics['cpu_usage'])\n        self.cpu_pub.publish(cpu_msg)\n\n        # Publish GPU usage if available\n        if hasattr(self, 'gpu_usage') and self.gpu_usage:\n            gpu_msg = UInt32()\n            gpu_msg.data = int(sum(self.gpu_usage) / len(self.gpu_usage))\n            self.gpu_pub.publish(gpu_msg)\n\n        # Log performance if degraded\n        if perf_metrics['fps'] < self.target_fps * 0.7:\n            self.get_logger().warn(\n                f'Performance degraded: {perf_metrics[\"fps\"]:.1f} FPS '\n                f'(target: {self.target_fps}), '\n                f'CPU: {perf_metrics[\"cpu_usage\"]:.1f}%, '\n                f'Memory: {perf_metrics[\"memory_usage\"]:.1f}%'\n            )\n\n    def optimize_pipeline(self):\n        \"\"\"Optimize entire pipeline based on performance\"\"\"\n        current_perf = self.get_current_performance()\n\n        # Adjust pipeline parameters based on performance\n        if current_perf['fps'] < self.target_fps * 0.5:\n            # Significantly below target - aggressive optimization\n            self.get_logger().warn('Significant performance degradation detected - applying aggressive optimization')\n            self.adaptive_params['feature_count'] = max(200, self.adaptive_params['feature_count'] // 2)\n            self.adaptive_params['image_decimation'] = min(10, self.adaptive_params['image_decimation'] * 2)\n            self.adaptive_params['pointcloud_decimation'] = min(16, self.adaptive_params['pointcloud_decimation'] * 2)\n        elif current_perf['fps'] > self.target_fps * 1.2:\n            # Above target - can afford more processing\n            self.adaptive_params['feature_count'] = min(2000, self.adaptive_params['feature_count'] * 1.1)\n            self.adaptive_params['image_decimation'] = max(1, self.adaptive_params['image_decimation'] // 1.1)\n\n    def get_performance_recommendations(self):\n        \"\"\"Get performance optimization recommendations\"\"\"\n        current_perf = self.get_current_performance()\n        recommendations = []\n\n        if current_perf['fps'] < self.target_fps * 0.8:\n            recommendations.append('Reduce feature count to improve FPS')\n            recommendations.append('Increase image decimation for lower resolution processing')\n\n        if current_perf['cpu_usage'] > 80:\n            recommendations.append('High CPU usage - consider offloading to GPU')\n\n        if current_perf['memory_usage'] > 85:\n            recommendations.append('High memory usage - implement memory management')\n\n        return recommendations\n"})}),"\n",(0,r.jsx)(n.h2,{id:"troubleshooting-and-best-practices",children:"Troubleshooting and Best Practices"}),"\n",(0,r.jsx)(n.h3,{id:"common-issues-and-solutions",children:"Common Issues and Solutions"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Isaac Sim troubleshooting guide\nclass IsaacSimTroubleshooter:\n    def __init__(self):\n        self.known_issues = {\n            'connection_timeout': {\n                'symptoms': ['Cannot connect to Isaac Sim', 'Timeout errors'],\n                'causes': ['Network issues', 'Isaac Sim not running', 'Port conflicts'],\n                'solutions': [\n                    'Verify Isaac Sim is running',\n                    'Check network connectivity',\n                    'Ensure correct ports are open',\n                    'Restart Isaac Sim and ROS bridge'\n                ]\n            },\n            'gpu_not_detected': {\n                'symptoms': ['CUDA errors', 'GPU not utilized'],\n                'causes': ['Driver issues', 'CUDA version mismatch', 'GPU not properly configured'],\n                'solutions': [\n                    'Update NVIDIA drivers',\n                    'Verify CUDA installation',\n                    'Check Isaac Sim GPU requirements',\n                    'Install proper Isaac ROS packages'\n                ]\n            },\n            'performance_degradation': {\n                'symptoms': ['Low FPS', 'High latency', 'Memory leaks'],\n                'causes': ['Insufficient hardware', 'Inefficient algorithms', 'Memory management issues'],\n                'solutions': [\n                    'Optimize processing parameters',\n                    'Implement adaptive processing',\n                    'Add performance monitoring',\n                    'Upgrade hardware if needed'\n                ]\n            },\n            'sensor_data_issues': {\n                'symptoms': ['No sensor data', 'Corrupted data', 'Wrong coordinate frames'],\n                'causes': ['Incorrect sensor configuration', 'TF issues', 'Message format problems'],\n                'solutions': [\n                    'Verify sensor configuration in Isaac Sim',\n                    'Check TF tree and transforms',\n                    'Validate message formats',\n                    'Test sensor separately'\n                ]\n            }\n        }\n\n    def diagnose_issue(self, error_message):\n        \"\"\"Diagnose issue based on error message\"\"\"\n        for issue_type, issue_data in self.known_issues.items():\n            for symptom in issue_data['symptoms']:\n                if symptom.lower() in error_message.lower():\n                    return {\n                        'issue_type': issue_type,\n                        'symptoms': issue_data['symptoms'],\n                        'causes': issue_data['causes'],\n                        'solutions': issue_data['solutions']\n                    }\n\n        return {'issue_type': 'unknown', 'solutions': ['Check general troubleshooting steps']}\n\n    def check_system_compatibility(self):\n        \"\"\"Check system compatibility with Isaac Sim requirements\"\"\"\n        import subprocess\n        import platform\n\n        checks = {\n            'os_compatible': self.check_os_compatibility(),\n            'gpu_available': self.check_gpu_availability(),\n            'cuda_installed': self.check_cuda_installation(),\n            'driver_version': self.check_driver_version(),\n            'memory_sufficient': self.check_memory(),\n            'disk_space': self.check_disk_space()\n        }\n\n        return checks\n\n    def check_os_compatibility(self):\n        \"\"\"Check if OS is compatible with Isaac Sim\"\"\"\n        os_name = platform.system().lower()\n        os_version = platform.release()\n\n        # Isaac Sim officially supports Ubuntu 20.04/22.04\n        if os_name == 'linux':\n            try:\n                with open('/etc/os-release', 'r') as f:\n                    os_info = f.read()\n                    if 'ubuntu' in os_info.lower() and ('20.04' in os_info or '22.04' in os_info):\n                        return True\n            except:\n                pass\n\n        return False\n\n    def check_gpu_availability(self):\n        \"\"\"Check if compatible GPU is available\"\"\"\n        try:\n            result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader,nounits'],\n                                  capture_output=True, text=True, timeout=10)\n            if result.returncode == 0 and 'RTX' in result.stdout:\n                return True\n        except:\n            pass\n\n        return False\n\n    def check_cuda_installation(self):\n        \"\"\"Check if CUDA is properly installed\"\"\"\n        try:\n            result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True, timeout=5)\n            return result.returncode == 0\n        except:\n            return False\n\n    def check_driver_version(self):\n        \"\"\"Check if driver version is compatible\"\"\"\n        try:\n            result = subprocess.run(['nvidia-smi', '--query-gpu=driver_version', '--format=csv,noheader,nounits'],\n                                  capture_output=True, text=True, timeout=5)\n            if result.returncode == 0:\n                version_str = result.stdout.strip()\n                version_parts = version_str.split('.')\n                if len(version_parts) >= 2:\n                    major_version = int(version_parts[0])\n                    # Isaac Sim requires relatively recent drivers\n                    return major_version >= 470\n        except:\n            pass\n\n        return False\n\n    def check_memory(self):\n        \"\"\"Check if system has sufficient memory\"\"\"\n        import psutil\n        memory_gb = psutil.virtual_memory().total / (1024**3)\n        return memory_gb >= 16  # Isaac Sim recommends 16GB+\n\n    def check_disk_space(self):\n        \"\"\"Check if sufficient disk space is available\"\"\"\n        import shutil\n        total, used, free = shutil.disk_usage(\"/\")\n        free_gb = free / (1024**3)\n        return free_gb >= 50  # Recommend at least 50GB free\n\n    def generate_system_report(self):\n        \"\"\"Generate comprehensive system compatibility report\"\"\"\n        checks = self.check_system_compatibility()\n\n        report = f\"\"\"\nIsaac Sim System Compatibility Report\n=====================================\n\nSystem Checks:\n- OS Compatible: {'\u2713' if checks['os_compatible'] else '\u2717'}\n- GPU Available: {'\u2713' if checks['gpu_available'] else '\u2717'}\n- CUDA Installed: {'\u2713' if checks['cuda_installed'] else '\u2717'}\n- Driver Version: {'\u2713' if checks['driver_version'] else '\u2717'}\n- Memory Sufficient: {'\u2713' if checks['memory_sufficient'] else '\u2717'}\n- Disk Space: {'\u2713' if checks['disk_space'] else '\u2717'}\n\nRecommendations:\n\"\"\"\n        if not checks['os_compatible']:\n            report += \"- Upgrade to Ubuntu 20.04 or 22.04\\n\"\n        if not checks['gpu_available']:\n            report += \"- Install NVIDIA RTX GPU\\n\"\n        if not checks['cuda_installed']:\n            report += \"- Install CUDA toolkit\\n\"\n        if not checks['driver_version']:\n            report += \"- Update NVIDIA drivers\\n\"\n        if not checks['memory_sufficient']:\n            report += \"- Upgrade to 16GB+ RAM\\n\"\n        if not checks['disk_space']:\n            report += \"- Free up disk space (need 50GB+)\\n\"\n\n        return report\n"})}),"\n",(0,r.jsx)(n.h2,{id:"practical-lab-complete-isaac-sim-environment",children:"Practical Lab: Complete Isaac Sim Environment"}),"\n",(0,r.jsx)(n.h3,{id:"lab-objective",children:"Lab Objective"}),"\n",(0,r.jsx)(n.p,{children:"Create a complete Isaac Sim environment with robot, realistic lighting, sensors, and ROS 2 integration."}),"\n",(0,r.jsx)(n.h3,{id:"implementation-steps",children:"Implementation Steps"}),"\n",(0,r.jsx)(n.h4,{id:"step-1-set-up-isaac-sim-environment",children:"Step 1: Set up Isaac Sim Environment"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Complete Isaac Sim integration example\nimport omni\nfrom omni.isaac.core import World\nfrom omni.isaac.core.robots import Robot\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\nfrom omni.isaac.sensor import Camera\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image, CameraInfo\nfrom geometry_msgs.msg import Twist\nfrom std_msgs.msg import String\n\nclass IsaacSimCompleteIntegration(Node):\n    def __init__(self):\n        super().__init__(\'isaac_sim_complete_integration\')\n\n        # Initialize Isaac Sim world\n        self.world = World(stage_units_in_meters=1.0)\n\n        # ROS 2 publishers and subscribers\n        self.image_pub = self.create_publisher(Image, \'camera/image_raw\', 10)\n        self.camera_info_pub = self.create_publisher(CameraInfo, \'camera/camera_info\', 10)\n        self.cmd_vel_sub = self.create_subscription(\n            Twist, \'cmd_vel\', self.cmd_vel_callback, 10)\n\n        # Isaac Sim components\n        self.camera = None\n        self.robot = None\n\n        # Integration state\n        self.isaac_connected = False\n        self.ros_connected = True\n\n        # Performance monitoring\n        self.frame_count = 0\n        self.last_published_time = self.get_clock().now()\n\n        self.get_logger().info(\'Isaac Sim Complete Integration Node Started\')\n\n    def setup_isaac_environment(self):\n        """Set up Isaac Sim environment with robot and sensors"""\n        # Add ground plane\n        self.world.scene.add_default_ground_plane()\n\n        # Add robot\n        self.robot = self.world.scene.add(\n            Robot(\n                prim_path="/World/Robot",\n                name="isaac_robot",\n                usd_path="/Isaac/Robots/TurtleBot3Burger/turtlebot3_burger.usd",\n                position=[0, 0, 0.1],\n                orientation=[0, 0, 0, 1]\n            )\n        )\n\n        # Add camera to robot\n        self.camera = Camera(\n            prim_path="/World/Robot/chassis/camera",\n            frequency=30,\n            resolution=(640, 480)\n        )\n        self.world.scene.add(self.camera)\n\n        # Set up lighting\n        from omni.isaac.core.utils.prims import create_prim\n        create_prim(\n            prim_path="/World/Light",\n            prim_type="DistantLight",\n            position=[0, 0, 10],\n            attributes={"color": [0.8, 0.8, 0.8]}\n        )\n\n        self.isaac_connected = True\n        self.get_logger().info(\'Isaac Sim environment set up successfully\')\n\n    def run_simulation(self, steps=1000):\n        """Run Isaac Sim with ROS 2 integration"""\n        self.world.reset()\n\n        for step in range(steps):\n            self.world.step(render=True)\n\n            # Process Isaac Sim data and publish to ROS\n            if self.isaac_connected:\n                self.process_isaac_data()\n\n            # Check for ROS commands\n            rclpy.spin_once(self, timeout_sec=0)\n\n    def process_isaac_data(self):\n        """Process Isaac Sim sensor data and publish to ROS"""\n        try:\n            # Get camera image from Isaac Sim\n            camera_image = self.camera.get_rgba()\n\n            if camera_image is not None:\n                # Convert Isaac image to ROS Image message\n                ros_image = self.isaac_to_ros_image(camera_image)\n\n                # Publish image\n                self.image_pub.publish(ros_image)\n\n                # Publish camera info\n                self.publish_camera_info(ros_image.header)\n\n                # Performance monitoring\n                self.frame_count += 1\n                current_time = self.get_clock().now()\n                if (current_time - self.last_published_time).nanoseconds > 1e9:  # 1 second\n                    fps = self.frame_count / ((current_time - self.last_published_time).nanoseconds / 1e9)\n                    self.get_logger().info(f\'Published {self.frame_count} frames, FPS: {fps:.1f}\')\n                    self.frame_count = 0\n                    self.last_published_time = current_time\n\n        except Exception as e:\n            self.get_logger().error(f\'Error processing Isaac data: {e}\')\n\n    def isaac_to_ros_image(self, isaac_image):\n        """Convert Isaac Sim image to ROS Image message"""\n        import numpy as np\n        from cv_bridge import CvBridge\n\n        # Isaac image format may need conversion\n        # This is a simplified example - actual format depends on Isaac Sim version\n        image_data = np.array(isaac_image)\n\n        # Convert to ROS Image using CV Bridge\n        bridge = CvBridge()\n        ros_image = bridge.cv2_to_imgmsg(image_data, encoding=\'rgba8\')\n\n        # Set header\n        ros_image.header.stamp = self.get_clock().now().to_msg()\n        ros_image.header.frame_id = \'camera_rgb_optical_frame\'\n\n        return ros_image\n\n    def publish_camera_info(self, header):\n        """Publish camera calibration information"""\n        camera_info = CameraInfo()\n        camera_info.header = header\n        camera_info.header.frame_id = \'camera_rgb_optical_frame\'\n\n        # Set camera parameters (adjust based on actual Isaac Sim camera)\n        camera_info.width = 640\n        camera_info.height = 480\n        camera_info.distortion_model = \'plumb_bob\'\n        camera_info.d = [0.0, 0.0, 0.0, 0.0, 0.0]  # Distortion coefficients\n        camera_info.k = [525.0, 0.0, 319.5, 0.0, 525.0, 239.5, 0.0, 0.0, 1.0]  # Camera matrix\n        camera_info.r = [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]  # Rectification matrix\n        camera_info.p = [525.0, 0.0, 319.5, 0.0, 0.0, 525.0, 239.5, 0.0, 0.0, 0.0, 1.0, 0.0]  # Projection matrix\n\n        self.camera_info_pub.publish(camera_info)\n\n    def cmd_vel_callback(self, msg):\n        """Handle velocity commands from ROS"""\n        if self.robot is not None:\n            # Apply velocity command to Isaac Sim robot\n            # This would involve controlling the robot in Isaac Sim\n            linear_x = msg.linear.x\n            angular_z = msg.angular.z\n\n            # In Isaac Sim, you would apply these velocities to the robot\n            # The exact method depends on the robot model and control interface\n            self.apply_robot_velocity(linear_x, angular_z)\n\n    def apply_robot_velocity(self, linear_x, angular_z):\n        """Apply velocity to Isaac Sim robot"""\n        # This is a placeholder - actual implementation depends on robot model\n        # You would typically use Isaac Sim\'s control interfaces\n        self.get_logger().debug(f\'Applying velocity: linear_x={linear_x}, angular_z={angular_z}\')\n\ndef main(args=None):\n    # Initialize ROS 2\n    rclpy.init(args=args)\n\n    # Initialize Isaac Sim (this would be done in Isaac Sim\'s application)\n    # For this example, we assume Isaac Sim is already running\n\n    # Create integration node\n    integration_node = IsaacSimCompleteIntegration()\n\n    try:\n        # Set up Isaac environment\n        integration_node.setup_isaac_environment()\n\n        # Run simulation\n        integration_node.run_simulation(steps=1000)\n\n    except KeyboardInterrupt:\n        pass\n    finally:\n        integration_node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,r.jsx)(n.h3,{id:"lab-exercise-isaac-sim-integration",children:"Lab Exercise: Isaac Sim Integration"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Set up Isaac Sim with a mobile robot model"}),"\n",(0,r.jsx)(n.li,{children:"Implement ROS 2 bridge for sensor data (camera, LiDAR, IMU)"}),"\n",(0,r.jsx)(n.li,{children:"Create control interface for robot movement"}),"\n",(0,r.jsx)(n.li,{children:"Test integration with RViz2 visualization"}),"\n",(0,r.jsx)(n.li,{children:"Evaluate performance and optimize parameters"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"expected-results",children:"Expected Results"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Working Isaac Sim to ROS 2 integration"}),"\n",(0,r.jsx)(n.li,{children:"Real-time sensor data publishing"}),"\n",(0,r.jsx)(n.li,{children:"Robot control from ROS 2 commands"}),"\n",(0,r.jsx)(n.li,{children:"Proper coordinate frame transformations"}),"\n",(0,r.jsx)(n.li,{children:"Performance within acceptable limits"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"review-questions",children:"Review Questions"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Explain the architecture of Isaac Sim and its main components."}),"\n",(0,r.jsx)(n.li,{children:"How do you configure Isaac Sim for optimal performance with GPU acceleration?"}),"\n",(0,r.jsx)(n.li,{children:"What are the key differences between Isaac Sim and traditional simulation environments?"}),"\n",(0,r.jsx)(n.li,{children:"How do you troubleshoot common Isaac Sim integration issues?"}),"\n",(0,r.jsx)(n.li,{children:"What are the best practices for optimizing Isaac Sim pipeline performance?"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,r.jsx)(n.p,{children:"After mastering Isaac Sim fundamentals, students should proceed to:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Isaac ROS integration and advanced features"}),"\n",(0,r.jsx)(n.li,{children:"VSLAM implementation for humanoid robots"}),"\n",(0,r.jsx)(n.li,{children:"Navigation systems with Isaac Sim"}),"\n",(0,r.jsx)(n.li,{children:"Sim-to-real transfer techniques"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"This comprehensive guide to Isaac Sim fundamentals provides the foundation for creating photorealistic simulation environments essential for Physical AI and Humanoid Robotics development."})]})}function d(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>s,x:()=>o});var a=i(6540);const r={},t=a.createContext(r);function s(e){const n=a.useContext(t);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),a.createElement(t.Provider,{value:n},e.children)}}}]);