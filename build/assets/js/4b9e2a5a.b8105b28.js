"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_textbook=globalThis.webpackChunkphysical_ai_humanoid_robotics_textbook||[]).push([[8182],{6285:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>d,frontMatter:()=>r,metadata:()=>o,toc:()=>m});const o=JSON.parse('{"id":"module-3/isaac-sim-workflows","title":"Isaac Sim Workflows","description":"Overview","source":"@site/docs/module-3/isaac-sim-workflows.md","sourceDirName":"module-3","slug":"/module-3/isaac-sim-workflows","permalink":"/docs/module-3/isaac-sim-workflows","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-3/isaac-sim-workflows.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2}}');var s=i(4848),t=i(8453);const r={sidebar_position:2},a="Isaac Sim Workflows",l={},m=[{value:"Overview",id:"overview",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Isaac Sim Setup Workflows",id:"isaac-sim-setup-workflows",level:2},{value:"Initial Installation and Configuration",id:"initial-installation-and-configuration",level:3},{value:"Environment Configuration",id:"environment-configuration",level:3},{value:"Project Structure Setup",id:"project-structure-setup",level:3},{value:"Environment Creation Workflows",id:"environment-creation-workflows",level:2},{value:"Basic Environment Setup",id:"basic-environment-setup",level:3},{value:"Advanced Environment with USD",id:"advanced-environment-with-usd",level:3},{value:"Robot Integration Workflows",id:"robot-integration-workflows",level:2},{value:"Robot Spawning and Configuration",id:"robot-spawning-and-configuration",level:3},{value:"Physics Configuration",id:"physics-configuration",level:3},{value:"Simulation Execution Workflows",id:"simulation-execution-workflows",level:2},{value:"Basic Simulation Loop",id:"basic-simulation-loop",level:3},{value:"Advanced Simulation with Recording",id:"advanced-simulation-with-recording",level:3},{value:"ROS 2 Integration Workflows",id:"ros-2-integration-workflows",level:2},{value:"Isaac ROS Bridge Setup",id:"isaac-ros-bridge-setup",level:3},{value:"Performance Optimization Workflows",id:"performance-optimization-workflows",level:2},{value:"Simulation Performance Monitoring",id:"simulation-performance-monitoring",level:3},{value:"Troubleshooting and Best Practices",id:"troubleshooting-and-best-practices",level:2},{value:"Common Issues and Solutions",id:"common-issues-and-solutions",level:3},{value:"Practical Lab: Complete Isaac Sim VSLAM Integration",id:"practical-lab-complete-isaac-sim-vslam-integration",level:2},{value:"Lab Objective",id:"lab-objective",level:3},{value:"Implementation Steps",id:"implementation-steps",level:3},{value:"Step 1: Set up Isaac Sim Environment",id:"step-1-set-up-isaac-sim-environment",level:4},{value:"Lab Exercise: Isaac Sim VSLAM Implementation",id:"lab-exercise-isaac-sim-vslam-implementation",level:3},{value:"Expected Results",id:"expected-results",level:3},{value:"Best Practices",id:"best-practices",level:2},{value:"Isaac Sim Workflows Best Practices",id:"isaac-sim-workflows-best-practices",level:3},{value:"Integration Best Practices",id:"integration-best-practices",level:3},{value:"Review Questions",id:"review-questions",level:2},{value:"Next Steps",id:"next-steps",level:2}];function c(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"isaac-sim-workflows",children:"Isaac Sim Workflows"})}),"\n",(0,s.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsx)(n.p,{children:"This section details the essential workflows for using NVIDIA Isaac Sim in Physical AI and Humanoid Robotics development. From initial setup to advanced simulation scenarios, these workflows provide systematic approaches to leveraging Isaac Sim's photorealistic capabilities for robotics research and development."}),"\n",(0,s.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,s.jsx)(n.p,{children:"By the end of this section, students will be able to:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Set up and configure Isaac Sim environments for robotics applications"}),"\n",(0,s.jsx)(n.li,{children:"Implement systematic workflows for simulation development and testing"}),"\n",(0,s.jsx)(n.li,{children:"Create complex simulation scenarios with realistic environments"}),"\n",(0,s.jsx)(n.li,{children:"Integrate Isaac Sim with ROS 2 development workflows"}),"\n",(0,s.jsx)(n.li,{children:"Optimize simulation performance and realism"}),"\n",(0,s.jsx)(n.li,{children:"Validate simulation results against real-world performance"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"isaac-sim-setup-workflows",children:"Isaac Sim Setup Workflows"}),"\n",(0,s.jsx)(n.h3,{id:"initial-installation-and-configuration",children:"Initial Installation and Configuration"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Download and install Isaac Sim\nwget https://developer.download.nvidia.com/isaac/isaac_sim/isaac_sim_2023.1.0.tar.gz\ntar -xf isaac_sim_2023.1.0.tar.gz\ncd isaac_sim_2023.1.0\n\n# Install dependencies\n./install_dependencies.sh\n\n# Verify installation\npython3 -c \"import omni; print('Isaac Sim installed successfully')\"\n"})}),"\n",(0,s.jsx)(n.h3,{id:"environment-configuration",children:"Environment Configuration"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# Isaac Sim environment configuration script\nimport omni\nfrom omni.isaac.core import World\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\nfrom omni.isaac.core.utils.prims import create_primitive\nfrom omni.isaac.core.utils.carb import set_carb_setting\n\ndef configure_isaac_sim_environment():\n    """Configure Isaac Sim environment for optimal performance"""\n\n    # Set physics solver parameters\n    set_carb_setting("/physics/solverType", "TGS")  # TGS solver for stability\n    set_carb_setting("/physics/iterations", 16)     # Solver iterations\n    set_carb_setting("/physics/worker_thread_count", 8)  # Threading\n\n    # Set rendering parameters\n    set_carb_setting("/rtx/rendermode", "Interactive")  # Interactive rendering\n    set_carb_setting("/renderer/resolution/width", 1280)  # Resolution\n    set_carb_setting("/renderer/resolution/height", 720)\n\n    # Set simulation parameters\n    set_carb_setting("/app/player/playSimulations", True)\n    set_carb_setting("/app/window/dockSpace", True)\n\n    print("Isaac Sim environment configured successfully")\n\ndef setup_world_with_defaults():\n    """Set up Isaac Sim world with default configurations"""\n\n    # Create world with 1-meter stage units\n    world = World(stage_units_in_meters=1.0)\n\n    # Add default ground plane\n    world.scene.add_default_ground_plane()\n\n    # Add default lighting\n    from omni.isaac.core.utils.prims import create_prim\n    create_prim(\n        prim_path="/World/Light",\n        prim_type="DistantLight",\n        position=[0, 0, 10],\n        attributes={"color": [0.8, 0.8, 0.8]}\n    )\n\n    return world\n'})}),"\n",(0,s.jsx)(n.h3,{id:"project-structure-setup",children:"Project Structure Setup"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"isaac_sim_project/\n\u251c\u2500\u2500 assets/                 # Custom 3D models and environments\n\u2502   \u251c\u2500\u2500 robots/\n\u2502   \u2502   \u251c\u2500\u2500 humanoid.urdf\n\u2502   \u2502   \u2514\u2500\u2500 mobile_base.urdf\n\u2502   \u251c\u2500\u2500 environments/\n\u2502   \u2502   \u251c\u2500\u2500 office.usd\n\u2502   \u2502   \u2514\u2500\u2500 warehouse.usd\n\u2502   \u2514\u2500\u2500 objects/\n\u2502       \u251c\u2500\u2500 furniture.usd\n\u2502       \u2514\u2500\u2500 props.usd\n\u251c\u2500\u2500 configs/                # Configuration files\n\u2502   \u251c\u2500\u2500 robot_configs.yaml\n\u2502   \u2514\u2500\u2500 simulation_params.yaml\n\u251c\u2500\u2500 scripts/                # Python scripts for automation\n\u2502   \u251c\u2500\u2500 spawn_robot.py\n\u2502   \u251c\u2500\u2500 setup_scene.py\n\u2502   \u2514\u2500\u2500 run_simulation.py\n\u251c\u2500\u2500 launch/                 # ROS 2 launch files\n\u2502   \u2514\u2500\u2500 isaac_sim.launch.py\n\u2514\u2500\u2500 logs/                   # Simulation logs and outputs\n"})}),"\n",(0,s.jsx)(n.h2,{id:"environment-creation-workflows",children:"Environment Creation Workflows"}),"\n",(0,s.jsx)(n.h3,{id:"basic-environment-setup",children:"Basic Environment Setup"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# Basic environment creation workflow\nimport omni\nfrom omni.isaac.core import World\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\nfrom omni.isaac.core.utils.prims import create_primitive\nfrom omni.isaac.core.materials import OmniPBR\n\nclass EnvironmentCreator:\n    def __init__(self, world_units=1.0):\n        self.world = World(stage_units_in_meters=world_units)\n        self.objects = []\n\n    def create_basic_environment(self):\n        """Create a basic environment with ground and lighting"""\n\n        # Add ground plane\n        self.world.scene.add_default_ground_plane()\n\n        # Add lighting\n        self.add_lighting()\n\n        # Add basic objects\n        self.add_basic_objects()\n\n        return self.world\n\n    def add_lighting(self):\n        """Add realistic lighting to the environment"""\n\n        # Add dome light for ambient lighting\n        dome_light = self.world.scene.add(\n            prim_path="/World/DomeLight",\n            name="dome_light",\n            light_type="DomeLight",\n            color=[0.2, 0.2, 0.2],\n            intensity=300\n        )\n\n        # Add directional light for shadows\n        directional_light = self.world.scene.add(\n            prim_path="/World/DirectionalLight",\n            name="directional_light",\n            light_type="DistantLight",\n            color=[0.9, 0.9, 0.9],\n            intensity=1000\n        )\n\n    def add_basic_objects(self):\n        """Add basic objects to the environment"""\n\n        # Add a table\n        table = create_primitive(\n            prim_path="/World/table",\n            primitive_type="Cuboid",\n            position=[2, 0, 0.5],\n            scale=[1, 0.8, 1],\n            color=[0.6, 0.4, 0.2]\n        )\n\n        # Add a box\n        box = create_primitive(\n            prim_path="/World/box",\n            primitive_type="Cuboid",\n            position=[2, 1, 0.25],\n            scale=[0.5, 0.5, 0.5],\n            color=[0.8, 0.2, 0.2]\n        )\n\n        self.objects.extend([table, box])\n\n    def create_office_environment(self):\n        """Create an office-style environment"""\n\n        # Start with basic environment\n        self.create_basic_environment()\n\n        # Add office-specific objects\n        self.add_office_desk()\n        self.add_office_chair()\n        self.add_office_equipment()\n\n    def add_office_desk(self):\n        """Add office desk to environment"""\n\n        desk = create_primitive(\n            prim_path="/World/desk",\n            primitive_type="Cuboid",\n            position=[0, 2, 0.4],\n            scale=[1.5, 0.8, 0.8],\n            color=[0.4, 0.4, 0.4]\n        )\n\n        # Add desk legs\n        for i in range(4):\n            x_offset = (-0.6 if i < 2 else 0.6)\n            y_offset = (-0.3 if i % 2 == 0 else 0.3)\n\n            leg = create_primitive(\n                prim_path=f"/World/desk_leg_{i}",\n                primitive_type="Cylinder",\n                position=[x_offset, y_offset, 0.2],\n                scale=[0.05, 0.05, 0.4],\n                color=[0.3, 0.3, 0.3]\n            )\n\n        self.objects.append(desk)\n\n    def add_office_chair(self):\n        """Add office chair to environment"""\n\n        chair_seat = create_primitive(\n            prim_path="/World/chair_seat",\n            primitive_type="Cuboid",\n            position=[0, 1.5, 0.2],\n            scale=[0.4, 0.4, 0.1],\n            color=[0.2, 0.2, 0.2]\n        )\n\n        self.objects.append(chair_seat)\n\n    def add_office_equipment(self):\n        """Add office equipment and decorations"""\n\n        # Add monitor\n        monitor = create_primitive(\n            prim_path="/World/monitor",\n            primitive_type="Cuboid",\n            position=[0, 2.1, 0.7],\n            scale=[0.4, 0.3, 0.02],\n            color=[0.1, 0.1, 0.1]\n        )\n\n        # Add plant\n        plant_pot = create_primitive(\n            prim_path="/World/plant_pot",\n            primitive_type="Cylinder",\n            position=[-1, 0, 0.25],\n            scale=[0.2, 0.2, 0.5],\n            color=[0.6, 0.4, 0.2]\n        )\n\n        self.objects.extend([monitor, plant_pot])\n'})}),"\n",(0,s.jsx)(n.h3,{id:"advanced-environment-with-usd",children:"Advanced Environment with USD"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# Advanced environment using USD composition\nimport omni\nfrom pxr import Usd, Sdf, Gf, UsdGeom, UsdLux\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\n\nclass AdvancedEnvironmentBuilder:\n    def __init__(self, stage_path="/World"):\n        self.stage_path = stage_path\n        self.stage = omni.usd.get_context().get_stage()\n\n    def create_complex_office_scene(self):\n        """Create a complex office scene using USD composition"""\n\n        # Create main office room\n        room_prim = self.stage.DefinePrim(f"{self.stage_path}/OfficeRoom", "Xform")\n\n        # Add room geometry\n        self.add_room_walls(room_prim)\n        self.add_room_floor(room_prim)\n        self.add_room_ceiling(room_prim)\n\n        # Add furniture and objects\n        self.add_desks_and_chairs(room_prim)\n        self.add_meeting_area(room_prim)\n        self.add_decorations(room_prim)\n\n        # Add lighting\n        self.add_office_lighting(room_prim)\n\n    def add_room_walls(self, parent_prim):\n        """Add room walls"""\n\n        # Define room dimensions\n        room_size = Gf.Vec3f(10, 8, 3)  # width, depth, height\n        wall_thickness = 0.1\n\n        # Create walls\n        walls = [\n            ("wall_front", Gf.Vec3f(0, room_size[1]/2, room_size[2]/2), Gf.Vec3f(room_size[0], wall_thickness, room_size[2])),\n            ("wall_back", Gf.Vec3f(0, -room_size[1]/2, room_size[2]/2), Gf.Vec3f(room_size[0], wall_thickness, room_size[2])),\n            ("wall_left", Gf.Vec3f(-room_size[0]/2, 0, room_size[2]/2), Gf.Vec3f(wall_thickness, room_size[1], room_size[2])),\n            ("wall_right", Gf.Vec3f(room_size[0]/2, 0, room_size[2]/2), Gf.Vec3f(wall_thickness, room_size[1], room_size[2]))\n        ]\n\n        for name, position, size in walls:\n            wall_prim = self.stage.DefinePrim(f"{parent_prim.GetPath()}/{name}", "Cube")\n            UsdGeom.XformCommonAPI(wall_prim).SetTranslate(position)\n            UsdGeom.XformCommonAPI(wall_prim).SetScale(size)\n\n            # Apply wall material\n            self.apply_wall_material(wall_prim)\n\n    def apply_wall_material(self, prim):\n        """Apply realistic wall material"""\n        # This would apply OmniPBR material for realistic appearance\n        pass\n\n    def add_desks_and_chairs(self, parent_prim):\n        """Add desks and chairs in office arrangement"""\n\n        # Create desk arrangement\n        for i in range(3):\n            desk_x = -3 + i * 3\n            self.add_desk_at_position(parent_prim, Gf.Vec3f(desk_x, 2, 0))\n\n    def add_desk_at_position(self, parent_prim, position):\n        """Add a complete desk setup at given position"""\n\n        # Create desk group\n        desk_group = self.stage.DefinePrim(f"{parent_prim.GetPath()}/Desk_{position[0]}", "Xform")\n        UsdGeom.XformCommonAPI(desk_group).SetTranslate(position)\n\n        # Add desk top\n        desk_top = self.stage.DefinePrim(f"{desk_group.GetPath()}/Top", "Cube")\n        UsdGeom.XformCommonAPI(desk_top).SetTranslate(Gf.Vec3f(0, 0, 0.75))\n        UsdGeom.XformCommonAPI(desk_top).SetScale(Gf.Vec3f(1.5, 0.8, 0.05))\n\n        # Add desk legs\n        for j in range(4):\n            leg_x = (-0.7 if j < 2 else 0.7)\n            leg_y = (-0.35 if j % 2 == 0 else 0.35)\n\n            leg = self.stage.DefinePrim(f"{desk_group.GetPath()}/Leg_{j}", "Cylinder")\n            UsdGeom.XformCommonAPI(leg).SetTranslate(Gf.Vec3f(leg_x, leg_y, 0.35))\n            UsdGeom.XformCommonAPI(leg).SetScale(Gf.Vec3f(0.05, 0.05, 0.7))\n'})}),"\n",(0,s.jsx)(n.h2,{id:"robot-integration-workflows",children:"Robot Integration Workflows"}),"\n",(0,s.jsx)(n.h3,{id:"robot-spawning-and-configuration",children:"Robot Spawning and Configuration"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# Robot integration workflow\nimport omni\nfrom omni.isaac.core import World\nfrom omni.isaac.core.robots import Robot\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\nfrom omni.isaac.core.utils.prims import get_prim_at_path\nfrom omni.isaac.core.articulations import ArticulationView\n\nclass RobotIntegrationManager:\n    def __init__(self, world):\n        self.world = world\n        self.robots = {}\n\n    def spawn_robot_from_usd(self, robot_name, usd_path, position=[0, 0, 0.5], orientation=[0, 0, 0, 1]):\n        """Spawn robot from USD file"""\n\n        prim_path = f"/World/{robot_name}"\n\n        # Add robot to stage\n        add_reference_to_stage(\n            usd_path=usd_path,\n            prim_path=prim_path\n        )\n\n        # Create robot object\n        robot = Robot(\n            prim_path=prim_path,\n            name=robot_name,\n            position=position,\n            orientation=orientation\n        )\n\n        # Add to world\n        self.world.scene.add(robot)\n\n        # Store reference\n        self.robots[robot_name] = robot\n\n        return robot\n\n    def spawn_mobile_robot(self, robot_name="mobile_robot", position=[0, 0, 0.1]):\n        """Spawn a mobile robot (e.g., TurtleBot3)"""\n\n        # Use a standard mobile robot model\n        robot = self.spawn_robot_from_usd(\n            robot_name=robot_name,\n            usd_path="/Isaac/Robots/TurtleBot3Burger/turtlebot3_burger.usd",\n            position=position\n        )\n\n        return robot\n\n    def spawn_humanoid_robot(self, robot_name="humanoid_robot", position=[0, 0, 0.8]):\n        """Spawn a humanoid robot"""\n\n        # Use a humanoid robot model\n        robot = self.spawn_robot_from_usd(\n            robot_name=robot_name,\n            usd_path="/Isaac/Robots/NVIDIA/Isaac/Robots/ant.usd",  # Example humanoid\n            position=position\n        )\n\n        return robot\n\n    def configure_robot_sensors(self, robot_name):\n        """Configure sensors for the robot"""\n\n        robot = self.robots[robot_name]\n\n        # Add RGB camera\n        self.add_camera_to_robot(robot)\n\n        # Add IMU\n        self.add_imu_to_robot(robot)\n\n        # Add LiDAR (if applicable)\n        self.add_lidar_to_robot(robot)\n\n    def add_camera_to_robot(self, robot):\n        """Add RGB camera to robot"""\n\n        from omni.isaac.sensor import Camera\n\n        camera = Camera(\n            prim_path=f"{robot.prim_path}/chassis/camera",\n            frequency=30,\n            resolution=(640, 480)\n        )\n\n        self.world.scene.add(camera)\n\n    def add_imu_to_robot(self, robot):\n        """Add IMU to robot"""\n\n        from omni.isaac.sensor import IMU\n\n        imu = IMU(\n            prim_path=f"{robot.prim_path}/chassis/imu",\n            frequency=100\n        )\n\n        self.world.scene.add(imu)\n\n    def add_lidar_to_robot(self, robot):\n        """Add LiDAR to robot"""\n\n        from omni.isaac.sensor import RotatingLidarSensor\n\n        lidar = RotatingLidarSensor(\n            prim_path=f"{robot.prim_path}/chassis/lidar",\n            translation=np.array([0, 0, 0.2]),\n            orientation=np.array([0, 0, 0, 1]),\n            name="Lidar_Sensor",\n            fov=360,\n            horizontal_resolution=1,\n            vertical_resolution=1,\n            range=25.0,\n            rotation_frequency=20,\n            samples_per_cycle=360\n        )\n\n        self.world.scene.add(lidar)\n\n    def configure_robot_controllers(self, robot_name):\n        """Configure robot controllers"""\n\n        robot = self.robots[robot_name]\n\n        # Set up joint properties for control\n        self.configure_joint_properties(robot)\n\n        # Set up control interfaces\n        self.setup_control_interfaces(robot)\n\n    def configure_joint_properties(self, robot):\n        """Configure robot joint properties"""\n\n        from omni.isaac.core.utils.stage import get_current_stage\n        from omni.isaac.core.utils.prims import get_prim_at_path\n        from pxr import PhysxSchema, UsdPhysics\n\n        stage = get_current_stage()\n\n        # Configure joint friction and damping\n        for joint_name in robot.joint_names:\n            joint_path = f"{robot.prim_path}/{joint_name}"\n            joint_prim = get_prim_at_path(joint_path)\n\n            # Set joint properties\n            if joint_prim:\n                # Set joint friction\n                PhysxSchema.PhysxJointAPI(joint_prim).CreateJointFrictionAttr(0.1)\n\n                # Set joint damping\n                PhysxSchema.PhysxJointAPI(joint_prim).CreateJointDampingAttr(0.01)\n\n    def setup_control_interfaces(self, robot):\n        """Set up control interfaces for the robot"""\n\n        # This would set up ROS 2 control interfaces\n        # or other control systems depending on the application\n        pass\n'})}),"\n",(0,s.jsx)(n.h3,{id:"physics-configuration",children:"Physics Configuration"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# Physics configuration for realistic robot simulation\nfrom omni.isaac.core.utils.physics import set_articulation_properties\nfrom omni.isaac.core.utils.prims import get_prim_at_path\n\ndef configure_robot_physics(robot):\n    """Configure physics properties for realistic robot simulation"""\n\n    # Get robot articulation\n    articulation = get_prim_at_path(robot.prim_path)\n\n    # Set physics properties\n    set_articulation_properties(\n        articulation=articulation,\n        joint_friction=[0.1] * len(robot.joint_names),  # Joint friction\n        joint_damping=[0.01] * len(robot.joint_names),  # Joint damping\n        joint_stiffness=[0.0] * len(robot.joint_names)  # Joint stiffness\n    )\n\n    # Configure collision properties\n    configure_collision_properties(robot)\n\ndef configure_collision_properties(robot):\n    """Configure collision properties for the robot"""\n    # Add collision filtering and material properties\n    # This would include setting up proper collision groups\n    # and material properties for realistic interactions\n    pass\n'})}),"\n",(0,s.jsx)(n.h2,{id:"simulation-execution-workflows",children:"Simulation Execution Workflows"}),"\n",(0,s.jsx)(n.h3,{id:"basic-simulation-loop",children:"Basic Simulation Loop"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# Basic simulation execution workflow\nimport time\nimport threading\nfrom collections import deque\n\nclass SimulationExecutor:\n    def __init__(self, world, robots=None):\n        self.world = world\n        self.robots = robots or {}\n        self.is_running = False\n        self.simulation_time = 0.0\n        self.real_time_factor = 1.0\n\n        # Performance monitoring\n        self.frame_times = deque(maxlen=100)\n        self.simulation_times = deque(maxlen=100)\n\n    def run_simulation(self, duration=60.0, realtime=True):\n        """Run simulation for specified duration"""\n\n        self.is_running = True\n        start_time = time.time()\n\n        while self.is_running and (time.time() - start_time) < duration:\n            frame_start = time.time()\n\n            # Step simulation\n            self.world.step(render=True)\n\n            # Process robot control\n            self.process_robot_control()\n\n            # Process sensor data\n            self.process_sensor_data()\n\n            # Monitor performance\n            frame_time = time.time() - frame_start\n            self.frame_times.append(frame_time)\n\n            # Maintain real-time factor if requested\n            if realtime and frame_time < (1.0 / 60.0):  # 60 FPS target\n                sleep_time = (1.0 / 60.0) - frame_time\n                time.sleep(sleep_time)\n\n        self.is_running = False\n\n    def process_robot_control(self):\n        """Process robot control commands"""\n\n        for robot_name, robot in self.robots.items():\n            # Get control commands (from ROS 2 or other interfaces)\n            control_cmd = self.get_robot_command(robot_name)\n\n            if control_cmd:\n                # Apply control to robot\n                self.apply_robot_control(robot, control_cmd)\n\n    def process_sensor_data(self):\n        """Process sensor data from all robots"""\n\n        for robot_name, robot in self.robots.items():\n            # Get sensor data\n            sensor_data = self.get_robot_sensor_data(robot_name)\n\n            if sensor_data:\n                # Process and publish sensor data\n                self.process_and_publish_sensor_data(robot_name, sensor_data)\n\n    def get_robot_command(self, robot_name):\n        """Get control command for robot"""\n        # This would interface with ROS 2 or other control systems\n        return None\n\n    def apply_robot_control(self, robot, control_cmd):\n        """Apply control command to robot"""\n        # Apply control command to robot\n        pass\n\n    def get_robot_sensor_data(self, robot_name):\n        """Get sensor data from robot"""\n        # Get sensor data from robot sensors\n        return {}\n\n    def process_and_publish_sensor_data(self, robot_name, sensor_data):\n        """Process and publish sensor data"""\n        # Process and publish sensor data to ROS 2 or other systems\n        pass\n\n    def get_performance_metrics(self):\n        """Get current performance metrics"""\n\n        if self.frame_times:\n            avg_frame_time = sum(self.frame_times) / len(self.frame_times)\n            current_fps = 1.0 / avg_frame_time if avg_frame_time > 0 else 0\n\n            # Calculate real-time factor\n            avg_sim_step = sum(self.simulation_times) / len(self.simulation_times) if self.simulation_times else 0\n            rtf = avg_sim_step / (1.0/60.0) if avg_sim_step > 0 else 0\n        else:\n            current_fps = 0\n            rtf = 0\n\n        return {\n            \'fps\': current_fps,\n            \'real_time_factor\': rtf,\n            \'frame_times\': list(self.frame_times),\n            \'simulation_times\': list(self.simulation_times)\n        }\n'})}),"\n",(0,s.jsx)(n.h3,{id:"advanced-simulation-with-recording",children:"Advanced Simulation with Recording"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# Advanced simulation with recording capabilities\nimport numpy as np\nimport cv2\nfrom PIL import Image\nimport os\n\nclass AdvancedSimulationRecorder:\n    def __init__(self, world, output_dir=\"simulation_recordings\"):\n        self.world = world\n        self.output_dir = output_dir\n        self.recordings = {}\n        self.is_recording = False\n\n        # Create output directory\n        os.makedirs(output_dir, exist_ok=True)\n        os.makedirs(f\"{output_dir}/images\", exist_ok=True)\n        os.makedirs(f\"{output_dir}/depth\", exist_ok=True)\n        os.makedirs(f\"{output_dir}/poses\", exist_ok=True)\n\n    def start_recording(self, recording_name, record_images=True, record_depth=True, record_poses=True):\n        \"\"\"Start recording simulation data\"\"\"\n\n        self.is_recording = True\n        self.current_recording = recording_name\n\n        # Initialize recording data\n        self.recordings[recording_name] = {\n            'images': [] if record_images else None,\n            'depth': [] if record_depth else None,\n            'poses': [] if record_poses else None,\n            'timestamps': [],\n            'record_images': record_images,\n            'record_depth': record_depth,\n            'record_poses': record_poses\n        }\n\n        print(f\"Started recording: {recording_name}\")\n\n    def record_frame(self, robot, camera, timestamp):\n        \"\"\"Record current frame data\"\"\"\n\n        if not self.is_recording:\n            return\n\n        recording = self.recordings[self.current_recording]\n        recording['timestamps'].append(timestamp)\n\n        # Record image if requested\n        if recording['record_images'] and camera:\n            image = self.get_camera_image(camera)\n            if image is not None:\n                recording['images'].append(image)\n                # Save to file\n                img_pil = Image.fromarray(image)\n                img_pil.save(f\"{self.output_dir}/images/frame_{len(recording['images']):06d}.png\")\n\n        # Record depth if requested\n        if recording['record_depth'] and camera:\n            depth = self.get_camera_depth(camera)\n            if depth is not None:\n                recording['depth'].append(depth)\n                # Save to file\n                depth_pil = Image.fromarray((depth * 1000).astype(np.uint16))  # Scale for 16-bit\n                depth_pil.save(f\"{self.output_dir}/depth/depth_{len(recording['depth']):06d}.png\")\n\n        # Record pose if requested\n        if recording['record_poses'] and robot:\n            pose = robot.get_world_pose()\n            recording['poses'].append(pose)\n\n    def get_camera_image(self, camera):\n        \"\"\"Get current camera image\"\"\"\n        try:\n            # Get image from Isaac Sim camera\n            image_data = camera.get_rgb()\n            return image_data\n        except Exception as e:\n            print(f\"Error getting camera image: {e}\")\n            return None\n\n    def get_camera_depth(self, camera):\n        \"\"\"Get current camera depth\"\"\"\n        try:\n            # Get depth from Isaac Sim depth sensor\n            depth_data = camera.get_depth()\n            return depth_data\n        except Exception as e:\n            print(f\"Error getting camera depth: {e}\")\n            return None\n\n    def stop_recording(self):\n        \"\"\"Stop current recording and save metadata\"\"\"\n\n        if not self.is_recording:\n            return\n\n        # Save metadata\n        recording = self.recordings[self.current_recording]\n        metadata = {\n            'recording_name': self.current_recording,\n            'total_frames': len(recording['timestamps']),\n            'duration': max(recording['timestamps']) - min(recording['timestamps']) if recording['timestamps'] else 0,\n            'record_images': recording['record_images'],\n            'record_depth': recording['record_depth'],\n            'record_poses': recording['record_poses']\n        }\n\n        import json\n        with open(f\"{self.output_dir}/{self.current_recording}_metadata.json\", 'w') as f:\n            json.dump(metadata, f, indent=2)\n\n        print(f\"Stopped recording: {self.current_recording}\")\n        print(f\"Recorded {metadata['total_frames']} frames\")\n\n        self.is_recording = False\n"})}),"\n",(0,s.jsx)(n.h2,{id:"ros-2-integration-workflows",children:"ROS 2 Integration Workflows"}),"\n",(0,s.jsx)(n.h3,{id:"isaac-ros-bridge-setup",children:"Isaac ROS Bridge Setup"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# Isaac ROS bridge integration workflow\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image, CameraInfo, PointCloud2, LaserScan\nfrom geometry_msgs.msg import Twist, PoseStamped\nfrom nav_msgs.msg import Odometry\nfrom std_msgs.msg import Header\nfrom cv_bridge import CvBridge\nimport numpy as np\n\nclass IsaacROSIntegration(Node):\n    def __init__(self):\n        super().__init__('isaac_ros_integration')\n\n        # Initialize CV bridge\n        self.cv_bridge = CvBridge()\n\n        # Publishers for Isaac Sim data\n        self.rgb_publisher = self.create_publisher(Image, 'camera/rgb/image_raw', 10)\n        self.depth_publisher = self.create_publisher(Image, 'camera/depth/image_raw', 10)\n        self.odom_publisher = self.create_publisher(Odometry, 'odom', 10)\n        self.scan_publisher = self.create_publisher(LaserScan, 'scan', 10)\n        self.camera_info_publisher = self.create_publisher(CameraInfo, 'camera/rgb/camera_info', 10)\n\n        # Subscribers for robot commands\n        self.cmd_vel_subscriber = self.create_subscription(\n            Twist, 'cmd_vel', self.cmd_vel_callback, 10)\n        self.goal_subscriber = self.create_subscription(\n            PoseStamped, 'goal_pose', self.goal_callback, 10)\n\n        # Timer for publishing sensor data\n        self.publish_timer = self.create_timer(0.1, self.publish_sensor_data)\n\n        # Isaac Sim integration\n        self.isaac_connected = False\n        self.robot_pose = np.eye(4)\n        self.camera_data = None\n        self.lidar_data = None\n\n        self.get_logger().info('Isaac ROS Integration Node Started')\n\n    def setup_isaac_connection(self):\n        \"\"\"Set up connection to Isaac Sim\"\"\"\n        # This would establish connection to Isaac Sim\n        # In practice, this might involve launching Isaac Sim\n        # or connecting to a running instance\n        self.isaac_connected = True\n        self.get_logger().info('Connected to Isaac Sim')\n\n    def cmd_vel_callback(self, msg):\n        \"\"\"Handle velocity commands from ROS\"\"\"\n        if not self.isaac_connected:\n            return\n\n        # Convert ROS Twist to Isaac Sim control\n        linear_x = msg.linear.x\n        angular_z = msg.angular.z\n\n        # Apply to Isaac Sim robot\n        self.apply_robot_control(linear_x, angular_z)\n\n        self.get_logger().debug(f'Received cmd_vel: linear_x={linear_x}, angular_z={angular_z}')\n\n    def goal_callback(self, msg):\n        \"\"\"Handle navigation goals from ROS\"\"\"\n        if not self.isaac_connected:\n            return\n\n        # Extract goal position\n        goal_x = msg.pose.position.x\n        goal_y = msg.pose.position.y\n        goal_z = msg.pose.position.z\n\n        # Send to Isaac Sim navigation system\n        self.set_navigation_goal(goal_x, goal_y, goal_z)\n\n        self.get_logger().info(f'Set navigation goal: ({goal_x}, {goal_y}, {goal_z})')\n\n    def publish_sensor_data(self):\n        \"\"\"Publish sensor data from Isaac Sim to ROS\"\"\"\n        if not self.isaac_connected:\n            return\n\n        # Get data from Isaac Sim\n        sensor_data = self.get_isaac_sensor_data()\n\n        if sensor_data:\n            # Publish RGB image\n            if 'rgb_image' in sensor_data:\n                rgb_msg = self.create_image_message(sensor_data['rgb_image'])\n                rgb_msg.header.frame_id = 'camera_rgb_optical_frame'\n                self.rgb_publisher.publish(rgb_msg)\n\n                # Publish camera info\n                self.publish_camera_info(rgb_msg.header)\n\n            # Publish depth image\n            if 'depth_image' in sensor_data:\n                depth_msg = self.create_image_message(sensor_data['depth_image'])\n                depth_msg.header.frame_id = 'camera_depth_optical_frame'\n                self.depth_publisher.publish(depth_msg)\n\n            # Publish odometry\n            if 'odometry' in sensor_data:\n                odom_msg = self.create_odometry_message(sensor_data['odometry'])\n                self.odom_publisher.publish(odom_msg)\n\n            # Publish laser scan\n            if 'laser_scan' in sensor_data:\n                scan_msg = self.create_laser_scan_message(sensor_data['laser_scan'])\n                self.scan_publisher.publish(scan_msg)\n\n    def create_image_message(self, image_array):\n        \"\"\"Create ROS Image message from numpy array\"\"\"\n        # Convert numpy array to ROS Image\n        image_msg = self.cv_bridge.cv2_to_imgmsg(image_array, encoding='rgb8')\n        image_msg.header.stamp = self.get_clock().now().to_msg()\n        return image_msg\n\n    def create_odometry_message(self, odometry_data):\n        \"\"\"Create ROS Odometry message\"\"\"\n        odom_msg = Odometry()\n        odom_msg.header.stamp = self.get_clock().now().to_msg()\n        odom_msg.header.frame_id = 'odom'\n        odom_msg.child_frame_id = 'base_link'\n\n        # Set pose\n        odom_msg.pose.pose.position.x = odometry_data['position'][0]\n        odom_msg.pose.pose.position.y = odometry_data['position'][1]\n        odom_msg.pose.pose.position.z = odometry_data['position'][2]\n\n        odom_msg.pose.pose.orientation.x = odometry_data['orientation'][0]\n        odom_msg.pose.pose.orientation.y = odometry_data['orientation'][1]\n        odom_msg.pose.pose.orientation.z = odometry_data['orientation'][2]\n        odom_msg.pose.pose.orientation.w = odometry_data['orientation'][3]\n\n        # Set twist (velocity)\n        odom_msg.twist.twist.linear.x = odometry_data['linear_velocity'][0]\n        odom_msg.twist.twist.linear.y = odometry_data['linear_velocity'][1]\n        odom_msg.twist.twist.linear.z = odometry_data['linear_velocity'][2]\n\n        odom_msg.twist.twist.angular.x = odometry_data['angular_velocity'][0]\n        odom_msg.twist.twist.angular.y = odometry_data['angular_velocity'][1]\n        odom_msg.twist.twist.angular.z = odometry_data['angular_velocity'][2]\n\n        return odom_msg\n\n    def create_laser_scan_message(self, scan_data):\n        \"\"\"Create ROS LaserScan message\"\"\"\n        scan_msg = LaserScan()\n        scan_msg.header.stamp = self.get_clock().now().to_msg()\n        scan_msg.header.frame_id = 'laser_frame'\n\n        # Set scan parameters\n        scan_msg.angle_min = scan_data['angle_min']\n        scan_msg.angle_max = scan_data['angle_max']\n        scan_msg.angle_increment = scan_data['angle_increment']\n        scan_msg.time_increment = scan_data['time_increment']\n        scan_msg.scan_time = scan_data['scan_time']\n        scan_msg.range_min = scan_data['range_min']\n        scan_msg.range_max = scan_data['range_max']\n\n        # Set range data\n        scan_msg.ranges = scan_data['ranges']\n        scan_msg.intensities = scan_data.get('intensities', [])\n\n        return scan_msg\n\n    def publish_camera_info(self, header):\n        \"\"\"Publish camera calibration information\"\"\"\n        camera_info = CameraInfo()\n        camera_info.header = header\n        camera_info.header.frame_id = 'camera_rgb_optical_frame'\n\n        # Set camera parameters (adjust based on actual Isaac Sim camera)\n        camera_info.width = 640\n        camera_info.height = 480\n        camera_info.distortion_model = 'plumb_bob'\n        camera_info.d = [0.0, 0.0, 0.0, 0.0, 0.0]  # Distortion coefficients\n        camera_info.k = [525.0, 0.0, 319.5, 0.0, 525.0, 239.5, 0.0, 0.0, 1.0]  # Camera matrix\n        camera_info.r = [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]  # Rectification matrix\n        camera_info.p = [525.0, 0.0, 319.5, 0.0, 0.0, 525.0, 239.5, 0.0, 0.0, 0.0, 1.0, 0.0]  # Projection matrix\n\n        self.camera_info_publisher.publish(camera_info)\n\n    def get_isaac_sensor_data(self):\n        \"\"\"Get sensor data from Isaac Sim\"\"\"\n        # This would interface with Isaac Sim to get sensor data\n        # Return a dictionary with sensor data\n        return {\n            'rgb_image': np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8),  # Placeholder\n            'depth_image': np.random.random((480, 640)).astype(np.float32),  # Placeholder\n            'odometry': {\n                'position': [0.0, 0.0, 0.0],\n                'orientation': [0.0, 0.0, 0.0, 1.0],\n                'linear_velocity': [0.0, 0.0, 0.0],\n                'angular_velocity': [0.0, 0.0, 0.0]\n            },\n            'laser_scan': {\n                'angle_min': -np.pi,\n                'angle_max': np.pi,\n                'angle_increment': np.pi / 180.0,  # 1 degree\n                'time_increment': 0.0,\n                'scan_time': 0.1,\n                'range_min': 0.1,\n                'range_max': 30.0,\n                'ranges': [float(np.random.random() * 10) for _ in range(360)]  # Placeholder\n            }\n        }\n\n    def apply_robot_control(self, linear_x, angular_z):\n        \"\"\"Apply control to Isaac Sim robot\"\"\"\n        # This would interface with Isaac Sim to control the robot\n        # Implementation depends on the robot model and control interface\n        pass\n\n    def set_navigation_goal(self, goal_x, goal_y, goal_z):\n        \"\"\"Set navigation goal in Isaac Sim\"\"\"\n        # This would set a navigation goal in Isaac Sim\n        # Implementation depends on Isaac Sim's navigation system\n        pass\n"})}),"\n",(0,s.jsx)(n.h2,{id:"performance-optimization-workflows",children:"Performance Optimization Workflows"}),"\n",(0,s.jsx)(n.h3,{id:"simulation-performance-monitoring",children:"Simulation Performance Monitoring"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# Performance optimization workflow\nimport time\nimport threading\nfrom collections import deque\nimport psutil\nimport GPUtil\n\nclass IsaacSimPerformanceOptimizer:\n    def __init__(self, target_fps=30):\n        self.target_fps = target_fps\n        self.frame_times = deque(maxlen=30)  # Last 30 frame times\n        self.processing_times = deque(maxlen=30)\n        self.memory_usage = deque(maxlen=30)\n        self.cpu_usage = deque(maxlen=30)\n\n        # Performance optimization parameters\n        self.optimization_params = {\n            'image_decimation': 1,  # Process every Nth frame\n            'pointcloud_decimation': 4,  # Process every 4th point\n            'feature_count': 1000,  # Number of features to track\n            'bundle_adjustment_frequency': 10  # BA every N keyframes\n        }\n\n        # Threading for performance monitoring\n        self.monitoring_thread = threading.Thread(target=self.monitor_performance)\n        self.monitoring_thread.daemon = True\n        self.monitoring_thread.start()\n\n    def monitor_performance(self):\n        \"\"\"Monitor system performance in separate thread\"\"\"\n        while True:\n            # CPU usage\n            cpu_percent = psutil.cpu_percent(interval=0.1)\n            self.cpu_usage.append(cpu_percent)\n\n            # Memory usage\n            memory_percent = psutil.virtual_memory().percent\n            self.memory_usage.append(memory_percent)\n\n            # GPU usage if available\n            gpus = GPUtil.getGPUs()\n            if gpus:\n                gpu_percent = gpus[0].load * 100\n                self.gpu_usage.append(gpu_percent)\n            else:\n                self.gpu_usage.append(0)\n\n            time.sleep(0.1)\n\n    def adaptive_processing(self, data_type='image'):\n        \"\"\"Adapt processing based on performance\"\"\"\n        if len(self.frame_times) > 1:\n            avg_frame_time = sum(self.frame_times) / len(self.frame_times)\n            current_fps = 1.0 / avg_frame_time if avg_frame_time > 0 else 0\n\n            if current_fps < self.target_fps * 0.8:\n                # Performance is low, reduce processing load\n                if data_type == 'image':\n                    self.optimization_params['feature_count'] = max(500,\n                        int(self.optimization_params['feature_count'] * 0.9))\n                    self.optimization_params['image_decimation'] = min(5,\n                        self.optimization_params['image_decimation'] + 1)\n                elif data_type == 'lidar':\n                    self.optimization_params['pointcloud_decimation'] = min(16,\n                        self.optimization_params['pointcloud_decimation'] * 2)\n            elif current_fps > self.target_fps * 1.1:\n                # Performance is good, can afford more processing\n                if data_type == 'image':\n                    self.optimization_params['feature_count'] = min(2000,\n                        int(self.optimization_params['feature_count'] * 1.1))\n                    self.optimization_params['image_decimation'] = max(1,\n                        self.optimization_params['image_decimation'] - 1)\n                elif data_type == 'lidar':\n                    self.optimization_params['pointcloud_decimation'] = max(1,\n                        self.optimization_params['pointcloud_decimation'] // 1.1)\n\n    def optimize_rendering_settings(self):\n        \"\"\"Optimize rendering settings for performance\"\"\"\n\n        # Reduce rendering quality for training data generation\n        from omni.isaac.core.utils.carb import set_carb_setting\n\n        set_carb_setting(\"/rtx/rendermode\", \"Interactive\")  # Less demanding than Raytraced\n        set_carb_setting(\"/rtx/indirectdiffuse:disable\", True)  # Disable expensive effects\n        set_carb_setting(\"/rtx/pathtracing:disable\", True)  # Disable full path tracing\n        set_carb_setting(\"/renderer/maxSamples\", 16)  # Reduce max samples for faster rendering\n\n        # Optimize for synthetic data generation\n        set_carb_setting(\"/app/player/playSimulations\", False)  # Don't play animations during data gen\n        set_carb_setting(\"/renderer/resolution/width\", 640)  # Lower resolution for faster processing\n        set_carb_setting(\"/renderer/resolution/height\", 480)  # Lower resolution for faster processing\n\n    def optimize_physics_settings(self):\n        \"\"\"Optimize physics settings for performance\"\"\"\n\n        from omni.isaac.core.utils.carb import set_carb_setting\n\n        # Adjust physics parameters for better performance\n        set_carb_setting(\"/physics/solverType\", \"TGS\")  # Generally faster solver\n        set_carb_setting(\"/physics/iterations\", 8)  # Reduce iterations for speed\n        set_carb_setting(\"/physics/maxDepenetrationVelocity\", 10.0)  # Limit velocity for stability\n\n        # Reduce contact processing\n        set_carb_setting(\"/physics/contactCollection\", 2)  # Reduce contact processing\n        set_carb_setting(\"/physics/maxAngularSpeed\", 50.0)  # Limit angular velocity\n\n    def get_performance_metrics(self):\n        \"\"\"Get current performance metrics\"\"\"\n        if len(self.frame_times) > 1:\n            avg_frame_time = sum(self.frame_times) / len(self.frame_times)\n            current_fps = 1.0 / avg_frame_time if avg_frame_time > 0 else 0\n        else:\n            current_fps = 0\n\n        avg_processing_time = sum(self.processing_times) / len(self.processing_times) if self.processing_times else 0\n        avg_cpu_usage = sum(self.cpu_usage) / len(self.cpu_usage) if self.cpu_usage else 0\n        avg_memory_usage = sum(self.memory_usage) / len(self.memory_usage) if self.memory_usage else 0\n\n        return {\n            'fps': current_fps,\n            'avg_processing_time': avg_processing_time,\n            'cpu_usage': avg_cpu_usage,\n            'memory_usage': avg_memory_usage,\n            'optimization_params': self.optimization_params.copy()\n        }\n\n    def optimize_pipeline(self):\n        \"\"\"Optimize entire pipeline based on performance\"\"\"\n        current_perf = self.get_current_performance()\n\n        # Adjust pipeline parameters based on performance\n        if current_perf['fps'] < self.target_fps * 0.5:\n            # Significantly below target - aggressive optimization\n            self.get_logger().warn('Significant performance degradation detected - applying aggressive optimization')\n            self.optimization_params['feature_count'] = max(200, self.optimization_params['feature_count'] // 2)\n            self.optimization_params['image_decimation'] = min(10, self.optimization_params['image_decimation'] * 2)\n            self.optimization_params['pointcloud_decimation'] = min(16, self.optimization_params['pointcloud_decimation'] * 2)\n        elif current_perf['fps'] > self.target_fps * 1.2:\n            # Above target - can afford more processing\n            self.optimization_params['feature_count'] = min(2000, self.optimization_params['feature_count'] * 1.1)\n            self.optimization_params['image_decimation'] = max(1, self.optimization_params['image_decimation'] // 1.1)\n"})}),"\n",(0,s.jsx)(n.h2,{id:"troubleshooting-and-best-practices",children:"Troubleshooting and Best Practices"}),"\n",(0,s.jsx)(n.h3,{id:"common-issues-and-solutions",children:"Common Issues and Solutions"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# Isaac Sim troubleshooting guide\nclass IsaacSimTroubleshooter:\n    def __init__(self):\n        self.known_issues = {\n            'gpu_not_detected': {\n                'symptoms': ['CUDA errors', 'GPU not utilized'],\n                'causes': ['Driver issues', 'CUDA version mismatch', 'GPU not properly configured'],\n                'solutions': [\n                    'Update NVIDIA drivers',\n                    'Verify CUDA installation',\n                    'Check Isaac Sim GPU requirements',\n                    'Install proper Isaac ROS packages'\n                ]\n            },\n            'performance_degradation': {\n                'symptoms': ['Low FPS', 'High latency', 'Memory leaks'],\n                'causes': ['Insufficient hardware', 'Inefficient algorithms', 'Memory management issues'],\n                'solutions': [\n                    'Optimize processing parameters',\n                    'Implement adaptive processing',\n                    'Add performance monitoring',\n                    'Upgrade hardware if needed'\n                ]\n            },\n            'sensor_data_issues': {\n                'symptoms': ['No sensor data', 'Corrupted data', 'Wrong coordinate frames'],\n                'causes': ['Incorrect sensor configuration', 'TF issues', 'Message format problems'],\n                'solutions': [\n                    'Verify sensor configuration in Isaac Sim',\n                    'Check TF tree and transforms',\n                    'Validate message formats',\n                    'Test sensor separately'\n                ]\n            },\n            'robot_control_problems': {\n                'symptoms': ['Robot not responding', 'Unstable movement', 'Drifting'],\n                'causes': ['Control parameter issues', 'Physics configuration', 'Joint limits'],\n                'solutions': [\n                    'Verify control parameters',\n                    'Check physics configuration',\n                    'Validate joint limits and properties',\n                    'Test control separately'\n                ]\n            }\n        }\n\n    def diagnose_issue(self, error_message):\n        \"\"\"Diagnose issue based on error message\"\"\"\n        for issue_type, issue_data in self.known_issues.items():\n            for symptom in issue_data['symptoms']:\n                if symptom.lower() in error_message.lower():\n                    return {\n                        'issue_type': issue_type,\n                        'symptoms': issue_data['symptoms'],\n                        'causes': issue_data['causes'],\n                        'solutions': issue_data['solutions']\n                    }\n\n        return {'issue_type': 'unknown', 'solutions': ['Check general troubleshooting steps']}\n\n    def check_system_compatibility(self):\n        \"\"\"Check system compatibility with Isaac Sim requirements\"\"\"\n        import subprocess\n        import platform\n\n        checks = {\n            'os_compatible': self.check_os_compatibility(),\n            'gpu_available': self.check_gpu_availability(),\n            'cuda_installed': self.check_cuda_installation(),\n            'driver_version': self.check_driver_version(),\n            'memory_sufficient': self.check_memory(),\n            'disk_space': self.check_disk_space()\n        }\n\n        return checks\n\n    def check_os_compatibility(self):\n        \"\"\"Check if OS is compatible with Isaac Sim\"\"\"\n        os_name = platform.system().lower()\n        os_version = platform.release()\n\n        # Isaac Sim officially supports Ubuntu 20.04/22.04\n        if os_name == 'linux':\n            try:\n                with open('/etc/os-release', 'r') as f:\n                    os_info = f.read()\n                    if 'ubuntu' in os_info.lower() and ('20.04' in os_info or '22.04' in os_info):\n                        return True\n            except:\n                pass\n\n        return False\n\n    def check_gpu_availability(self):\n        \"\"\"Check if compatible GPU is available\"\"\"\n        try:\n            result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader,nounits'],\n                                  capture_output=True, text=True, timeout=10)\n            if result.returncode == 0 and 'RTX' in result.stdout:\n                return True\n        except:\n            pass\n\n        return False\n\n    def check_cuda_installation(self):\n        \"\"\"Check if CUDA is properly installed\"\"\"\n        try:\n            result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True, timeout=5)\n            return result.returncode == 0\n        except:\n            return False\n\n    def check_driver_version(self):\n        \"\"\"Check if driver version is compatible\"\"\"\n        try:\n            result = subprocess.run(['nvidia-smi', '--query-gpu=driver_version', '--format=csv,noheader,nounits'],\n                                  capture_output=True, text=True, timeout=5)\n            if result.returncode == 0:\n                version_str = result.stdout.strip()\n                version_parts = version_str.split('.')\n                if len(version_parts) >= 2:\n                    major_version = int(version_parts[0])\n                    # Isaac Sim requires relatively recent drivers\n                    return major_version >= 470\n        except:\n            pass\n\n        return False\n\n    def check_memory(self):\n        \"\"\"Check if system has sufficient memory\"\"\"\n        import psutil\n        memory_gb = psutil.virtual_memory().total / (1024**3)\n        return memory_gb >= 16  # Isaac Sim recommends 16GB+\n\n    def check_disk_space(self):\n        \"\"\"Check if sufficient disk space is available\"\"\"\n        import shutil\n        total, used, free = shutil.disk_usage(\"/\")\n        free_gb = free / (1024**3)\n        return free_gb >= 50  # Recommend at least 50GB free\n\n    def generate_system_report(self):\n        \"\"\"Generate comprehensive system compatibility report\"\"\"\n        checks = self.check_system_compatibility()\n\n        report = f\"\"\"\nIsaac Sim System Compatibility Report\n====================================\n\nSystem Checks:\n- OS Compatible: {'\u2713' if checks['os_compatible'] else '\u2717'}\n- GPU Available: {'\u2713' if checks['gpu_available'] else '\u2717'}\n- CUDA Installed: {'\u2713' if checks['cuda_installed'] else '\u2717'}\n- Driver Version: {'\u2713' if checks['driver_version'] else '\u2717'}\n- Memory Sufficient: {'\u2713' if checks['memory_sufficient'] else '\u2717'}\n- Disk Space: {'\u2713' if checks['disk_space'] else '\u2717'}\n\nRecommendations:\n\"\"\"\n        if not checks['os_compatible']:\n            report += \"- Upgrade to Ubuntu 20.04 or 22.04\\n\"\n        if not checks['gpu_available']:\n            report += \"- Install NVIDIA RTX GPU\\n\"\n        if not checks['cuda_installed']:\n            report += \"- Install CUDA toolkit\\n\"\n        if not checks['driver_version']:\n            report += \"- Update NVIDIA drivers\\n\"\n        if not checks['memory_sufficient']:\n            report += \"- Upgrade to 16GB+ RAM\\n\"\n        if not checks['disk_space']:\n            report += \"- Free up disk space (need 50GB+)\\n\"\n\n        return report\n"})}),"\n",(0,s.jsx)(n.h2,{id:"practical-lab-complete-isaac-sim-vslam-integration",children:"Practical Lab: Complete Isaac Sim VSLAM Integration"}),"\n",(0,s.jsx)(n.h3,{id:"lab-objective",children:"Lab Objective"}),"\n",(0,s.jsx)(n.p,{children:"Implement a complete VSLAM system integrated with Isaac Sim that includes camera simulation, feature tracking, pose estimation, and map building."}),"\n",(0,s.jsx)(n.h3,{id:"implementation-steps",children:"Implementation Steps"}),"\n",(0,s.jsx)(n.h4,{id:"step-1-set-up-isaac-sim-environment",children:"Step 1: Set up Isaac Sim Environment"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# Complete VSLAM integration example\nimport omni\nfrom omni.isaac.core import World\nfrom omni.isaac.core.robots import Robot\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\nfrom omni.isaac.sensor import Camera\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image\nfrom geometry_msgs.msg import PoseStamped\nfrom std_msgs.msg import String\n\nclass IsaacVSLAMIntegration(Node):\n    def __init__(self):\n        super().__init__(\'isaac_vslam_integration\')\n\n        # Initialize Isaac Sim world\n        self.world = World(stage_units_in_meters=1.0)\n\n        # ROS 2 publishers and subscribers\n        self.image_pub = self.create_publisher(Image, \'camera/image_raw\', 10)\n        self.pose_pub = self.create_publisher(PoseStamped, \'vslam/pose\', 10)\n        self.status_pub = self.create_publisher(String, \'vslam/status\', 10)\n        self.cmd_vel_sub = self.create_subscription(\n            Twist, \'cmd_vel\', self.cmd_vel_callback, 10)\n\n        # Isaac Sim components\n        self.camera = None\n        self.robot = None\n\n        # VSLAM state\n        self.vslam_system = None\n        self.isaac_connected = False\n        self.ros_connected = True\n\n        # Performance monitoring\n        self.frame_count = 0\n        self.last_published_time = self.get_clock().now()\n\n        self.get_logger().info(\'Isaac VSLAM Integration Node Started\')\n\n    def setup_isaac_environment(self):\n        """Set up Isaac Sim environment with robot and sensors"""\n        # Add ground plane\n        self.world.scene.add_default_ground_plane()\n\n        # Add robot\n        self.robot = self.world.scene.add(\n            Robot(\n                prim_path="/World/Robot",\n                name="isaac_robot",\n                usd_path="/Isaac/Robots/TurtleBot3Burger/turtlebot3_burger.usd",\n                position=[0, 0, 0.1],\n                orientation=[0, 0, 0, 1]\n            )\n        )\n\n        # Add camera to robot\n        self.camera = Camera(\n            prim_path="/World/Robot/chassis/camera",\n            frequency=30,\n            resolution=(640, 480)\n        )\n        self.world.scene.add(self.camera)\n\n        # Set up lighting\n        from omni.isaac.core.utils.prims import create_prim\n        create_prim(\n            prim_path="/World/Light",\n            prim_type="DistantLight",\n            position=[0, 0, 10],\n            attributes={"color": [0.8, 0.8, 0.8]}\n        )\n\n        # Initialize VSLAM system\n        camera_matrix = np.array([\n            [525.0, 0.0, 319.5],  # fx, 0, cx\n            [0.0, 525.0, 239.5],  # 0, fy, cy\n            [0.0, 0.0, 1.0]       # 0, 0, 1\n        ])\n        self.vslam_system = ORBSLAM(camera_matrix, np.zeros(5))\n\n        self.isaac_connected = True\n        self.get_logger().info(\'Isaac Sim environment set up successfully\')\n\n    def run_simulation(self, steps=1000):\n        """Run Isaac Sim with VSLAM integration"""\n        self.world.reset()\n\n        for step in range(steps):\n            self.world.step(render=True)\n\n            # Process Isaac Sim data and publish to ROS\n            if self.isaac_connected:\n                self.process_isaac_data()\n\n            # Check for ROS commands\n            rclpy.spin_once(self, timeout_sec=0)\n\n    def process_isaac_data(self):\n        """Process Isaac Sim sensor data and run VSLAM"""\n        try:\n            # Get camera image from Isaac Sim\n            camera_image = self.camera.get_rgba()\n\n            if camera_image is not None:\n                # Convert Isaac image to ROS Image message\n                ros_image = self.isaac_to_ros_image(camera_image)\n\n                # Run VSLAM on image\n                estimated_pose = self.vslam_system.process_frame(\n                    camera_image, self.world.current_time\n                )\n\n                # Publish image\n                self.image_pub.publish(ros_image)\n\n                # Publish estimated pose\n                self.publish_pose_estimate(estimated_pose)\n\n                # Performance monitoring\n                self.frame_count += 1\n                current_time = self.get_clock().now()\n                if (current_time - self.last_published_time).nanoseconds > 1e9:  # 1 second\n                    fps = self.frame_count / ((current_time - self.last_published_time).nanoseconds / 1e9)\n                    self.get_logger().info(f\'VSLAM: {self.frame_count} frames, FPS: {fps:.1f}\')\n                    self.frame_count = 0\n                    self.last_published_time = current_time\n\n        except Exception as e:\n            self.get_logger().error(f\'Error processing Isaac data: {e}\')\n\n    def isaac_to_ros_image(self, isaac_image):\n        """Convert Isaac Sim image to ROS Image message"""\n        import numpy as np\n        from cv_bridge import CvBridge\n\n        # Isaac image format may need conversion\n        # This is a simplified example - actual format depends on Isaac Sim version\n        image_data = np.array(isaac_image)\n\n        # Convert to ROS Image using CV Bridge\n        bridge = CvBridge()\n        ros_image = bridge.cv2_to_imgmsg(image_data, encoding=\'rgba8\')\n\n        # Set header\n        ros_image.header.stamp = self.get_clock().now().to_msg()\n        ros_image.header.frame_id = \'camera_rgb_optical_frame\'\n\n        return ros_image\n\n    def publish_pose_estimate(self, pose):\n        """Publish VSLAM pose estimate"""\n        pose_msg = PoseStamped()\n        pose_msg.header.stamp = self.get_clock().now().to_msg()\n        pose_msg.header.frame_id = \'vslam_map\'\n\n        # Convert 4x4 pose matrix to position and orientation\n        pose_msg.pose.position.x = float(pose[0, 3])\n        pose_msg.pose.position.y = float(pose[1, 3])\n        pose_msg.pose.position.z = float(pose[2, 3])\n\n        # Convert rotation matrix to quaternion\n        rotation_matrix = pose[:3, :3]\n        qw, qx, qy, qz = self.rotation_matrix_to_quaternion(rotation_matrix)\n        pose_msg.pose.orientation.w = qw\n        pose_msg.pose.orientation.x = qx\n        pose_msg.pose.orientation.y = qy\n        pose_msg.pose.orientation.z = qz\n\n        self.pose_pub.publish(pose_msg)\n\n    def rotation_matrix_to_quaternion(self, R):\n        """Convert rotation matrix to quaternion [w, x, y, z]"""\n        trace = np.trace(R)\n        if trace > 0:\n            s = np.sqrt(trace + 1.0) * 2  # s = 4 * qw\n            qw = 0.25 * s\n            qx = (R[2, 1] - R[1, 2]) / s\n            qy = (R[0, 2] - R[2, 0]) / s\n            qz = (R[1, 0] - R[0, 1]) / s\n        else:\n            if R[0, 0] > R[1, 1] and R[0, 0] > R[2, 2]:\n                s = np.sqrt(1.0 + R[0, 0] - R[1, 1] - R[2, 2]) * 2\n                qw = (R[2, 1] - R[1, 2]) / s\n                qx = 0.25 * s\n                qy = (R[0, 1] + R[1, 0]) / s\n                qz = (R[0, 2] + R[2, 0]) / s\n            elif R[1, 1] > R[2, 2]:\n                s = np.sqrt(1.0 + R[1, 1] - R[0, 0] - R[2, 2]) * 2\n                qw = (R[0, 2] - R[2, 0]) / s\n                qx = (R[0, 1] + R[1, 0]) / s\n                qy = 0.25 * s\n                qz = (R[1, 2] + R[2, 1]) / s\n            else:\n                s = np.sqrt(1.0 + R[2, 2] - R[0, 0] - R[1, 1]) * 2\n                qw = (R[1, 0] - R[0, 1]) / s\n                qx = (R[0, 2] + R[2, 0]) / s\n                qy = (R[1, 2] + R[2, 1]) / s\n                qz = 0.25 * s\n\n        return qw, qx, qy, qz\n\n    def cmd_vel_callback(self, msg):\n        """Handle velocity commands from ROS"""\n        if self.robot is not None:\n            # Apply velocity command to Isaac Sim robot\n            # This would involve controlling the robot in Isaac Sim\n            linear_x = msg.linear.x\n            angular_z = msg.angular.z\n\n            # In Isaac Sim, you would apply these velocities to the robot\n            # The exact method depends on the robot model and control interface\n            self.apply_robot_velocity(linear_x, angular_z)\n\n    def apply_robot_velocity(self, linear_x, angular_z):\n        """Apply velocity to Isaac Sim robot"""\n        # This is a placeholder - actual implementation depends on robot model\n        # You would typically use Isaac Sim\'s control interfaces\n        self.get_logger().debug(f\'Applying velocity: linear_x={linear_x}, angular_z={angular_z}\')\n\ndef main(args=None):\n    # Initialize ROS 2\n    rclpy.init(args=args)\n\n    # Initialize Isaac Sim (this would be done in Isaac Sim\'s application)\n    # For this example, we assume Isaac Sim is already running\n\n    # Create integration node\n    integration_node = IsaacVSLAMIntegration()\n\n    try:\n        # Set up Isaac environment\n        integration_node.setup_isaac_environment()\n\n        # Run simulation\n        integration_node.run_simulation(steps=1000)\n\n    except KeyboardInterrupt:\n        pass\n    finally:\n        integration_node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,s.jsx)(n.h3,{id:"lab-exercise-isaac-sim-vslam-implementation",children:"Lab Exercise: Isaac Sim VSLAM Implementation"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Set up Isaac Sim with a mobile robot model"}),"\n",(0,s.jsx)(n.li,{children:"Implement VSLAM system with feature tracking"}),"\n",(0,s.jsx)(n.li,{children:"Integrate with ROS 2 for visualization"}),"\n",(0,s.jsx)(n.li,{children:"Test system in various environments"}),"\n",(0,s.jsx)(n.li,{children:"Evaluate performance and accuracy"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"expected-results",children:"Expected Results"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Working VSLAM system integrated with Isaac Sim"}),"\n",(0,s.jsx)(n.li,{children:"Real-time pose estimation and mapping"}),"\n",(0,s.jsx)(n.li,{children:"Proper ROS 2 integration and communication"}),"\n",(0,s.jsx)(n.li,{children:"Performance within acceptable limits"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,s.jsx)(n.h3,{id:"isaac-sim-workflows-best-practices",children:"Isaac Sim Workflows Best Practices"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Environment Design"}),": Create realistic but optimized environments"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Physics Configuration"}),": Tune physics parameters for stability"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Sensor Simulation"}),": Configure sensors to match real-world characteristics"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Performance Monitoring"}),": Continuously monitor and optimize performance"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Validation"}),": Validate simulation results against real-world data"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"integration-best-practices",children:"Integration Best Practices"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Modular Design"}),": Keep components modular and reusable"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Error Handling"}),": Implement robust error handling"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Performance Monitoring"}),": Monitor and optimize performance continuously"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Documentation"}),": Maintain clear documentation for all components"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Testing"}),": Implement comprehensive testing for all systems"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"review-questions",children:"Review Questions"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Explain the process for setting up Isaac Sim with a custom robot model."}),"\n",(0,s.jsx)(n.li,{children:"How do you configure VSLAM systems for optimal performance in Isaac Sim?"}),"\n",(0,s.jsx)(n.li,{children:"What are the key considerations for ROS 2 integration with Isaac Sim?"}),"\n",(0,s.jsx)(n.li,{children:"How do you troubleshoot common Isaac Sim performance issues?"}),"\n",(0,s.jsx)(n.li,{children:"What are the best practices for creating realistic simulation environments?"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,s.jsx)(n.p,{children:"After mastering Isaac Sim workflows, students should proceed to:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Advanced VSLAM implementation for humanoid robots"}),"\n",(0,s.jsx)(n.li,{children:"Isaac ROS integration and advanced features"}),"\n",(0,s.jsx)(n.li,{children:"Navigation systems with Isaac Sim"}),"\n",(0,s.jsx)(n.li,{children:"Sim-to-real transfer techniques"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"This comprehensive guide to Isaac Sim workflows provides the practical foundation for creating sophisticated simulation environments essential for Physical AI and Humanoid Robotics development."})]})}function d(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>a});var o=i(6540);const s={},t=o.createContext(s);function r(e){const n=o.useContext(t);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),o.createElement(t.Provider,{value:n},e.children)}}}]);