"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_textbook=globalThis.webpackChunkphysical_ai_humanoid_robotics_textbook||[]).push([[787],{1092:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>c,frontMatter:()=>t,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"module-3/sim-to-real-principles","title":"Sim-to-Real Principles","description":"Overview","source":"@site/docs/module-3/sim-to-real-principles.md","sourceDirName":"module-3","slug":"/module-3/sim-to-real-principles","permalink":"/docs/module-3/sim-to-real-principles","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-3/sim-to-real-principles.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"VSLAM Systems","permalink":"/docs/module-3/vslam-systems"},"next":{"title":"Vision-Language-Action (VLA) Fundamentals","permalink":"/docs/module-4/vla-fundamentals"}}');var r=a(4848),s=a(8453);const t={sidebar_position:4},o="Sim-to-Real Principles",l={},d=[{value:"Overview",id:"overview",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Key Concepts",id:"key-concepts",level:2},{value:"The Reality Gap",id:"the-reality-gap",level:3},{value:"Domain Randomization",id:"domain-randomization",level:3},{value:"Domain Adaptation",id:"domain-adaptation",level:3},{value:"Theoretical Foundations",id:"theoretical-foundations",level:2},{value:"Simulation Fidelity Levels",id:"simulation-fidelity-levels",level:3},{value:"Transfer Learning Framework",id:"transfer-learning-framework",level:3},{value:"Domain Randomization Techniques",id:"domain-randomization-techniques",level:2},{value:"Environmental Domain Randomization",id:"environmental-domain-randomization",level:3},{value:"Sensor Domain Randomization",id:"sensor-domain-randomization",level:3},{value:"Reality Gap Reduction Strategies",id:"reality-gap-reduction-strategies",level:2},{value:"System Identification and Parameter Estimation",id:"system-identification-and-parameter-estimation",level:3},{value:"Adaptive Control for Sim-to-Real Transfer",id:"adaptive-control-for-sim-to-real-transfer",level:3},{value:"Evaluation and Validation",id:"evaluation-and-validation",level:2},{value:"Sim-to-Real Transfer Evaluation Framework",id:"sim-to-real-transfer-evaluation-framework",level:3},{value:"Best Practices and Guidelines",id:"best-practices-and-guidelines",level:2},{value:"Systematic Approach to Sim-to-Real Transfer",id:"systematic-approach-to-sim-to-real-transfer",level:3},{value:"1. Gradual Fidelity Increase",id:"1-gradual-fidelity-increase",level:4},{value:"2. Validation Strategies",id:"2-validation-strategies",level:4},{value:"3. Safety Considerations",id:"3-safety-considerations",level:4},{value:"Troubleshooting Common Issues",id:"troubleshooting-common-issues",level:2},{value:"Addressing Specific Transfer Problems",id:"addressing-specific-transfer-problems",level:3},{value:"1. Sensor Mismatch",id:"1-sensor-mismatch",level:4},{value:"2. Actuator Discrepancies",id:"2-actuator-discrepancies",level:4},{value:"Practical Lab: Sim-to-Real Transfer",id:"practical-lab-sim-to-real-transfer",level:2},{value:"Lab Objective",id:"lab-objective",level:3},{value:"Implementation Steps",id:"implementation-steps",level:3},{value:"Expected Outcome",id:"expected-outcome",level:3},{value:"Review Questions",id:"review-questions",level:2},{value:"Next Steps",id:"next-steps",level:2}];function m(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"sim-to-real-principles",children:"Sim-to-Real Principles"})}),"\n",(0,r.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,r.jsx)(n.p,{children:"Sim-to-real transfer is a critical challenge in robotics that involves transferring knowledge, skills, and behaviors learned in simulation to real-world robotic systems. This section covers the theoretical foundations, practical techniques, and implementation strategies for effective sim-to-real transfer in Physical AI and Humanoid Robotics applications."}),"\n",(0,r.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,r.jsx)(n.p,{children:"By the end of this section, students will be able to:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Understand the fundamental challenges of sim-to-real transfer"}),"\n",(0,r.jsx)(n.li,{children:"Apply domain randomization and domain adaptation techniques"}),"\n",(0,r.jsx)(n.li,{children:"Implement reality gap reduction strategies"}),"\n",(0,r.jsx)(n.li,{children:"Evaluate sim-to-real transfer effectiveness"}),"\n",(0,r.jsx)(n.li,{children:"Design robust systems that work in both simulation and reality"}),"\n",(0,r.jsx)(n.li,{children:"Address sensor, actuator, and environmental discrepancies"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"key-concepts",children:"Key Concepts"}),"\n",(0,r.jsx)(n.h3,{id:"the-reality-gap",children:"The Reality Gap"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Definition"}),": The discrepancy between simulated and real-world robot behavior"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Sources"}),": Modeling inaccuracies, sensor noise, actuator dynamics, environmental factors"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Impact"}),": Performance degradation when transferring from simulation to reality"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Mitigation"}),": Systematic approaches to reduce the gap"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"domain-randomization",children:"Domain Randomization"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Purpose"}),": Train models on diverse simulation conditions to improve robustness"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Approach"}),": Randomize environmental parameters during training"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Benefits"}),": Improved generalization to unseen real-world conditions"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Implementation"}),": Systematic variation of physics, lighting, textures, and dynamics"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"domain-adaptation",children:"Domain Adaptation"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Transfer Learning"}),": Adapting models trained in simulation to real data"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Fine-tuning"}),": Adjusting model parameters with limited real-world data"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Adversarial Training"}),": Using adversarial networks to learn domain-invariant features"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Self-supervised Learning"}),": Learning representations without labeled real data"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"theoretical-foundations",children:"Theoretical Foundations"}),"\n",(0,r.jsx)(n.h3,{id:"simulation-fidelity-levels",children:"Simulation Fidelity Levels"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Simulation fidelity classification system\nclass SimulationFidelity:\n    def __init__(self):\n        self.levels = {\n            'level_1': {\n                'name': 'Functional Fidelity',\n                'description': 'Basic functionality and behavior simulation',\n                'components': ['Kinematics', 'Basic Dynamics', 'Simple Sensors'],\n                'use_case': 'Algorithm development and testing'\n            },\n            'level_2': {\n                'name': 'Physical Fidelity',\n                'description': 'Accurate physical properties and interactions',\n                'components': ['Realistic Physics', 'Accurate Mass Properties', 'Detailed Collision Models'],\n                'use_case': 'Control system validation'\n            },\n            'level_3': {\n                'name': 'Sensory Fidelity',\n                'description': 'Realistic sensor simulation and noise models',\n                'components': ['Realistic Sensor Noise', 'Latency Simulation', 'Resolution Matching'],\n                'use_case': 'Perception system validation'\n            },\n            'level_4': {\n                'name': 'Temporal Fidelity',\n                'description': 'Accurate timing and synchronization',\n                'components': ['Real-time Performance', 'Synchronization', 'Latency Modeling'],\n                'use_case': 'Real-time system validation'\n            },\n            'level_5': {\n                'name': 'Environmental Fidelity',\n                'description': 'Accurate environmental modeling and dynamics',\n                'components': ['Realistic Environments', 'Dynamic Elements', 'Weather Effects'],\n                'use_case': 'Full system validation'\n            }\n        }\n\n    def get_fidelity_requirements(self, application):\n        \"\"\"Get simulation fidelity requirements for specific applications\"\"\"\n        requirements = {\n            'navigation': ['level_1', 'level_2', 'level_3'],\n            'manipulation': ['level_1', 'level_2', 'level_3', 'level_4'],\n            'perception': ['level_1', 'level_3', 'level_5'],\n            'control': ['level_1', 'level_2', 'level_4']\n        }\n\n        return requirements.get(application, ['level_1'])\n"})}),"\n",(0,r.jsx)(n.h3,{id:"transfer-learning-framework",children:"Transfer Learning Framework"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Transfer learning framework for sim-to-real\nimport torch\nimport torch.nn as nn\nimport numpy as np\n\nclass SimToRealTransferFramework:\n    def __init__(self, source_domain_model, target_domain_data_loader=None):\n        self.source_model = source_domain_model\n        self.target_data_loader = target_domain_data_loader\n\n        # Domain adaptation components\n        self.domain_discriminator = self.build_domain_discriminator()\n        self.feature_extractor = self.extract_features(source_domain_model)\n\n        # Transfer parameters\n        self.transfer_loss_weight = 0.1\n        self.adversarial_loss_weight = 0.5\n\n    def build_domain_discriminator(self):\n        """Build domain discriminator for adversarial training"""\n        return nn.Sequential(\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(128, 2),  # Binary classifier: sim vs real\n            nn.Softmax(dim=1)\n        )\n\n    def extract_features(self, model):\n        """Extract feature extractor from source model"""\n        # This assumes the model has a feature extractor as first part\n        # Implementation depends on specific model architecture\n        return nn.Sequential(*list(model.children())[:-2])  # Remove classifier layers\n\n    def train_adversarial_transfer(self, epochs=100):\n        """Train with adversarial domain adaptation"""\n        optimizer = torch.optim.Adam(\n            list(self.feature_extractor.parameters()) +\n            list(self.domain_discriminator.parameters()),\n            lr=0.001\n        )\n\n        criterion = nn.CrossEntropyLoss()\n        domain_criterion = nn.CrossEntropyLoss()\n\n        for epoch in range(epochs):\n            total_loss = 0\n\n            for sim_batch, real_batch in zip(self.source_data_loader, self.target_data_loader):\n                optimizer.zero_grad()\n\n                # Process simulated data\n                sim_features = self.feature_extractor(sim_batch[\'images\'])\n                sim_predictions = self.source_model.classifier(sim_features)\n                sim_labels = sim_batch[\'labels\']\n\n                # Process real data\n                real_features = self.feature_extractor(real_batch[\'images\'])\n                real_predictions = self.source_model.classifier(real_features)\n                real_labels = real_batch[\'labels\']\n\n                # Task loss (supervised on real data)\n                task_loss = criterion(real_predictions, real_labels)\n\n                # Domain discrimination loss\n                sim_domain_preds = self.domain_discriminator(sim_features.detach())\n                real_domain_preds = self.domain_discriminator(real_features.detach())\n\n                # Labels: 0 for sim, 1 for real\n                sim_domain_labels = torch.zeros(sim_domain_preds.size(0)).long()\n                real_domain_labels = torch.ones(real_domain_preds.size(0)).long()\n\n                domain_loss = (\n                    domain_criterion(sim_domain_preds, sim_domain_labels) +\n                    domain_criterion(real_domain_preds, real_domain_labels)\n                )\n\n                # Adversarial loss (try to fool discriminator)\n                adv_sim_preds = self.domain_discriminator(sim_features)\n                adv_real_preds = self.domain_discriminator(real_features)\n\n                # Try to predict both as same domain (domain confusion)\n                adv_loss = (\n                    domain_criterion(adv_sim_preds, real_domain_labels) +  # Sim as real\n                    domain_criterion(adv_real_preds, sim_domain_labels)    # Real as sim\n                )\n\n                # Total loss\n                total_batch_loss = (\n                    task_loss +\n                    self.transfer_loss_weight * domain_loss -\n                    self.adversarial_loss_weight * adv_loss\n                )\n\n                total_batch_loss.backward()\n                optimizer.step()\n\n                total_loss += total_batch_loss.item()\n\n            print(f"Epoch {epoch}, Loss: {total_loss/len(self.target_data_loader)}")\n\n    def fine_tune_on_real_data(self, real_data_loader, epochs=10):\n        """Fine-tune the transferred model on real data"""\n        # Freeze feature extractor layers\n        for param in self.feature_extractor.parameters():\n            param.requires_grad = False\n\n        # Only train the classifier\n        classifier_optimizer = torch.optim.Adam(\n            self.source_model.classifier.parameters(),\n            lr=0.0001  # Lower learning rate for fine-tuning\n        )\n\n        criterion = nn.CrossEntropyLoss()\n\n        for epoch in range(epochs):\n            epoch_loss = 0\n            for batch in real_data_loader:\n                classifier_optimizer.zero_grad()\n\n                features = self.feature_extractor(batch[\'images\'])\n                predictions = self.source_model.classifier(features)\n\n                loss = criterion(predictions, batch[\'labels\'])\n                loss.backward()\n\n                classifier_optimizer.step()\n                epoch_loss += loss.item()\n\n            print(f"Fine-tuning Epoch {epoch}, Loss: {epoch_loss/len(real_data_loader)}")\n'})}),"\n",(0,r.jsx)(n.h2,{id:"domain-randomization-techniques",children:"Domain Randomization Techniques"}),"\n",(0,r.jsx)(n.h3,{id:"environmental-domain-randomization",children:"Environmental Domain Randomization"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Domain randomization for environment simulation\nimport numpy as np\nimport random\nimport cv2\n\nclass EnvironmentRandomizer:\n    def __init__(self):\n        self.randomization_params = {\n            'lighting': {\n                'intensity_range': (0.5, 2.0),\n                'color_temperature_range': (3000, 8000),\n                'shadow_softness_range': (0.1, 0.9)\n            },\n            'materials': {\n                'roughness_range': (0.0, 1.0),\n                'metallic_range': (0.0, 1.0),\n                'specular_range': (0.0, 1.0)\n            },\n            'textures': {\n                'scale_range': (0.5, 2.0),\n                'rotation_range': (0, 360),\n                'distortion_range': (0, 0.1)\n            },\n            'dynamics': {\n                'friction_range': (0.1, 1.0),\n                'restitution_range': (0.0, 0.5),\n                'damping_range': (0.0, 0.1)\n            }\n        }\n\n    def randomize_lighting(self, scene):\n        \"\"\"Randomize lighting conditions in the scene\"\"\"\n        # Randomize light intensity\n        intensity_factor = random.uniform(*self.randomization_params['lighting']['intensity_range'])\n        scene.light_intensity *= intensity_factor\n\n        # Randomize color temperature\n        color_temp = random.uniform(*self.randomization_params['lighting']['color_temperature_range'])\n        scene.light_color = self.color_temperature_to_rgb(color_temp)\n\n        # Randomize shadow properties\n        shadow_softness = random.uniform(*self.randomization_params['lighting']['shadow_softness_range'])\n        scene.shadow_softness = shadow_softness\n\n        return scene\n\n    def randomize_materials(self, materials):\n        \"\"\"Randomize material properties\"\"\"\n        randomized_materials = []\n\n        for material in materials:\n            new_material = material.copy()\n\n            # Randomize roughness\n            roughness = random.uniform(*self.randomization_params['materials']['roughness_range'])\n            new_material['roughness'] = roughness\n\n            # Randomize metallic\n            metallic = random.uniform(*self.randomization_params['materials']['metallic_range'])\n            new_material['metallic'] = metallic\n\n            # Randomize specular\n            specular = random.uniform(*self.randomization_params['materials']['specular_range'])\n            new_material['specular'] = specular\n\n            randomized_materials.append(new_material)\n\n        return randomized_materials\n\n    def randomize_textures(self, texture_params):\n        \"\"\"Randomize texture properties\"\"\"\n        randomized_params = texture_params.copy()\n\n        # Randomize texture scale\n        scale_factor = random.uniform(*self.randomization_params['textures']['scale_range'])\n        randomized_params['scale'] *= scale_factor\n\n        # Randomize rotation\n        rotation = random.uniform(*self.randomization_params['textures']['rotation_range'])\n        randomized_params['rotation'] = rotation\n\n        # Randomize distortion\n        distortion = random.uniform(*self.randomization_params['textures']['distortion_range'])\n        randomized_params['distortion'] = distortion\n\n        return randomized_params\n\n    def randomize_dynamics(self, dynamics_params):\n        \"\"\"Randomize dynamic properties\"\"\"\n        randomized_params = dynamics_params.copy()\n\n        # Randomize friction\n        friction = random.uniform(*self.randomization_params['dynamics']['friction_range'])\n        randomized_params['friction'] = friction\n\n        # Randomize restitution (bounciness)\n        restitution = random.uniform(*self.randomization_params['dynamics']['restitution_range'])\n        randomized_params['restitution'] = restitution\n\n        # Randomize damping\n        damping = random.uniform(*self.randomization_params['dynamics']['damping_range'])\n        randomized_params['damping'] = damping\n\n        return randomized_params\n\n    def color_temperature_to_rgb(self, temp_kelvin):\n        \"\"\"Convert color temperature to RGB values\"\"\"\n        temp = temp_kelvin / 100\n\n        if temp <= 66:\n            red = 255\n            green = temp\n            green = 99.4708025861 * np.log(green) - 161.1195681661\n        else:\n            red = temp - 60\n            red = 329.698727446 * (red ** -0.1332047592)\n            green = temp - 60\n            green = 288.1221695283 * (green ** -0.0755148492)\n\n        blue = 255 if temp >= 66 else temp - 10\n        blue = 138.5177312231 * np.log(blue) - 305.0447927307 if temp < 19 else 0\n\n        return np.array([max(0, min(255, x))/255.0 for x in [red, green, blue]])\n"})}),"\n",(0,r.jsx)(n.h3,{id:"sensor-domain-randomization",children:"Sensor Domain Randomization"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Sensor domain randomization for realistic simulation\nimport numpy as np\nimport cv2\nfrom scipy.ndimage import gaussian_filter\n\nclass SensorRandomizer:\n    def __init__(self):\n        self.noise_params = {\n            'camera': {\n                'gaussian_noise_std': (0.001, 0.01),\n                'poisson_noise_lambda': (0.01, 0.1),\n                'salt_pepper_ratio': (0.001, 0.01),\n                'blur_kernel_size': (1, 3),\n                'color_jitter_brightness': (0.8, 1.2),\n                'color_jitter_contrast': (0.8, 1.2),\n                'color_jitter_saturation': (0.8, 1.2)\n            },\n            'lidar': {\n                'range_noise_std': (0.001, 0.02),\n                'angular_noise_std': (0.001, 0.01),\n                'dropout_probability': (0.001, 0.05),\n                'intensity_noise_std': (0.01, 0.1)\n            },\n            'imu': {\n                'acceleration_bias': (-0.1, 0.1),\n                'gyro_bias': (-0.01, 0.01),\n                'acceleration_noise': (0.001, 0.01),\n                'gyro_noise': (0.0001, 0.001)\n            }\n        }\n\n    def add_camera_noise(self, image):\n        \"\"\"Add realistic camera noise to image\"\"\"\n        # Convert to float for processing\n        img_float = image.astype(np.float32) / 255.0\n\n        # Gaussian noise\n        gaussian_std = np.random.uniform(*self.noise_params['camera']['gaussian_noise_std'])\n        gaussian_noise = np.random.normal(0, gaussian_std, img_float.shape)\n        img_noisy = img_float + gaussian_noise\n\n        # Poisson noise (shot noise)\n        poisson_lambda = np.random.uniform(*self.noise_params['camera']['poisson_noise_lambda'])\n        poisson_noise = np.random.poisson(img_noisy * 255 * poisson_lambda) / (255 * poisson_lambda)\n        img_noisy = img_noisy + poisson_noise\n\n        # Salt and pepper noise\n        salt_pepper_prob = np.random.uniform(*self.noise_params['camera']['salt_pepper_ratio'])\n        salt_pepper_mask = np.random.random(img_noisy.shape[:2]) < salt_pepper_prob\n        img_noisy[salt_pepper_mask] = 1.0  # Salt\n        pepper_mask = np.random.random(img_noisy.shape[:2]) < salt_pepper_prob\n        img_noisy[pepper_mask] = 0.0  # Pepper\n\n        # Gaussian blur\n        blur_size = np.random.uniform(*self.noise_params['camera']['blur_kernel_size'])\n        img_blurred = gaussian_filter(img_noisy, sigma=blur_size)\n\n        # Color jittering\n        brightness_factor = np.random.uniform(*self.noise_params['camera']['color_jitter_brightness'])\n        contrast_factor = np.random.uniform(*self.noise_params['camera']['color_jitter_contrast'])\n        saturation_factor = np.random.uniform(*self.noise_params['camera']['color_jitter_saturation'])\n\n        # Apply brightness\n        img_blurred = img_blurred * brightness_factor\n\n        # Apply contrast\n        img_blurred = (img_blurred - 0.5) * contrast_factor + 0.5\n\n        # Apply saturation (convert to HSV temporarily)\n        if img_blurred.shape[2] == 3:  # RGB image\n            hsv = cv2.cvtColor((img_blurred * 255).astype(np.uint8), cv2.COLOR_RGB2HSV)\n            hsv[:, :, 1] = np.clip(hsv[:, :, 1] * saturation_factor, 0, 255)\n            img_blurred = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB).astype(np.float32) / 255.0\n\n        # Clip and convert back to uint8\n        img_result = np.clip(img_blurred * 255, 0, 255).astype(np.uint8)\n\n        return img_result\n\n    def add_lidar_noise(self, ranges, angles):\n        \"\"\"Add realistic LiDAR noise to scan data\"\"\"\n        noisy_ranges = ranges.copy().astype(np.float32)\n\n        # Range measurement noise\n        range_noise_std = np.random.uniform(*self.noise_params['lidar']['range_noise_std'])\n        range_noise = np.random.normal(0, range_noise_std, noisy_ranges.shape)\n        noisy_ranges = noisy_ranges + range_noise\n\n        # Angular measurement noise\n        angular_noise_std = np.random.uniform(*self.noise_params['lidar']['angular_noise_std'])\n        angular_noise = np.random.normal(0, angular_noise_std, angles.shape)\n        noisy_angles = angles + angular_noise\n\n        # Dropout (missing measurements)\n        dropout_prob = np.random.uniform(*self.noise_params['lidar']['dropout_probability'])\n        dropout_mask = np.random.random(noisy_ranges.shape) < dropout_prob\n        noisy_ranges[dropout_mask] = np.inf  # Invalid measurements\n\n        # Intensity noise (if available)\n        if hasattr(self, 'intensities') and self.intensities is not None:\n            intensity_noise_std = np.random.uniform(*self.noise_params['lidar']['intensity_noise_std'])\n            intensity_noise = np.random.normal(0, intensity_noise_std, self.intensities.shape)\n            noisy_intensities = self.intensities + intensity_noise\n            noisy_intensities = np.clip(noisy_intensities, 0, 1)\n        else:\n            noisy_intensities = None\n\n        return noisy_ranges, noisy_angles, noisy_intensities\n\n    def add_imu_noise(self, accel_data, gyro_data):\n        \"\"\"Add realistic IMU noise to sensor data\"\"\"\n        # Accelerometer noise\n        accel_bias = np.random.uniform(*self.noise_params['imu']['acceleration_bias'], size=3)\n        accel_noise = np.random.normal(\n            0,\n            np.random.uniform(*self.noise_params['imu']['acceleration_noise']),\n            accel_data.shape\n        )\n        noisy_accel = accel_data + accel_bias + accel_noise\n\n        # Gyroscope noise\n        gyro_bias = np.random.uniform(*self.noise_params['imu']['gyro_bias'], size=3)\n        gyro_noise = np.random.normal(\n            0,\n            np.random.uniform(*self.noise_params['imu']['gyro_noise']),\n            gyro_data.shape\n        )\n        noisy_gyro = gyro_data + gyro_bias + gyro_noise\n\n        return noisy_accel, noisy_gyro\n"})}),"\n",(0,r.jsx)(n.h2,{id:"reality-gap-reduction-strategies",children:"Reality Gap Reduction Strategies"}),"\n",(0,r.jsx)(n.h3,{id:"system-identification-and-parameter-estimation",children:"System Identification and Parameter Estimation"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# System identification for reality gap reduction\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.integrate import solve_ivp\n\nclass SystemIdentifier:\n    def __init__(self):\n        self.simulation_parameters = {}\n        self.real_parameters = {}\n        self.correction_factors = {}\n\n    def identify_robot_dynamics(self, real_data, sim_data):\n        """Identify real robot dynamics parameters from experimental data"""\n        # Real robot experimental data: [time, position, velocity, torque]\n        t_real = real_data[\'time\']\n        q_real = real_data[\'position\']\n        dq_real = real_data[\'velocity\']\n        tau_real = real_data[\'torque\']\n\n        # Simulation data for comparison\n        t_sim = sim_data[\'time\']\n        q_sim = sim_data[\'position\']\n        dq_sim = sim_data[\'velocity\']\n        tau_sim = sim_data[\'torque\']\n\n        # Define objective function to minimize dynamics mismatch\n        def dynamics_error(params):\n            # Update simulation parameters\n            self.update_simulation_parameters(params)\n\n            # Simulate with updated parameters\n            sim_result = self.simulate_robot_dynamics(tau_real, params)\n\n            # Calculate error between real and simulated behavior\n            pos_error = np.mean((sim_result[\'position\'] - q_real)**2)\n            vel_error = np.mean((sim_result[\'velocity\'] - dq_real)**2)\n\n            return pos_error + vel_error\n\n        # Initial parameter guess\n        initial_params = self.get_initial_parameter_guess()\n\n        # Optimize parameters\n        result = minimize(\n            dynamics_error,\n            initial_params,\n            method=\'L-BFGS-B\',\n            options={\'maxiter\': 1000}\n        )\n\n        # Store identified parameters\n        self.real_parameters = self.convert_to_physical_parameters(result.x)\n\n        return result.x\n\n    def update_simulation_parameters(self, params):\n        """Update simulation with identified parameters"""\n        # This would update the physics simulation with new parameters\n        # such as mass, inertia, friction coefficients, etc.\n        pass\n\n    def simulate_robot_dynamics(self, torques, params):\n        """Simulate robot dynamics with given parameters"""\n        # Robot dynamics: M(q)q_ddot + C(q,q_dot)q_dot + G(q) = \u03c4\n        def dynamics_ode(t, state):\n            q = state[:len(state)//2]  # Position\n            dq = state[len(state)//2:]  # Velocity\n\n            # Calculate dynamics matrices with current parameters\n            M = self.mass_matrix(q, params)\n            C = self.coriolis_matrix(q, dq, params)\n            G = self.gravity_vector(q, params)\n\n            # Calculate acceleration: q_ddot = M^(-1)(\u03c4 - C*q_dot - G)\n            tau_applied = self.interpolate_torques(t, torques)\n            q_ddot = np.linalg.solve(M, tau_applied - C @ dq - G)\n\n            return np.concatenate([dq, q_ddot])\n\n        # Initial state\n        initial_state = np.concatenate([self.q0, self.dq0])\n\n        # Solve ODE\n        solution = solve_ivp(\n            dynamics_ode,\n            [0, torques.shape[0] * self.dt],\n            initial_state,\n            method=\'RK45\',\n            t_eval=np.linspace(0, torques.shape[0] * self.dt, torques.shape[0])\n        )\n\n        # Extract results\n        positions = solution.y[:len(initial_state)//2, :].T\n        velocities = solution.y[len(initial_state)//2:, :].T\n\n        return {\'position\': positions, \'velocity\': velocities}\n\n    def mass_matrix(self, q, params):\n        """Calculate mass matrix M(q)"""\n        # Implementation depends on robot structure\n        # This is a simplified example\n        n = len(q)  # Number of joints\n        M = np.zeros((n, n))\n\n        # Fill in mass matrix based on parameters\n        for i in range(n):\n            M[i, i] = params[f\'link_{i}_mass\']  # Simplified diagonal approximation\n\n        return M\n\n    def coriolis_matrix(self, q, dq, params):\n        """Calculate Coriolis matrix C(q, q_dot)"""\n        # Simplified implementation\n        n = len(q)\n        C = np.zeros((n, n))\n\n        # Add Coriolis and centrifugal terms\n        for i in range(n):\n            for j in range(n):\n                C[i, j] = params.get(f\'coriolis_{i}_{j}\', 0) * dq[j]\n\n        return C\n\n    def gravity_vector(self, q, params):\n        """Calculate gravity vector G(q)"""\n        n = len(q)\n        G = np.zeros(n)\n\n        for i in range(n):\n            G[i] = params[f\'link_{i}_mass\'] * params[\'gravity\'] * np.sin(q[i])\n\n        return G\n\n    def interpolate_torques(self, t, torques):\n        """Interpolate torques at time t"""\n        # Simplified interpolation\n        idx = int(t / self.dt)\n        if idx >= len(torques):\n            return torques[-1]\n        return torques[idx]\n\n    def get_initial_parameter_guess(self):\n        """Get initial guess for parameters"""\n        # Start with simulation parameters as initial guess\n        initial_guess = []\n\n        # Add mass parameters\n        for i in range(self.num_joints):\n            initial_guess.append(self.simulation_parameters.get(f\'link_{i}_mass\', 1.0))\n\n        # Add other parameters\n        initial_guess.append(self.simulation_parameters.get(\'gravity\', 9.81))\n\n        return np.array(initial_guess)\n\n    def convert_to_physical_parameters(self, optimized_params):\n        """Convert optimization parameters to physical meanings"""\n        physical_params = {}\n        param_idx = 0\n\n        # Convert mass parameters\n        for i in range(self.num_joints):\n            physical_params[f\'link_{i}_mass\'] = optimized_params[param_idx]\n            param_idx += 1\n\n        # Convert gravity\n        physical_params[\'gravity\'] = optimized_params[param_idx]\n\n        return physical_params\n'})}),"\n",(0,r.jsx)(n.h3,{id:"adaptive-control-for-sim-to-real-transfer",children:"Adaptive Control for Sim-to-Real Transfer"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Adaptive control strategies for sim-to-real transfer\nimport numpy as np\nfrom scipy.linalg import solve_continuous_are\n\nclass AdaptiveController:\n    def __init__(self, nominal_model, learning_rate=0.01):\n        self.nominal_model = nominal_model\n        self.learning_rate = learning_rate\n\n        # Adaptive parameter estimates\n        self.theta_hat = np.zeros(self.nominal_model[\'params\'].size)\n        self.P = np.eye(self.theta_hat.size) * 100  # Covariance matrix\n\n        # Controller parameters\n        self.Kp = np.eye(3) * 10  # Proportional gain\n        self.Kd = np.eye(3) * 2   # Derivative gain\n\n    def adaptive_control(self, state, reference, dt):\n        """Adaptive control law with parameter estimation"""\n        # State error\n        position_error = reference[:3] - state[:3]\n        velocity_error = reference[3:6] - state[3:6]\n\n        # Desired acceleration (PD control)\n        desired_accel = self.Kp @ position_error + self.Kd @ velocity_error\n\n        # Regressor matrix (depends on robot dynamics)\n        phi = self.compute_regressor(state, desired_accel)\n\n        # Adaptive control term\n        adaptive_term = phi @ self.theta_hat\n\n        # Total control input\n        control_input = desired_accel + adaptive_term\n\n        # Update parameter estimates\n        self.update_parameters(state, reference, phi, control_input, dt)\n\n        return control_input\n\n    def compute_regressor(self, state, desired_accel):\n        """Compute regressor matrix for adaptive control"""\n        # This computes \u03c6 such that \u03c4 = \u03c6 @ \u03b8\n        # where \u03c4 is the control torque and \u03b8 are the unknown parameters\n        q = state[:3]      # Position\n        dq = state[3:6]    # Velocity\n        ddq_d = desired_accel  # Desired acceleration\n\n        # Simplified regressor (in practice, this would be more complex)\n        phi = np.zeros((3, len(self.theta_hat)))  # 3 DOF, adjustable parameters\n\n        # Fill regressor based on dynamics structure\n        # This is a simplified example - real implementation would be robot-specific\n        phi[0, 0] = q[0]**2  # Example: quadratic term\n        phi[1, 1] = dq[1]**2  # Example: velocity squared term\n        phi[2, 2] = np.sin(q[2])  # Example: trigonometric term\n\n        return phi\n\n    def update_parameters(self, state, reference, phi, control_input, dt):\n        """Update parameter estimates using least squares"""\n        # Prediction error\n        predicted_control = phi @ self.theta_hat\n        error = control_input - predicted_control\n\n        # Covariance update\n        denominator = 1 + phi.T @ self.P @ phi\n        K = (self.P @ phi) / denominator\n\n        # Parameter update\n        self.theta_hat += K * error\n\n        # Covariance matrix update\n        self.P = self.P - (K @ phi.T @ self.P)\n\n        # Add forgetting factor for time-varying parameters\n        self.P = self.P / (1 - 0.001)  # Forgetting factor\n\n    def robust_control_augmentation(self, state, nominal_control):\n        """Add robust control to handle unmodeled dynamics"""\n        # Sliding surface\n        s = state[3:6] + self.Kp @ state[:3]  # s = e_dot + Kp*e\n\n        # Robust control term\n        robust_gain = 5.0\n        robust_term = -robust_gain * np.tanh(s / 0.1)  # Smooth sign function\n\n        return nominal_control + robust_term\n'})}),"\n",(0,r.jsx)(n.h2,{id:"evaluation-and-validation",children:"Evaluation and Validation"}),"\n",(0,r.jsx)(n.h3,{id:"sim-to-real-transfer-evaluation-framework",children:"Sim-to-Real Transfer Evaluation Framework"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Evaluation framework for sim-to-real transfer\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\n\nclass TransferEvaluator:\n    def __init__(self):\n        self.simulation_results = {}\n        self.real_world_results = {}\n        self.transfer_metrics = {}\n\n    def evaluate_policy_transfer(self, sim_policy, real_robot, test_scenarios):\n        \"\"\"Evaluate how well a policy transfers from simulation to reality\"\"\"\n        sim_scores = []\n        real_scores = []\n        transfer_gaps = []\n\n        for scenario in test_scenarios:\n            # Test policy in simulation\n            sim_score = self.evaluate_policy_in_simulation(sim_policy, scenario)\n            sim_scores.append(sim_score)\n\n            # Test same policy in reality\n            real_score = self.evaluate_policy_in_real_world(sim_policy, scenario)\n            real_scores.append(real_score)\n\n            # Calculate transfer gap\n            transfer_gap = (sim_score - real_score) / sim_score if sim_score != 0 else 0\n            transfer_gaps.append(transfer_gap)\n\n        self.transfer_metrics['policy_transfer'] = {\n            'sim_scores': sim_scores,\n            'real_scores': real_scores,\n            'transfer_gaps': transfer_gaps,\n            'average_gap': np.mean(transfer_gaps),\n            'gap_std': np.std(transfer_gaps)\n        }\n\n        return self.transfer_metrics['policy_transfer']\n\n    def evaluate_perception_transfer(self, sim_model, real_sensor_data):\n        \"\"\"Evaluate perception model transfer from sim to real\"\"\"\n        # Test perception model on real data\n        predictions = []\n        ground_truths = []\n\n        for sample in real_sensor_data:\n            pred = sim_model.predict(sample['sensor_data'])\n            predictions.append(pred)\n            ground_truths.append(sample['ground_truth'])\n\n        # Calculate metrics\n        mse = mean_squared_error(ground_truths, predictions)\n        mae = mean_absolute_error(ground_truths, predictions)\n\n        # Calculate success rate (percentage of predictions within threshold)\n        threshold = 0.1  # Example threshold\n        success_count = sum(abs(p - g) < threshold for p, g in zip(predictions, ground_truths))\n        success_rate = success_count / len(predictions)\n\n        self.transfer_metrics['perception_transfer'] = {\n            'mse': mse,\n            'mae': mae,\n            'success_rate': success_rate,\n            'predictions': predictions,\n            'ground_truths': ground_truths\n        }\n\n        return self.transfer_metrics['perception_transfer']\n\n    def evaluate_control_transfer(self, sim_controller, real_robot, trajectory):\n        \"\"\"Evaluate control policy transfer\"\"\"\n        # Execute trajectory with simulation controller in reality\n        execution_errors = []\n        tracking_errors = []\n\n        for waypoint in trajectory:\n            # Get control command from sim controller\n            sim_command = sim_controller.get_control_command(waypoint)\n\n            # Execute in real robot\n            real_response = real_robot.execute_command(sim_command)\n\n            # Calculate tracking error\n            tracking_error = np.linalg.norm(waypoint[:3] - real_response['position'])\n            tracking_errors.append(tracking_error)\n\n            # Calculate execution error (deviation from expected)\n            expected_response = sim_controller.get_expected_response(sim_command)\n            execution_error = np.linalg.norm(\n                real_response['position'] - expected_response['position']\n            )\n            execution_errors.append(execution_error)\n\n        self.transfer_metrics['control_transfer'] = {\n            'tracking_errors': tracking_errors,\n            'execution_errors': execution_errors,\n            'avg_tracking_error': np.mean(tracking_errors),\n            'avg_execution_error': np.mean(execution_errors),\n            'tracking_success_rate': np.mean(np.array(tracking_errors) < 0.05)  # Within 5cm\n        }\n\n        return self.transfer_metrics['control_transfer']\n\n    def calculate_generalization_metrics(self, multiple_scenarios_results):\n        \"\"\"Calculate generalization metrics across multiple scenarios\"\"\"\n        # Robustness: consistency across scenarios\n        gaps_across_scenarios = [\n            scenario['transfer_gap'] for scenario in multiple_scenarios_results\n        ]\n\n        robustness = 1.0 / (1.0 + np.std(gaps_across_scenarios))  # Higher is better\n\n        # Adaptability: ability to recover from transfer gaps\n        adaptability = self.calculate_adaptability_score(multiple_scenarios_results)\n\n        # Scalability: performance across different complexity levels\n        scalability = self.calculate_scalability_score(multiple_scenarios_results)\n\n        self.transfer_metrics['generalization'] = {\n            'robustness': robustness,\n            'adaptability': adaptability,\n            'scalability': scalability,\n            'consistency': 1.0 - np.std(gaps_across_scenarios)  # Lower std = more consistent\n        }\n\n        return self.transfer_metrics['generalization']\n\n    def calculate_adaptability_score(self, results):\n        \"\"\"Calculate adaptability based on improvement over time\"\"\"\n        # This would measure how well the system adapts during deployment\n        # Implementation depends on specific adaptation mechanisms used\n        return 0.8  # Placeholder\n\n    def calculate_scalability_score(self, results):\n        \"\"\"Calculate scalability across different complexity levels\"\"\"\n        # Measure performance across easy, medium, hard scenarios\n        easy_results = [r for r in results if r['complexity'] == 'easy']\n        hard_results = [r for r in results if r['complexity'] == 'hard']\n\n        if easy_results and hard_results:\n            easy_performance = np.mean([r['performance'] for r in easy_results])\n            hard_performance = np.mean([r['performance'] for r in hard_results])\n\n            # Scalability: how well performance degrades with complexity\n            scalability = hard_performance / easy_performance if easy_performance != 0 else 0\n        else:\n            scalability = 0.5  # Default if no complexity variation\n\n        return scalability\n\n    def generate_transfer_report(self):\n        \"\"\"Generate comprehensive transfer evaluation report\"\"\"\n        report = {\n            'summary': {\n                'policy_transfer_gap': self.transfer_metrics.get('policy_transfer', {}).get('average_gap', 'N/A'),\n                'perception_accuracy': self.transfer_metrics.get('perception_transfer', {}).get('success_rate', 'N/A'),\n                'control_precision': self.transfer_metrics.get('control_transfer', {}).get('avg_tracking_error', 'N/A'),\n                'overall_robustness': self.transfer_metrics.get('generalization', {}).get('robustness', 'N/A')\n            },\n            'detailed_metrics': self.transfer_metrics,\n            'recommendations': self.generate_recommendations()\n        }\n\n        return report\n\n    def generate_recommendations(self):\n        \"\"\"Generate recommendations based on transfer evaluation\"\"\"\n        recommendations = []\n\n        # Policy transfer recommendations\n        policy_gap = self.transfer_metrics.get('policy_transfer', {}).get('average_gap', 1.0)\n        if policy_gap > 0.3:\n            recommendations.append(\n                \"High policy transfer gap detected (>30%). Consider implementing \"\n                \"domain randomization or fine-tuning on real data.\"\n            )\n\n        # Perception transfer recommendations\n        perception_success = self.transfer_metrics.get('perception_transfer', {}).get('success_rate', 0)\n        if perception_success < 0.7:\n            recommendations.append(\n                \"Low perception success rate (<70%). Consider adding more \"\n                \"domain randomization or collecting real-world training data.\"\n            )\n\n        # Control transfer recommendations\n        control_error = self.transfer_metrics.get('control_transfer', {}).get('avg_tracking_error', float('inf'))\n        if control_error > 0.1:  # More than 10cm error\n            recommendations.append(\n                \"High control tracking error (>10cm). Consider system identification \"\n                \"and adaptive control techniques.\"\n            )\n\n        # General recommendations\n        if not recommendations:\n            recommendations.append(\n                \"Transfer performance is acceptable. Consider expanding to \"\n                \"more diverse scenarios to test robustness.\"\n            )\n\n        return recommendations\n"})}),"\n",(0,r.jsx)(n.h2,{id:"best-practices-and-guidelines",children:"Best Practices and Guidelines"}),"\n",(0,r.jsx)(n.h3,{id:"systematic-approach-to-sim-to-real-transfer",children:"Systematic Approach to Sim-to-Real Transfer"}),"\n",(0,r.jsx)(n.h4,{id:"1-gradual-fidelity-increase",children:"1. Gradual Fidelity Increase"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Gradual fidelity increase strategy\nclass FidelityScheduler:\n    def __init__(self):\n        self.fidelity_levels = [\n            'abstract_simulation',    # Level 1: Basic functionality\n            'kinematic_simulation',   # Level 2: Kinematics only\n            'dynamic_simulation',     # Level 3: Basic dynamics\n            'sensory_simulation',     # Level 4: Sensor simulation\n            'high_fidelity_sim'       # Level 5: Full fidelity\n        ]\n\n        self.current_level = 0\n        self.performance_thresholds = [0.8, 0.85, 0.9, 0.92, 0.95]  # Minimum performance at each level\n\n    def advance_fidelity(self, current_performance):\n        \"\"\"Advance to next fidelity level if performance threshold is met\"\"\"\n        if current_performance >= self.performance_thresholds[self.current_level]:\n            if self.current_level < len(self.fidelity_levels) - 1:\n                self.current_level += 1\n                return True, f\"Advancing to {self.fidelity_levels[self.current_level]}\"\n\n        return False, f\"Stay at {self.fidelity_levels[self.current_level]}, performance {current_performance:.3f} < threshold {self.performance_thresholds[self.current_level]:.3f}\"\n"})}),"\n",(0,r.jsx)(n.h4,{id:"2-validation-strategies",children:"2. Validation Strategies"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Cross-validation"}),": Test on multiple simulation conditions"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Ablation Studies"}),": Isolate specific transfer challenges"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Baseline Comparisons"}),": Compare against no-transfer baselines"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Human Evaluation"}),": Include subjective quality assessments"]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"3-safety-considerations",children:"3. Safety Considerations"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Safe Exploration"}),": Limit initial real-world trials"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Fallback Systems"}),": Have manual override capabilities"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Monitoring"}),": Continuously monitor system behavior"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Graceful Degradation"}),": Design systems to fail safely"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"troubleshooting-common-issues",children:"Troubleshooting Common Issues"}),"\n",(0,r.jsx)(n.h3,{id:"addressing-specific-transfer-problems",children:"Addressing Specific Transfer Problems"}),"\n",(0,r.jsx)(n.h4,{id:"1-sensor-mismatch",children:"1. Sensor Mismatch"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Sensor calibration and adaptation\nclass SensorAdapter:\n    def __init__(self, sim_sensor_model, real_sensor_characteristics):\n        self.sim_model = sim_sensor_model\n        self.real_char = real_sensor_characteristics\n        self.calibration_params = self.learn_calibration_mapping()\n\n    def adapt_sensor_data(self, real_sensor_data):\n        """Adapt real sensor data to match simulation format"""\n        # Apply learned calibration mapping\n        calibrated_data = self.apply_calibration(real_sensor_data, self.calibration_params)\n        return calibrated_data\n\n    def learn_calibration_mapping(self):\n        """Learn mapping from real to sim sensor characteristics"""\n        # This would involve collecting paired sim/real sensor data\n        # and learning a transformation function\n        return {\'gain\': 1.0, \'offset\': 0.0, \'noise_scale\': 1.0}  # Placeholder\n'})}),"\n",(0,r.jsx)(n.h4,{id:"2-actuator-discrepancies",children:"2. Actuator Discrepancies"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Actuator modeling and compensation\nclass ActuatorCompensator:\n    def __init__(self):\n        self.delay_compensation = 0.02  # 20ms delay\n        self.nonlinear_compensation = lambda x: x  # Identity initially\n        self.friction_compensation = 0.1  # Friction coefficient\n\n    def compensate_command(self, desired_command, current_state):\n        """Compensate for actuator nonlinearities"""\n        # Predict delay effect\n        compensated_command = desired_command  # Apply delay compensation\n\n        # Apply nonlinear compensation\n        compensated_command = self.nonlinear_compensation(compensated_command)\n\n        # Account for friction\n        if abs(compensated_command) < self.friction_compensation:\n            compensated_command = 0  # Below friction threshold\n        else:\n            compensated_command = np.sign(compensated_command) * (\n                abs(compensated_command) - self.friction_compensation\n            )\n\n        return compensated_command\n'})}),"\n",(0,r.jsx)(n.h2,{id:"practical-lab-sim-to-real-transfer",children:"Practical Lab: Sim-to-Real Transfer"}),"\n",(0,r.jsx)(n.h3,{id:"lab-objective",children:"Lab Objective"}),"\n",(0,r.jsx)(n.p,{children:"Implement a complete sim-to-real transfer pipeline for a navigation task, including domain randomization, system identification, and performance evaluation."}),"\n",(0,r.jsx)(n.h3,{id:"implementation-steps",children:"Implementation Steps"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Set up Isaac Sim environment with navigation scenario"}),"\n",(0,r.jsx)(n.li,{children:"Implement domain randomization for training"}),"\n",(0,r.jsx)(n.li,{children:"Train navigation policy in simulation"}),"\n",(0,r.jsx)(n.li,{children:"Transfer to real robot (or realistic simulation)"}),"\n",(0,r.jsx)(n.li,{children:"Evaluate transfer performance using established metrics"}),"\n",(0,r.jsx)(n.li,{children:"Apply system identification to reduce reality gap"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"expected-outcome",children:"Expected Outcome"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Working sim-to-real transfer pipeline"}),"\n",(0,r.jsx)(n.li,{children:"Quantified transfer performance metrics"}),"\n",(0,r.jsx)(n.li,{children:"Demonstrated understanding of transfer challenges"}),"\n",(0,r.jsx)(n.li,{children:"Implemented gap reduction techniques"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"review-questions",children:"Review Questions"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:'Explain the concept of "reality gap" and its impact on sim-to-real transfer.'}),"\n",(0,r.jsx)(n.li,{children:"How does domain randomization help improve sim-to-real transfer?"}),"\n",(0,r.jsx)(n.li,{children:"What are the key components of a systematic sim-to-real transfer approach?"}),"\n",(0,r.jsx)(n.li,{children:"How do you evaluate the success of sim-to-real transfer?"}),"\n",(0,r.jsx)(n.li,{children:"What are the main challenges in transferring control policies from simulation to reality?"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,r.jsx)(n.p,{children:"After mastering sim-to-real principles, students should proceed to:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Advanced navigation for humanoid robots"}),"\n",(0,r.jsx)(n.li,{children:"Vision-Language-Action system integration"}),"\n",(0,r.jsx)(n.li,{children:"Real-world deployment strategies"}),"\n",(0,r.jsx)(n.li,{children:"Continuous learning and adaptation systems"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"This comprehensive guide to sim-to-real transfer provides the foundation for successfully bridging the gap between simulation-based development and real-world robotic deployment in Physical AI and Humanoid Robotics applications."})]})}function c(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(m,{...e})}):m(e)}},8453:(e,n,a)=>{a.d(n,{R:()=>t,x:()=>o});var i=a(6540);const r={},s=i.createContext(r);function t(e){const n=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:t(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);